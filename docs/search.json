[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python: De usuario a explorador de datos",
    "section": "",
    "text": "Bienvenida\nSi estás buscando comenzar una aventura en el mundo de la programación y análisis de datos, ¡estás en el lugar correcto!. En este curso MOOC vamos a transformarte de usuario a explorador de datos. Si ya sabes instalar Python, la sintáxis básica de Python, uso de pip y usar la libreta de Jupyter, este curso es para ti.\nNo te mentiremos, este camino no es fácil ni corto, hemos preparado casi 70 lecciones y 52 libretas de Jupyter para este viaje.\nEsta página no es un curso, contiene el material de ejercicios del curso MOOC Python: De usuario a explorador de datos, por lo que si aún no te has inscrito, te recomendamos hacerlo.",
    "crumbs": [
      "Bienvenida"
    ]
  },
  {
    "objectID": "index.html#qué-aprenderás",
    "href": "index.html#qué-aprenderás",
    "title": "Python: De usuario a explorador de datos",
    "section": "¿Qué aprenderás?",
    "text": "¿Qué aprenderás?\nEl curso está organizado por cuatro grandes temas o semanas y un proyecto final, que son:\n\nIntroducción al Manejo de Datos con ETL:\n\nExtracción: Aprenderás a obtener datos desde diferentes fuentes, incluyendo archivos CSV y XLSX.\nTransformación: Te enseñaremos a manipular y preparar tus datos utilizando pandas, facilitando la limpieza y organización.\nCarga: Finalmente, integraremos los datos transformados en una estructura que puedas utilizar para análisis o informes futuros.\nInicio en Pandas: Dominarás las técnicas de manipulación de dataframes y series temporales, esenciales para cualquier explorador de datos.\n\nVisualización de Datos con Matplotlib:\n\nAprenderás a identificar la anatomia de una gráfica en matplotlib.\nComenzarás creando gráficas simples con plt.subplots.\nAprenderas a crear gráficas complejas con plt.subplots y gridspec para diseño más complejos.\nAprenderás a crear gráficas interactivas en la libreta de Jupyter con los ipywidgets.\nAprenderás a personalizar una figura para dejarla lista para ser publicada en cualquier medio.\n\nOperaciones básicas con NumPy:\n\nAprenderas a crear y conocer los arrays.\nAprenderás a cargar datos numéricos de archivos con diferentes herramientas.\nAplicarás la carga y manipulación de matricez con un conjunto de imagenes.\nExplorarás las herramientas de algebra lineal de NumPy para manejar grandes conjuntos de datos numéricos, optimizando tus análisis.\n\nGestión de Proyectos de Datos:\n\nAprenderás y aplicarás el concepto del espacio de trabajo para tus proyectos de ciencia de datos.\nConocerás la importancia de la narrativa computacional en tu espacio de trabajo, nombres de libretas y variables dentro de tus libretas de Jupyter.\nConocerás las mejores estrategias para tener un flujo de trabajo robusto, reproducible y colaborativo.\nAprenderás a como desarrollar tus propios paquetes locales para disminuir los errores en tu flujo de trabajo.\n\nProyecto final:\n\nCulminarás con un proyecto final que pone en practica los conceptos de este curso y mucho enfasis en las buenas prácticas sobre narrativa computacional y espacio de trabajo.\nAplicaras el ETL de principio a fin, desde extraer, transformar y cargar tus datos.",
    "crumbs": [
      "Bienvenida"
    ]
  },
  {
    "objectID": "uso.html",
    "href": "uso.html",
    "title": "Recomendaciones",
    "section": "",
    "text": "Explorar las libretas\nLas libreta están organizadas temáticamente de acuerdo al curso. Puedes desplegar los temas específicos en cada libreta para revisar o profundizar en áreas particulares de interés. Esta estructura modular te permite avanzar a tu propio ritmo y volver sobre temas según lo necesites solo con un vistazo.",
    "crumbs": [
      "Recomendaciones y datos",
      "Recomendaciones"
    ]
  },
  {
    "objectID": "uso.html#búsqueda-específica",
    "href": "uso.html#búsqueda-específica",
    "title": "Recomendaciones",
    "section": "Búsqueda específica",
    "text": "Búsqueda específica\nSi necesitas encontrar ejercicios que utilicen un comando específico de Python o aborden un concepto particular, utiliza la barra de búsqueda, ubicada en la parte superior derecha. Esto te permitirá cruzar toda la colección de libretas rápidamente, identificando ejemplos, explicaciones y problemas prácticos que hacen uso del comando o tema que quieres revisar. Esta función es ideal para estudiar funciones específicas, para la revisión de temas de interés en tus proyectos o para recordar esa configuración especial en algún comando.",
    "crumbs": [
      "Recomendaciones y datos",
      "Recomendaciones"
    ]
  },
  {
    "objectID": "uso.html#copiar-código-fácilmente",
    "href": "uso.html#copiar-código-fácilmente",
    "title": "Recomendaciones",
    "section": "Copiar código fácilmente",
    "text": "Copiar código fácilmente\nGracias a la integración con la tecnología de Quarto, copiar y pegar código de estas libretas es más sencillo que nunca. Simplemente con un clic sobre el bloque de código, este se copiará al portapapeles, facilitando la práctica y la implementación de lo aprendido en tus propios proyectos o ejercicios de prueba. Esto es especialmente útil para experimentar con variantes de los códigos proporcionados y para realizar tus propios ajustes y mejoras.\nEste libro de ejercicios es una herramienta valiosa que te proporciona flexibilidad y control sobre tu aprendizaje en Python, permitiéndote explorar, practicar y perfeccionar tus habilidades de programación en ciencia de datos. Utiliza estas libretas como acompañamiento a las lecciones del MOOC Python: De usuario a explorador de datos y verás cómo tu comprensión y habilidad con Python crecen exponencialmente.",
    "crumbs": [
      "Recomendaciones y datos",
      "Recomendaciones"
    ]
  },
  {
    "objectID": "datos.html",
    "href": "datos.html",
    "title": "Datos para el curso",
    "section": "",
    "text": "Este MOOC está pensado para que repliques las clases con los datos proporcionados. Para esto es importante que tengas los datos y experimentes con los conceptos presentados.\nLos datos se pueden descargar en esta liga.\nUna vez que llegues a esa página (Figura 1), da click en Download raw file para que puedas descargar el zip.\n\n\n\n\n\n\nEspacio de trabajo\n\n\n\nNo olvides crear tu espacio de trabajo para tu proceso de aprendizaje del curso.\n\n\n\n\n\n\n\n\nFigura 1: Página de descarga de los datos del MOOC Python de Usuario a Explorador de Datos",
    "crumbs": [
      "Recomendaciones y datos",
      "Datos para el curso"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/semana1.html",
    "href": "notebooks/semanaUno/semana1.html",
    "title": "Semana Uno",
    "section": "",
    "text": "¡Bienvenides a una semana emocionante de aprendizaje al manejo de datos!\nEn esta semana abordarás desde las definiciones de funciones hasta la manipulación avanzada de archivos, pasando por una introducción esencial a las series temporales. Desentrañaremos los conceptos clave que forman el esqueleto de cualquier proyecto analítico práctico, incluyendo el manejo de formatos de archivo como CSV y XLSX, y el dominio de Pandas, una de las herramientas más poderosas de Python para el manejo de datos.\nCon cada sesión, te equiparás para enfrentar desafíos cada vez más compleojs. Aprenderás a crear bloques de código reutilizables que servirán para automatizar tus tareas, optimizando así tu flujo de trabajo. Dominarás el proceso de ETL (Extracción, Transformación, Carga), esencial para extraer datos de diversas fuentes, transformarlos para su análisis y cargarlos en un entorno listo para usarse.\nAprenderás que el índice es uno de los conceptos más importantes de los DataFrames y más si es una serie temporal y lo configuras correctamente. Y para cerrar, aprenderás a generar gráficos y visualizaciones rápidas para explorar tus datos de manera efectiva.",
    "crumbs": [
      "Semana Uno"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/funciones.html",
    "href": "notebooks/semanaUno/funciones.html",
    "title": "1  Funciones en Python",
    "section": "",
    "text": "1.1 Para aprender más…",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Funciones en Python</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/funciones.html#para-aprender-más",
    "href": "notebooks/semanaUno/funciones.html#para-aprender-más",
    "title": "1  Funciones en Python",
    "section": "",
    "text": "Funciones de Python w3schools",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Funciones en Python</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/funciones.html#ejercicios-sugeridos",
    "href": "notebooks/semanaUno/funciones.html#ejercicios-sugeridos",
    "title": "1  Funciones en Python",
    "section": "1.2 Ejercicios sugeridos",
    "text": "1.2 Ejercicios sugeridos\n\n1.2.1 Ejercicio: Función para Resample con Argumentos por Default\nEscribe una función en Python que acepte un objeto DataFrame de la biblioteca pandas como parámetro. La función debe incluir un argumento adicional que especifique el periodo para aplicar la función resample(). La función debe calcular y retornar la desviación estándar de cada columna del dataframe para ese periodo especificado. Por defecto, el periodo debe estar configurado para ser anual. Documenta la función.\nRequisitos: 1. La función debe tener dos parámetros: el DataFrame y el periodo de muestreo. 2. El argumento del periodo debe tener un valor por default anual. 3. Utiliza la función resample() de pandas para agrupar los datos según el periodo indicado. 4. Calcula y devuelve la desviación estándar de las columnas del DataFrame.\n\n\nCódigo\ndef resample_std(dataframe, period='YE'):\n    \"\"\"\n    Calcula la desviación estándar de los valores en un DataFrame agrupados por un periodo especificado.\n    \n    Args:\n    dataframe (pd.DataFrame): El DataFrame que contiene los datos a analizar.\n    period (str, opcional): Una cadena que representa el intervalo de tiempo para el agrupamiento.\n                            Los valores válidos son aquellos compatibles con la función `resample()` de pandas,\n                            como 'YE' para anual, 'ME' para mensual, etc. El valor por defecto es 'YE' (anual).\n                            \n    Returns:\n    pd.Series: Una serie con la desviación estándar de los valores agrupados por el periodo especificado.\n    \"\"\"\n    # Agrupar los datos por el periodo especificado y calcular la desviación estándar\n    result = dataframe.resample(period).std()\n    \n    return result\n\n\n\nresample_std(cuerna_mean,period=\"ME\")\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n2012-01-31\n1.893345\n0.651048\n71.547346\n173.948067\n313.538191\n449.154262\n34.698048",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Funciones en Python</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/ETL.html",
    "href": "notebooks/semanaUno/ETL.html",
    "title": "2  Extracción, tranformación y carga",
    "section": "",
    "text": "¡Bienvenides al corazón del proceso ETL! Aquí es donde la Extracción, Transformación y Carga (Loading) de datos cobran vida.\nA lo largo de este recorrido, aprenderemos cómo estas tres etapas se entrelazan para convertir datos crudos en información útil, proporcionando la base para la toma de decisiones informadas en el mundo de la ciencia de datos. El proceso ETL es esencial para convertir datos en información valiosa. Aprenderás a extraer, transformar y cargar datos con precisión, abriendo las puertas a un mundo de análisis y conocimiento.\nDesde la extracción inicial de datos de diversas fuentes hasta la transformación hábil para revelar patrones y tendencias, y finalmente la carga en sistemas listos para su análisis, descubrirás cómo este proceso fundamental impulsa la ciencia de datos.\n\nimport pandas as pd\nfrom iertools.read \n\n\nImporta archivos (Extraction)\n\nesolmet = pd.read_csv\nruoa = pd.read_csv\n\n\n\nLimpieza (Transformation)\n\n# cleaning esolmet y ruoa\n\n\n# Junta datos en un dataframe\ndatos = pd.concat([esolmet,ruoa])\n\n\n\nCarga (Loading)\n\ndatos.to_csv",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Extracción, tranformación y carga</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/Intro_series_temporales.html",
    "href": "notebooks/semanaUno/Intro_series_temporales.html",
    "title": "3  Introducción a las series temporales",
    "section": "",
    "text": "¡Bienvenides al emocionante mundo de las series temporales, explora el tiempo con Pandas! En esta sección, exploraremos cómo Pandas, la popular biblioteca de Python, nos permite manejar y analizar datos temporales con facilidad. Desde momentos en el tiempo hasta valores correspondientes, descubre cómo las series temporales se convierten en una herramienta invaluable en la ciencia de datos y la ingeniería.\nLas series temporales nos permiten comprender cómo evolucionan los datos a lo largo del tiempo. Revelan patrones y tendencias que nos ayudan a tomar decisiones informadas. Desde fechas hasta valores, exploraremos cómo Pandas nos brinda la capacidad de manipular el tiempo con la misma facilidad que manipulamos los números.\nDesde la extracción de momentos en el tiempo hasta la manipulación de valores correspondientes, Pandas se convierte en nuestro aliado confiable en el análisis temporal.\n\nimport pandas as pd\n\nFormato año-mes-dia 2020-01-01\nFormato año-mes-dia hora:minuto en formato 24 horas 2020-01-01 22:00\nFormato año-mes-dia hora:minuto:segundo en formato 24 horas 2020-01-01 22:00:30.1\nFormato año-mes-dia hora:minuto en formato AM PM 2020-01-01 10:00:30.1 PM\n\n%load ../data/Cuernavaca_To_1dia_comas.csv\n\n\n%load ../data/Cuernavca_T1dia_tabulador.csv\n\n\n\na = pd.to_datetime('2020-01-01')\na\n\nTimestamp('2020-01-01 00:00:00')\n\n\n\na + pd.DateOffset(hour=1)\n\nTimestamp('2020-01-01 01:00:00')\n\n\n\na + pd.Timedelta('1h')\n\nTimestamp('2020-01-01 01:00:00')",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introducción a las series temporales</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/Intro_pandas_dataframe.html",
    "href": "notebooks/semanaUno/Intro_pandas_dataframe.html",
    "title": "4  Introducción a Pandas y DataFrames",
    "section": "",
    "text": "Dataframes\ncuerna = pd.read_csv(\"../data/Cuernavaca_To_1dia_comas.csv\")\ncuerna\n\n\n\n\n\n\n\n\n\ntiempo\nTo\n\n\n\n\n0\n2012-01-01 00:00:00\n19.3\n\n\n1\n2012-01-01 01:00:00\n18.6\n\n\n2\n2012-01-01 02:00:00\n17.9\n\n\n3\n2012-01-01 03:00:00\n17.3\n\n\n4\n2012-01-01 04:00:00\n16.6\n\n\n5\n2012-01-01 05:00:00\n15.9\n\n\n6\n2012-01-01 06:00:00\n17.0\n\n\n7\n2012-01-01 07:00:00\n18.0\n\n\n8\n2012-01-01 08:00:00\n19.0\n\n\n9\n2012-01-01 09:00:00\n20.0\n\n\n10\n2012-01-01 10:00:00\n20.0\n\n\n11\n2012-01-01 11:00:00\n20.0\n\n\n12\n2012-01-01 12:00:00\n21.0\n\n\n13\n2012-01-01 13:00:00\n22.0\n\n\n14\n2012-01-01 14:00:00\n21.7\n\n\n15\n2012-01-01 15:00:00\n21.3\n\n\n16\n2012-01-01 16:00:00\n21.0\n\n\n17\n2012-01-01 17:00:00\n19.0\n\n\n18\n2012-01-01 18:00:00\n17.1\n\n\n19\n2012-01-01 19:00:00\n17.0\n\n\n20\n2012-01-01 20:00:00\n17.3\n\n\n21\n2012-01-01 21:00:00\n17.0\n\n\n22\n2012-01-01 22:00:00\n16.6\n\n\n23\n2012-01-01 23:00:00\n15.9\ncuerna.index\n\nRangeIndex(start=0, stop=24, step=1)\nf = \"../data/Cuernavaca_To_1dia_comas.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna # nombre es parte de la narrativa \n\n\n\n\n\n\n\n\n\nTo\n\n\ntiempo\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n\n\n2012-01-01 01:00:00\n18.6\n\n\n2012-01-01 02:00:00\n17.9\n\n\n2012-01-01 03:00:00\n17.3\n\n\n2012-01-01 04:00:00\n16.6\n\n\n2012-01-01 05:00:00\n15.9\n\n\n2012-01-01 06:00:00\n17.0\n\n\n2012-01-01 07:00:00\n18.0\n\n\n2012-01-01 08:00:00\n19.0\n\n\n2012-01-01 09:00:00\n20.0\n\n\n2012-01-01 10:00:00\n20.0\n\n\n2012-01-01 11:00:00\n20.0\n\n\n2012-01-01 12:00:00\n21.0\n\n\n2012-01-01 13:00:00\n22.0\n\n\n2012-01-01 14:00:00\n21.7\n\n\n2012-01-01 15:00:00\n21.3\n\n\n2012-01-01 16:00:00\n21.0\n\n\n2012-01-01 17:00:00\n19.0\n\n\n2012-01-01 18:00:00\n17.1\n\n\n2012-01-01 19:00:00\n17.0\n\n\n2012-01-01 20:00:00\n17.3\n\n\n2012-01-01 21:00:00\n17.0\n\n\n2012-01-01 22:00:00\n16.6\n\n\n2012-01-01 23:00:00\n15.9\ncuerna.index\n\nDatetimeIndex(['2012-01-01 00:00:00', '2012-01-01 01:00:00',\n               '2012-01-01 02:00:00', '2012-01-01 03:00:00',\n               '2012-01-01 04:00:00', '2012-01-01 05:00:00',\n               '2012-01-01 06:00:00', '2012-01-01 07:00:00',\n               '2012-01-01 08:00:00', '2012-01-01 09:00:00',\n               '2012-01-01 10:00:00', '2012-01-01 11:00:00',\n               '2012-01-01 12:00:00', '2012-01-01 13:00:00',\n               '2012-01-01 14:00:00', '2012-01-01 15:00:00',\n               '2012-01-01 16:00:00', '2012-01-01 17:00:00',\n               '2012-01-01 18:00:00', '2012-01-01 19:00:00',\n               '2012-01-01 20:00:00', '2012-01-01 21:00:00',\n               '2012-01-01 22:00:00', '2012-01-01 23:00:00'],\n              dtype='datetime64[ns]', name='tiempo', freq=None)",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introducción a Pandas y DataFrames</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/archivos_csv_xlsx.html",
    "href": "notebooks/semanaUno/archivos_csv_xlsx.html",
    "title": "5  Archivos CSV y XLSX",
    "section": "",
    "text": "¿Cuándo usar CSV y cuándo usar XLSX? La mayoría de las veces no tienes opción de escoger, te dan el conjunto de datos en formatos diferentes y no te queda más que cargar tus datos desde ahí.\nSaber qué es cada uno de estos archivos es imprescindible. Muchas personas confunden un CSV por un archivo de una hoja de cálculo. Aprende las diferencias y aprende a importar cada uno de ellos.",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Archivos CSV y XLSX</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/read_csv.html",
    "href": "notebooks/semanaUno/read_csv.html",
    "title": "6  Lectura de archivos csv",
    "section": "",
    "text": "En el análisis de datos con Pandas, la función pd.read_csv() es una herramienta esencial para importar datos desde archivos CSV. Esta poderosa función no solo simplifica la carga de datos, sino que también ofrece una amplia gama de opciones flexibles que permiten una adaptación precisa a las diversas necesidades de importación.\nAprender a personalizar la lectura de tus archivos CSV es esencial para alinearlos con los objetivos específicos de tu proyecto. Ya sea que necesites saltar filas, interpretar fechas o utilizar una columna como índice, pd.read_csv() te brinda todas las herramientas necesarias para preparar tus datos para un análisis de datos efectivo y poderoso en Pandas.\nEs más que una simple función de importación; es la clave para desbloquear el potencial completo de tus datos en el entorno de Pandas, permitiéndote centrarte en lo que realmente importa: obtener infromación valiosa a través del análisis de datos.\n\nimport pandas as pd\n\n\nf = \"../data/Cuernavaca_To_1dia_comas.csv\"\ncuerna = pd.read_csv(f)\ncuerna.head() # hacerlo primero sin head\n\n\n\n\n\n\n\n\n\ntiempo\nTo\n\n\n\n\n0\n2012-01-01 00:00:00\n19.3\n\n\n1\n2012-01-01 01:00:00\n18.6\n\n\n2\n2012-01-01 02:00:00\n17.9\n\n\n3\n2012-01-01 03:00:00\n17.3\n\n\n4\n2012-01-01 04:00:00\n16.6\n\n\n\n\n\n\n\n\n\ntype(cuerna)\n\npandas.core.frame.DataFrame\n\n\n\ncuerna = pd.read_csv(f) #Muestra las opciones que tiene shift + tab adentro de parentesis\n\n\ncuerna = pd.read_csv(f,index_col=0)\ncuerna.index\n\nIndex(['2012-01-01 00:00:00', '2012-01-01 01:00:00', '2012-01-01 02:00:00',\n       '2012-01-01 03:00:00', '2012-01-01 04:00:00', '2012-01-01 05:00:00',\n       '2012-01-01 06:00:00', '2012-01-01 07:00:00', '2012-01-01 08:00:00',\n       '2012-01-01 09:00:00', '2012-01-01 10:00:00', '2012-01-01 11:00:00',\n       '2012-01-01 12:00:00', '2012-01-01 13:00:00', '2012-01-01 14:00:00',\n       '2012-01-01 15:00:00', '2012-01-01 16:00:00', '2012-01-01 17:00:00',\n       '2012-01-01 18:00:00', '2012-01-01 19:00:00', '2012-01-01 20:00:00',\n       '2012-01-01 21:00:00', '2012-01-01 22:00:00', '2012-01-01 23:00:00'],\n      dtype='object', name='tiempo')",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Lectura de archivos csv</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/read_excel.html",
    "href": "notebooks/semanaUno/read_excel.html",
    "title": "7  Lectura de archivos XLSX",
    "section": "",
    "text": "¿Quieres aprender a leer tus datos de una hoja de cálculo? En esta sesión, exploraremos la función pd.read_excel(), una herramienta fundamental para importar datos de archivos XLSX en Pandas. Descubre cómo pd.read_excel() simplifica la carga de datos Excel, ofreciendo opciones flexibles para controlar la lectura de datos y preparar el terreno para el análisis de datos efectivo en Pandas.\nSi buscas tener un control detallado sobre la importación de tus datos de Excel, pd.read_excel() es la herramienta que necesitas. Con sus capacidades avanzadas, puedes especificar exactamente qué hojas importar, cómo manejar las fechas, y ajustar numerosas opciones para afinar el proceso de carga. Esto te permite no solo simplificar la importación de datos sino también asegurar que la preparación de tus datos esté perfectamente alineada con las necesidades de tu análisis avanzado en Pandas.\n\nimport pandas as pd\n\n\nf = \"../data/Cuernavaca_To_1dia_comas.xlsx\"\ncuerna = pd.read_excel(f)\ncuerna.head()\n\n\n\n\n\n\n\n\n\ntiempo\nTo\n\n\n\n\n0\n2012-01-01 00:00:00\n19.3\n\n\n1\n2012-01-01 01:00:00\n18.6\n\n\n2\n2012-01-01 02:00:00\n17.9\n\n\n3\n2012-01-01 03:00:00\n17.3\n\n\n4\n2012-01-01 04:00:00\n16.6\n\n\n\n\n\n\n\n\n\nf = \"../data/Cuernavaca_To_1dia_comas.xlsx\"\ncuerna = pd.read_excel(f,index_col=0) #explorar opciones de read_excel\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\n\n\ntiempo\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n\n\n2012-01-01 01:00:00\n18.6\n\n\n2012-01-01 02:00:00\n17.9\n\n\n2012-01-01 03:00:00\n17.3\n\n\n2012-01-01 04:00:00\n16.6\n\n\n\n\n\n\n\n\n\ncuerna.index # resalta que se importa como datetime porque asi estaba declarada en el excel\n\nDatetimeIndex(['2012-01-01 00:00:00', '2012-01-01 01:00:00',\n               '2012-01-01 02:00:00', '2012-01-01 03:00:00',\n               '2012-01-01 04:00:00', '2012-01-01 05:00:00',\n               '2012-01-01 06:00:00', '2012-01-01 07:00:00',\n               '2012-01-01 08:00:00', '2012-01-01 09:00:00',\n               '2012-01-01 10:00:00', '2012-01-01 11:00:00',\n               '2012-01-01 12:00:00', '2012-01-01 13:00:00',\n               '2012-01-01 14:00:00', '2012-01-01 15:00:00',\n               '2012-01-01 16:00:00', '2012-01-01 17:00:00',\n               '2012-01-01 18:00:00', '2012-01-01 19:00:00',\n               '2012-01-01 20:00:00', '2012-01-01 21:00:00',\n               '2012-01-01 22:00:00', '2012-01-01 23:00:00'],\n              dtype='datetime64[ns]', name='tiempo', freq=None)",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Lectura de archivos XLSX</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/explorando_read_csv.html",
    "href": "notebooks/semanaUno/explorando_read_csv.html",
    "title": "8  Explorando las opciones de read_csv",
    "section": "",
    "text": "En esta sesión, exploraremos los parámetros de la función pd.read_csv(), que nos permiten personalizar la carga de datos desde archivos CSV.\nDesde la selección de separadores hasta la definición de columnas de índice, los parámetros de la función son esenciales para una carga de datos efectiva en Pandas.\nDescubre cómo estos parámetros te ayudan a optimizar la importación de datos y adaptarla a tus necesidades específicas con Pandas. Toma el control con los parámetros de pd.read_csv() y personaliza la importación de datos para adaptarla a tus necesidades específicas.\n\n# revisa los datos\n\n\nimport pandas as pd\n\n\nf = \"../data/Cuernavca_T1dia_tabulador.csv\"\ncuerna = pd.read_csv(f) # Como leer la ayuda shift + tab\ncuerna.head()\n\n\n\n\n\n\n\n\n\ntiempo\\tTo\n\n\n\n\n0\n2012-01-01 00:00:00\\t19.3\n\n\n1\n2012-01-01 01:00:00\\t18.6\n\n\n2\n2012-01-01 02:00:00\\t17.9\n\n\n3\n2012-01-01 03:00:00\\t17.3\n\n\n4\n2012-01-01 04:00:00\\t16.6\n\n\n\n\n\n\n\n\n\ncuerna = pd.read_csv(f,sep=\"\\t\") #delimiter\ncuerna = pd.read_csv(f,delimiter=\"\\t\") #delimiter\n\ncuerna.head()\n\n\n\n\n\n\n\n\n\ntiempo\nTo\n\n\n\n\n0\n2012-01-01 00:00:00\n19.3\n\n\n1\n2012-01-01 01:00:00\n18.6\n\n\n2\n2012-01-01 02:00:00\n17.9\n\n\n3\n2012-01-01 03:00:00\n17.3\n\n\n4\n2012-01-01 04:00:00\n16.6\n\n\n\n\n\n\n\n\n\ncuerna = pd.read_csv(f,header=None,sep=\"\\t\")\ncuerna.head()\n\n\n\n\n\n\n\n\n\n0\n1\n\n\n\n\n0\ntiempo\nTo\n\n\n1\n2012-01-01 00:00:00\n19.3\n\n\n2\n2012-01-01 01:00:00\n18.6\n\n\n3\n2012-01-01 02:00:00\n17.9\n\n\n4\n2012-01-01 03:00:00\n17.3\n\n\n\n\n\n\n\n\n\ncuerna = pd.read_csv(\n    f,\n    header=None,\n    sep=\"\\t\",\n    names = [\"t\",\"temperatura\"]\n)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nt\ntemperatura\n\n\n\n\n0\ntiempo\nTo\n\n\n1\n2012-01-01 00:00:00\n19.3\n\n\n2\n2012-01-01 01:00:00\n18.6\n\n\n3\n2012-01-01 02:00:00\n17.9\n\n\n4\n2012-01-01 03:00:00\n17.3\n\n\n\n\n\n\n\n\n\ncuerna = pd.read_csv(\n    f,\n    header=None,\n    sep=\"\\t\",\n    names = [\"t\",\"temperatura\"],\n    skiprows=1\n)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nt\ntemperatura\n\n\n\n\n0\n2012-01-01 00:00:00\n19.3\n\n\n1\n2012-01-01 01:00:00\n18.6\n\n\n2\n2012-01-01 02:00:00\n17.9\n\n\n3\n2012-01-01 03:00:00\n17.3\n\n\n4\n2012-01-01 04:00:00\n16.6\n\n\n\n\n\n\n\n\n\ncuerna = pd.read_csv(\n    f,\n    header=None,\n    sep=\"\\t\",\n    names = [\"t\",\"temperatura\"],\n    skiprows=1,\n    index_col=0\n)\ncuerna.head()\n\n\n\n\n\n\n\n\n\ntemperatura\n\n\nt\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n\n\n2012-01-01 01:00:00\n18.6\n\n\n2012-01-01 02:00:00\n17.9\n\n\n2012-01-01 03:00:00\n17.3\n\n\n2012-01-01 04:00:00\n16.6\n\n\n\n\n\n\n\n\n\ncuerna = pd.read_csv(\n    f,\n    header=None,\n    sep=\"\\t\",\n    names = [\"t\",\"temperatura\"],\n    skiprows=1,\n    index_col=0,\n    parse_dates=True\n)\ncuerna.head()\n\n\n\n\n\n\n\n\n\ntemperatura\n\n\nt\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n\n\n2012-01-01 01:00:00\n18.6\n\n\n2012-01-01 02:00:00\n17.9\n\n\n2012-01-01 03:00:00\n17.3\n\n\n2012-01-01 04:00:00\n16.6\n\n\n\n\n\n\n\n\n\ncuerna.index\n\nDatetimeIndex(['2012-01-01 00:00:00', '2012-01-01 01:00:00',\n               '2012-01-01 02:00:00', '2012-01-01 03:00:00',\n               '2012-01-01 04:00:00', '2012-01-01 05:00:00',\n               '2012-01-01 06:00:00', '2012-01-01 07:00:00',\n               '2012-01-01 08:00:00', '2012-01-01 09:00:00',\n               '2012-01-01 10:00:00', '2012-01-01 11:00:00',\n               '2012-01-01 12:00:00', '2012-01-01 13:00:00',\n               '2012-01-01 14:00:00', '2012-01-01 15:00:00',\n               '2012-01-01 16:00:00', '2012-01-01 17:00:00',\n               '2012-01-01 18:00:00', '2012-01-01 19:00:00',\n               '2012-01-01 20:00:00', '2012-01-01 21:00:00',\n               '2012-01-01 22:00:00', '2012-01-01 23:00:00'],\n              dtype='datetime64[ns]', name='t', freq=None)\n\n\n\nf = \"../data/Cuernavaca_1dia_comas.csv\"\ncuerna = pd.read_csv(\n    f,\n    index_col=0,\n    parse_dates=True\n)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n\n\n\n\n\n\n\n\n\nf = \"../data/Cuernavaca_1dia_comas.csv\"\ncuerna = pd.read_csv(\n    f,\n    index_col=0,\n    parse_dates=True,\n    usecols=[0,1,2,3]\n)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\n\n\ntiempo\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n0.0\n26\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n\n\n2012-01-01 03:00:00\n17.3\n0.0\n30\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Explorando las opciones de read_csv</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/indice.html",
    "href": "notebooks/semanaUno/indice.html",
    "title": "9  El índice en series temporales",
    "section": "",
    "text": "El índice en series temporales, facilita la identificación, ordenación y análisis de tus datos, convirtiéndose en un elemento crucial en el manejo de series temporales.\nConoce la manera en que el índice se transforma en un aliado para la manipulación de datos cronológicamente estructurados. A lo largo de este notebook, aprenderemos a configurar el índice en Pandas, en específico con series temporales. Esto nos abre la puerta a realizar operaciones complejas como el filtrado por intervalos de tiempo y el estudio de patrones estacionales. Experimenta la transformación que el índice en Pandas puede aportar a tu metodología de análisis de series temporales.\n\nimport pandas as pd\n\n\nf = \"../data/Cuernavaca_To_1dia_comas.csv\"\ncuerna = pd.read_csv(\n    f\n)\ncuerna.head()\n\n\n\n\n\n\n\n\n\ntiempo\nTo\n\n\n\n\n0\n2012-01-01 00:00:00\n19.3\n\n\n1\n2012-01-01 01:00:00\n18.6\n\n\n2\n2012-01-01 02:00:00\n17.9\n\n\n3\n2012-01-01 03:00:00\n17.3\n\n\n4\n2012-01-01 04:00:00\n16.6\n\n\n\n\n\n\n\n\n\ncuerna.index\n\nRangeIndex(start=0, stop=24, step=1)\n\n\n\nf = \"../data/Cuernavaca_To_1dia_comas.csv\"\ncuerna = pd.read_csv(\n    f,\n    index_col=0,\n    parse_dates=True\n)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\n\n\ntiempo\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n\n\n2012-01-01 01:00:00\n18.6\n\n\n2012-01-01 02:00:00\n17.9\n\n\n2012-01-01 03:00:00\n17.3\n\n\n2012-01-01 04:00:00\n16.6\n\n\n\n\n\n\n\n\n\ncuerna.index # comentar que podrian ser solo dias\n\nDatetimeIndex(['2012-01-01 00:00:00', '2012-01-01 01:00:00',\n               '2012-01-01 02:00:00', '2012-01-01 03:00:00',\n               '2012-01-01 04:00:00', '2012-01-01 05:00:00',\n               '2012-01-01 06:00:00', '2012-01-01 07:00:00',\n               '2012-01-01 08:00:00', '2012-01-01 09:00:00',\n               '2012-01-01 10:00:00', '2012-01-01 11:00:00',\n               '2012-01-01 12:00:00', '2012-01-01 13:00:00',\n               '2012-01-01 14:00:00', '2012-01-01 15:00:00',\n               '2012-01-01 16:00:00', '2012-01-01 17:00:00',\n               '2012-01-01 18:00:00', '2012-01-01 19:00:00',\n               '2012-01-01 20:00:00', '2012-01-01 21:00:00',\n               '2012-01-01 22:00:00', '2012-01-01 23:00:00'],\n              dtype='datetime64[ns]', name='tiempo', freq=None)\n\n\n\ncuerna.resample(\"D\").mean() # veremos mas operaciones \n\n\n\n\n\n\n\n\n\nTo\n\n\ntiempo\n\n\n\n\n\n2012-01-01\n18.604167",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>El índice en series temporales</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/datetime_pandas.html",
    "href": "notebooks/semanaUno/datetime_pandas.html",
    "title": "10  El objeto datetime en Pandas",
    "section": "",
    "text": "En el análisis de series temporales con Pandas, la comprensión de los tipos de objetos de tiempo (datetime) es fundamental. Ahora, exploraremos cómo los tipos de objetos como datetime64, Timestamp, DateOffset, Timedelta y Period, son esenciales para trabajar con fechas y horas de manera precisa y eficiente en Pandas.\nLos objetos temporales en Pandas son el fundamento para el análisis de series temporales. A través de esta sesión, descubriremos la importancia de estos tipos de objetos y cómo son indispensables para una gestión precisa y eficiente del tiempo, ofreciendo las herramientas fundamentales para un análisis temporal.\n\nimport pandas as pd\n\n\nf = \"../data/Cuernavaca_1dia_comas.csv\"\ncuerna = pd.read_csv(\n    f,\n    index_col=0,\n    parse_dates=True\n)\ncuerna.index\n\nDatetimeIndex(['2012-01-01 00:00:00', '2012-01-01 01:00:00',\n               '2012-01-01 02:00:00', '2012-01-01 03:00:00',\n               '2012-01-01 04:00:00', '2012-01-01 05:00:00',\n               '2012-01-01 06:00:00', '2012-01-01 07:00:00',\n               '2012-01-01 08:00:00', '2012-01-01 09:00:00',\n               '2012-01-01 10:00:00', '2012-01-01 11:00:00',\n               '2012-01-01 12:00:00', '2012-01-01 13:00:00',\n               '2012-01-01 14:00:00', '2012-01-01 15:00:00',\n               '2012-01-01 16:00:00', '2012-01-01 17:00:00',\n               '2012-01-01 18:00:00', '2012-01-01 19:00:00',\n               '2012-01-01 20:00:00', '2012-01-01 21:00:00',\n               '2012-01-01 22:00:00', '2012-01-01 23:00:00'],\n              dtype='datetime64[ns]', name='tiempo', freq=None)\n\n\n\ntype(cuerna.index)\n\npandas.core.indexes.datetimes.DatetimeIndex\n\n\n\npd.to_datetime('2012-01-01 22:00:00')\n\nTimestamp('2012-01-01 22:00:00')\n\n\n\ntype(pd.to_datetime('2012-01-01 22:00:00'))\n\npandas._libs.tslibs.timestamps.Timestamp\n\n\n\ncuerna.index[0] # Si sacamos un elemento del datetimeindex obtenemos un timestamp\n\nTimestamp('2012-01-01 00:00:00')\n\n\n\npd.to_datetime('2012-01-01 22:00:00') + pd.DateOffset(years=1)\n\nTimestamp('2013-01-01 22:00:00')\n\n\n\npd.Period('2012-01-01',freq=\"D\",month=2) \n\nPeriod('2012-01-01', 'D')\n\n\n\npd.to_datetime('2012-01-02 22:00:00')  - pd.to_datetime('2012-01-01')\n\nTimedelta('1 days 22:00:00')\n\n\n\npd.to_datetime('2012-01-02')  + pd.Timedelta('3D2h30Min5S')\n\nTimestamp('2012-01-05 02:30:05')",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>El objeto datetime en Pandas</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/columnas_renglones.html",
    "href": "notebooks/semanaUno/columnas_renglones.html",
    "title": "11  Localiza columnas y renglones",
    "section": "",
    "text": "En está sesión , nos enfocaremos en técnicas que van desde la selección de columnas hasta la manipulación de filas con .loc y .iloc, herramientas que te empoderarán para manejar tus datos temporales en Pandas con eficacia.\nAcceder a las columnas, ya sea utilizando corchetes, la notación de punto te cambiará tu flujo de trabajo. Estas estrategias no solo facilitan la selección de datos relevantes sino que también optimizan el proceso de análisis temporal.\n\nimport pandas as pd\n\n\nf = \"../data/Cuernavaca_1dia_comas.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n\n\n\n\n\n\n\n\n\ncuerna['To']\n\ntiempo\n2012-01-01 00:00:00    19.3\n2012-01-01 01:00:00    18.6\n2012-01-01 02:00:00    17.9\n2012-01-01 03:00:00    17.3\n2012-01-01 04:00:00    16.6\n2012-01-01 05:00:00    15.9\n2012-01-01 06:00:00    17.0\n2012-01-01 07:00:00    18.0\n2012-01-01 08:00:00    19.0\n2012-01-01 09:00:00    20.0\n2012-01-01 10:00:00    20.0\n2012-01-01 11:00:00    20.0\n2012-01-01 12:00:00    21.0\n2012-01-01 13:00:00    22.0\n2012-01-01 14:00:00    21.7\n2012-01-01 15:00:00    21.3\n2012-01-01 16:00:00    21.0\n2012-01-01 17:00:00    19.0\n2012-01-01 18:00:00    17.1\n2012-01-01 19:00:00    17.0\n2012-01-01 20:00:00    17.3\n2012-01-01 21:00:00    17.0\n2012-01-01 22:00:00    16.6\n2012-01-01 23:00:00    15.9\nName: To, dtype: float64\n\n\n\ncuerna.To #Por esto no conviene usar espacios o caracteres extraños\n\ntiempo\n2012-01-01 00:00:00    19.3\n2012-01-01 01:00:00    18.6\n2012-01-01 02:00:00    17.9\n2012-01-01 03:00:00    17.3\n2012-01-01 04:00:00    16.6\n2012-01-01 05:00:00    15.9\n2012-01-01 06:00:00    17.0\n2012-01-01 07:00:00    18.0\n2012-01-01 08:00:00    19.0\n2012-01-01 09:00:00    20.0\n2012-01-01 10:00:00    20.0\n2012-01-01 11:00:00    20.0\n2012-01-01 12:00:00    21.0\n2012-01-01 13:00:00    22.0\n2012-01-01 14:00:00    21.7\n2012-01-01 15:00:00    21.3\n2012-01-01 16:00:00    21.0\n2012-01-01 17:00:00    19.0\n2012-01-01 18:00:00    17.1\n2012-01-01 19:00:00    17.0\n2012-01-01 20:00:00    17.3\n2012-01-01 21:00:00    17.0\n2012-01-01 22:00:00    16.6\n2012-01-01 23:00:00    15.9\nName: To, dtype: float64\n\n\n\ncuerna[[\"Ws\",\"To\"]]\n\n\n\n\n\n\n\n\n\nWs\nTo\n\n\ntiempo\n\n\n\n\n\n\n2012-01-01 00:00:00\n0.0\n19.3\n\n\n2012-01-01 01:00:00\n0.0\n18.6\n\n\n2012-01-01 02:00:00\n0.0\n17.9\n\n\n2012-01-01 03:00:00\n0.0\n17.3\n\n\n2012-01-01 04:00:00\n0.0\n16.6\n\n\n2012-01-01 05:00:00\n0.0\n15.9\n\n\n2012-01-01 06:00:00\n0.0\n17.0\n\n\n2012-01-01 07:00:00\n0.0\n18.0\n\n\n2012-01-01 08:00:00\n0.0\n19.0\n\n\n2012-01-01 09:00:00\n0.0\n20.0\n\n\n2012-01-01 10:00:00\n1.0\n20.0\n\n\n2012-01-01 11:00:00\n2.1\n20.0\n\n\n2012-01-01 12:00:00\n1.8\n21.0\n\n\n2012-01-01 13:00:00\n1.5\n22.0\n\n\n2012-01-01 14:00:00\n1.3\n21.7\n\n\n2012-01-01 15:00:00\n1.2\n21.3\n\n\n2012-01-01 16:00:00\n1.0\n21.0\n\n\n2012-01-01 17:00:00\n0.0\n19.0\n\n\n2012-01-01 18:00:00\n0.0\n17.1\n\n\n2012-01-01 19:00:00\n0.0\n17.0\n\n\n2012-01-01 20:00:00\n0.0\n17.3\n\n\n2012-01-01 21:00:00\n0.2\n17.0\n\n\n2012-01-01 22:00:00\n0.5\n16.6\n\n\n2012-01-01 23:00:00\n0.8\n15.9\n\n\n\n\n\n\n\n\n\ncuerna.iloc[0]\n\nTo       19.3\nWs        0.0\nWd       26.0\nP     87415.0\nIg        0.0\nIb        0.0\nId        0.0\nName: 2012-01-01 00:00:00, dtype: float64\n\n\n\ncuerna.iloc[0:10]\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n\n\n2012-01-01 05:00:00\n15.9\n0.0\n26\n87087\n0\n0\n0\n\n\n2012-01-01 06:00:00\n17.0\n0.0\n27\n87096\n0\n0\n0\n\n\n2012-01-01 07:00:00\n18.0\n0.0\n34\n87140\n20\n151\n11\n\n\n2012-01-01 08:00:00\n19.0\n0.0\n61\n87185\n164\n522\n37\n\n\n2012-01-01 09:00:00\n20.0\n0.0\n95\n87229\n369\n812\n58\n\n\n\n\n\n\n\n\n\ncuerna.iloc[-1]\n\nTo       15.9\nWs        0.8\nWd       93.0\nP     87143.0\nIg        0.0\nIb        0.0\nId        0.0\nName: 2012-01-01 23:00:00, dtype: float64\n\n\n\ncuerna.iloc[-1:-10:-2]\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 23:00:00\n15.9\n0.8\n93\n87143\n0\n0\n0\n\n\n2012-01-01 21:00:00\n17.0\n0.2\n85\n87080\n0\n0\n0\n\n\n2012-01-01 19:00:00\n17.0\n0.0\n269\n87101\n0\n0\n0\n\n\n2012-01-01 17:00:00\n19.0\n0.0\n198\n87185\n219\n650\n46\n\n\n2012-01-01 15:00:00\n21.3\n1.2\n176\n87287\n617\n932\n74",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Localiza columnas y renglones</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/Intro_EDA.html",
    "href": "notebooks/semanaUno/Intro_EDA.html",
    "title": "12  EDA: Explora visualmente tus datos",
    "section": "",
    "text": "¿Tus datos te dicen poco? Aprende las técnicas de EDA y descubre cómo visualizar, resumir y comprender las características principales y patrones en tus conjuntos de datos.\nCon EDA, puedes crear visualizaciones impactantes como histogramas, gráficos de caja y diagramas de dispersión para revelar la distribución y las relaciones entre tus variables. Estas herramientas gráficas son esenciales para interpretar tus datos de manera intuitiva y efectiva.\nEn esta sesión, descubriremos cómo el EDA es un aliado poderoso en la comprensión profunda de la naturaleza de nuestros datos. Nos permite identificar patrones, tendencias y anomalías, lo que resulta crucial para tomar decisiones basadas en evidencia en nuestro análisis de datos.\n\nimport pandas as pd\n\n\nf = \"../data/Cuernavaca_1dia_comas.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.index\n\nDatetimeIndex(['2012-01-01 00:00:00', '2012-01-01 01:00:00',\n               '2012-01-01 02:00:00', '2012-01-01 03:00:00',\n               '2012-01-01 04:00:00', '2012-01-01 05:00:00',\n               '2012-01-01 06:00:00', '2012-01-01 07:00:00',\n               '2012-01-01 08:00:00', '2012-01-01 09:00:00',\n               '2012-01-01 10:00:00', '2012-01-01 11:00:00',\n               '2012-01-01 12:00:00', '2012-01-01 13:00:00',\n               '2012-01-01 14:00:00', '2012-01-01 15:00:00',\n               '2012-01-01 16:00:00', '2012-01-01 17:00:00',\n               '2012-01-01 18:00:00', '2012-01-01 19:00:00',\n               '2012-01-01 20:00:00', '2012-01-01 21:00:00',\n               '2012-01-01 22:00:00', '2012-01-01 23:00:00'],\n              dtype='datetime64[ns]', name='tiempo', freq=None)\n\n\n\ncuerna.plot()\n\n\n\n\n\n\n\n\n\ncuerna.plot(subplots=True)\n\narray([&lt;Axes: xlabel='tiempo'&gt;, &lt;Axes: xlabel='tiempo'&gt;,\n       &lt;Axes: xlabel='tiempo'&gt;, &lt;Axes: xlabel='tiempo'&gt;,\n       &lt;Axes: xlabel='tiempo'&gt;, &lt;Axes: xlabel='tiempo'&gt;,\n       &lt;Axes: xlabel='tiempo'&gt;], dtype=object)\n\n\n\n\n\n\n\n\n\n\ncuerna.plot(subplots=True,figsize=(10,10))\n\narray([&lt;Axes: xlabel='tiempo'&gt;, &lt;Axes: xlabel='tiempo'&gt;,\n       &lt;Axes: xlabel='tiempo'&gt;, &lt;Axes: xlabel='tiempo'&gt;,\n       &lt;Axes: xlabel='tiempo'&gt;, &lt;Axes: xlabel='tiempo'&gt;,\n       &lt;Axes: xlabel='tiempo'&gt;], dtype=object)\n\n\n\n\n\n\n\n\n\n\ncuerna.columns\n\nIndex(['To', 'Ws', 'Wd', 'P', 'Ig', 'Ib', 'Id'], dtype='object')\n\n\n\ncolumnas = ['To',  'P', 'Ig']\ncuerna[columnas].plot(subplots=True)\n\narray([&lt;Axes: xlabel='tiempo'&gt;, &lt;Axes: xlabel='tiempo'&gt;,\n       &lt;Axes: xlabel='tiempo'&gt;], dtype=object)",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>EDA: Explora visualmente tus datos</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/AnalisisEstadistico.html",
    "href": "notebooks/semanaUno/AnalisisEstadistico.html",
    "title": "13  Exploración de los datos en tu DataFrame",
    "section": "",
    "text": "Iniciar un análisis de datos requiere comprender desde el inicio tanto la estructura como el contenido de tus DataFrames. Ahora, emprenderemos el camino hacia el Análisis Exploratorio de Datos (EDA), enfocándonos en pasos esenciales como conocer y descubrir los tipos de datos de tu DataFrame. Descubre el núcleo de tu información mediante estadísticas descriptivas que proporcionan un panorama de las tendencias centrales, la dispersión y la forma de las variables.\nEs crucial verificar el tipo de tus datos para asegurar que cada columna esté adecuadamente configurada para el análisis deseado.\n\nimport pandas as pd\n\n\nf = \"../data/Cuernavaca_1dia_comas_Nans.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\nobservacion\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\nNaN\n0.0\n26\n87415\n0\n0\n0\nSí\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\nNo\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\nNo\n\n\n2012-01-01 03:00:00\nNaN\n0.0\n30\n87554\n0\n0\n0\nNo\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\nNo\n\n\n\n\n\n\n\n\n\ncuerna.tail()\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\nobservacion\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 19:00:00\n17.0\n0.0\n269\n87101\n0\n0\n0\nNo\n\n\n2012-01-01 20:00:00\nNaN\n0.0\n50\n87115\n0\n0\n0\nNo\n\n\n2012-01-01 21:00:00\n17.0\n0.2\n85\n87080\n0\n0\n0\nNo\n\n\n2012-01-01 22:00:00\n16.6\n0.5\n89\n87089\n0\n0\n0\nNo\n\n\n2012-01-01 23:00:00\nNaN\n0.8\n93\n87143\n0\n0\n0\nNo\n\n\n\n\n\n\n\n\n\ncuerna.describe()\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\n\n\n\n\ncount\n13.000000\n24.00000\n24.00000\n24.000000\n24.000000\n24.000000\n24.00000\n\n\nmean\n18.123077\n0.47500\n101.25000\n87255.958333\n227.666667\n366.625000\n28.00000\n\n\nstd\n1.744111\n0.67711\n71.75214\n180.197351\n311.130291\n442.973727\n34.25353\n\n\nmin\n15.900000\n0.00000\n26.00000\n87080.000000\n0.000000\n0.000000\n0.00000\n\n\n25%\n17.000000\n0.00000\n30.00000\n87112.250000\n0.000000\n0.000000\n0.00000\n\n\n50%\n17.900000\n0.00000\n91.00000\n87229.000000\n0.000000\n0.000000\n0.00000\n\n\n75%\n19.000000\n1.00000\n160.00000\n87305.500000\n466.750000\n867.250000\n65.75000\n\n\nmax\n22.000000\n2.10000\n269.00000\n87788.000000\n810.000000\n999.000000\n80.00000\n\n\n\n\n\n\n\n\n\ncuerna.dtypes\n\nTo             float64\nWs             float64\nWd               int64\nP                int64\nIg               int64\nIb               int64\nId               int64\nobservacion     object\ndtype: object\n\n\n\ncuerna.nunique()\n\nTo              9\nWs             10\nWd             19\nP              20\nIg             12\nIb             12\nId             11\nobservacion     2\ndtype: int64\n\n\n\ncuerna.observacion.value_counts()\n\nobservacion\nNo    16\nSí     8\nName: count, dtype: int64\n\n\n\ncuerna.observacion.value_counts(normalize=True)\n\nobservacion\nNo    0.666667\nSí    0.333333\nName: proportion, dtype: float64\n\n\n\ncuerna.isnull()\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\nobservacion\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 01:00:00\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 02:00:00\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 03:00:00\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 04:00:00\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 05:00:00\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 06:00:00\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 07:00:00\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 08:00:00\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 09:00:00\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 10:00:00\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 11:00:00\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 12:00:00\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 13:00:00\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 14:00:00\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 15:00:00\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 16:00:00\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 17:00:00\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 18:00:00\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 19:00:00\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 20:00:00\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 21:00:00\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 22:00:00\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2012-01-01 23:00:00\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\n\n\ncuerna.isnull().sum()\n\nTo             11\nWs              0\nWd              0\nP               0\nIg              0\nIb              0\nId              0\nobservacion     0\ndtype: int64",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Exploración de los datos en tu DataFrame</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/ValoresNulos.html",
    "href": "notebooks/semanaUno/ValoresNulos.html",
    "title": "14  Valores nulos en datos y DataFrames",
    "section": "",
    "text": "Los valores nulos representan un desafío significativo en la gestión de DataFrames y el análisis de datos. En esta sesión, abordaremos su relevancia y las técnicas efectivas para manejarlos, asegurando así la precisión y fiabilidad de nuestros análisis.\nEl primer paso es la limpieza de datos, un proceso vital que implica la identificación y eliminación de valores nulos, lo que resulta en una mejora sustancial de la calidad de tus conjuntos de datos. Un tratamiento adecuado de los mismos es esencial para garantizar resultados fiables y prevenir errores en tu análisis.\nLos valores nulos no siempre deben ser vistos como simples huecos en tus datos; pueden revelar información crucial sobre tu conjunto de datos. Aprender a interpretar y utilizar esta información puede proporcionar una perspectiva más enriquecedora y completa en tu análisis.\n\n# pip install missingno\n#pip install missingno --upgrade\n\n\nimport pandas as pd\nimport missingno as msno\n\n\nf = \"../data/Cuernavaca_1dia_comas_Nans.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 24 entries, 2012-01-01 00:00:00 to 2012-01-01 23:00:00\nData columns (total 8 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   To           13 non-null     float64\n 1   Ws           24 non-null     float64\n 2   Wd           24 non-null     int64  \n 3   P            24 non-null     int64  \n 4   Ig           24 non-null     int64  \n 5   Ib           24 non-null     int64  \n 6   Id           24 non-null     int64  \n 7   observacion  24 non-null     object \ndtypes: float64(2), int64(5), object(1)\nmemory usage: 1.7+ KB\n\n\n\nf = \"../data/Cuernavaca_1dia_comas_NULOS.csv\"\ncuerna = pd.read_csv(f)\ncuerna.To.mean()\n\nTypeError: Could not convert Nulo18.617.9Nulo16.615.917.018.019.020.020.0NuloNulo22.0NuloNuloNuloNuloNulo17.0Nulo17.016.6Nulo to numeric\n\n\n\nf = \"../data/Cuernavaca_1dia_comas_NULOS.csv\"\ncuerna = pd.read_csv(f,na_values=\"Nulo\")\ncuerna\n\n\n\n\n\n\n\n\n\ntiempo\nTo\nWs\nWd\nP\nIg\nIb\nId\nobservacion\n\n\n\n\n0\n2012-01-01 00:00:00\nNaN\n0.0\n26\n87415\n0\n0\n0\nSí\n\n\n1\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\nNo\n\n\n2\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\nNo\n\n\n3\n2012-01-01 03:00:00\nNaN\n0.0\n30\n87554\n0\n0\n0\nNo\n\n\n4\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\nNo\n\n\n5\n2012-01-01 05:00:00\n15.9\n0.0\n26\n87087\n0\n0\n0\nSí\n\n\n6\n2012-01-01 06:00:00\n17.0\n0.0\n27\n87096\n0\n0\n0\nNo\n\n\n7\n2012-01-01 07:00:00\n18.0\n0.0\n34\n87140\n20\n151\n11\nSí\n\n\n8\n2012-01-01 08:00:00\n19.0\n0.0\n61\n87185\n164\n522\n37\nNo\n\n\n9\n2012-01-01 09:00:00\n20.0\n0.0\n95\n87229\n369\n812\n58\nSí\n\n\n10\n2012-01-01 10:00:00\n20.0\n1.0\n108\n87229\n568\n931\n68\nNo\n\n\n11\n2012-01-01 11:00:00\nNaN\n2.1\n160\n87229\n717\n981\n75\nNo\n\n\n12\n2012-01-01 12:00:00\nNaN\n1.8\n135\n87273\n800\n999\n79\nSí\n\n\n13\n2012-01-01 13:00:00\n22.0\n1.5\n160\n87316\n810\n998\n80\nNo\n\n\n14\n2012-01-01 14:00:00\nNaN\n1.3\n164\n87302\n747\n977\n79\nNo\n\n\n15\n2012-01-01 15:00:00\nNaN\n1.2\n176\n87287\n617\n932\n74\nSí\n\n\n16\n2012-01-01 16:00:00\nNaN\n1.0\n140\n87273\n433\n846\n65\nSí\n\n\n17\n2012-01-01 17:00:00\nNaN\n0.0\n198\n87185\n219\n650\n46\nNo\n\n\n18\n2012-01-01 18:00:00\nNaN\n0.0\n221\n87104\n0\n0\n0\nSí\n\n\n19\n2012-01-01 19:00:00\n17.0\n0.0\n269\n87101\n0\n0\n0\nNo\n\n\n20\n2012-01-01 20:00:00\nNaN\n0.0\n50\n87115\n0\n0\n0\nNo\n\n\n21\n2012-01-01 21:00:00\n17.0\n0.2\n85\n87080\n0\n0\n0\nNo\n\n\n22\n2012-01-01 22:00:00\n16.6\n0.5\n89\n87089\n0\n0\n0\nNo\n\n\n23\n2012-01-01 23:00:00\nNaN\n0.8\n93\n87143\n0\n0\n0\nNo\n\n\n\n\n\n\n\n\n\ncuerna.To\n\n0      NaN\n1     18.6\n2     17.9\n3      NaN\n4     16.6\n5     15.9\n6     17.0\n7     18.0\n8     19.0\n9     20.0\n10    20.0\n11     NaN\n12     NaN\n13    22.0\n14     NaN\n15     NaN\n16     NaN\n17     NaN\n18     NaN\n19    17.0\n20     NaN\n21    17.0\n22    16.6\n23     NaN\nName: To, dtype: float64\n\n\n\nmsno.matrix(cuerna)\n\n\n\n\n\n\n\n\n\nmsno.bar(cuerna,)",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Valores nulos en datos y DataFrames</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/Operaciones_basicas.html",
    "href": "notebooks/semanaUno/Operaciones_basicas.html",
    "title": "15  Operaciones básicas con DataFrames",
    "section": "",
    "text": "En esta sesión, nos veremos operaciones entre columnas utilizando Pandas. Abordaremos desde la creación de nuevas columnas hasta la eliminación de las que ya no necesitamos, destacando las herramientas clave que Pandas pone a nuestra disposición para la manipulación eficaz de datos.\nAprenderás a realizar operaciones matemáticas básicas entre columnas de tu DataFrame, tales como sumar dos columnas para obtener un total o restar una constante. Además, podrás aplicar funciones personalizadas o utilizar las funciones integradas de Pandas para llevar a cabo cálculos más complejos entre columnas, lo que ampliará significativamente las capacidades de tu análisis.\n\nimport pandas as pd\n\n\nf = \"../data/Cuernavaca_1dia_comas.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n\n\n\n\n\n\n\n\n\ncuerna.To\n\ntiempo\n2012-01-01 00:00:00    19.3\n2012-01-01 01:00:00    18.6\n2012-01-01 02:00:00    17.9\n2012-01-01 03:00:00    17.3\n2012-01-01 04:00:00    16.6\n2012-01-01 05:00:00    15.9\n2012-01-01 06:00:00    17.0\n2012-01-01 07:00:00    18.0\n2012-01-01 08:00:00    19.0\n2012-01-01 09:00:00    20.0\n2012-01-01 10:00:00    20.0\n2012-01-01 11:00:00    20.0\n2012-01-01 12:00:00    21.0\n2012-01-01 13:00:00    22.0\n2012-01-01 14:00:00    21.7\n2012-01-01 15:00:00    21.3\n2012-01-01 16:00:00    21.0\n2012-01-01 17:00:00    19.0\n2012-01-01 18:00:00    17.1\n2012-01-01 19:00:00    17.0\n2012-01-01 20:00:00    17.3\n2012-01-01 21:00:00    17.0\n2012-01-01 22:00:00    16.6\n2012-01-01 23:00:00    15.9\nName: To, dtype: float64\n\n\n\ncuerna.To.mean()\n\n18.604166666666668\n\n\n\ncuerna.To.max()\n\n22.0\n\n\n\ncuerna.max()\n\nTo       22.0\nWs        2.1\nWd      269.0\nP     87788.0\nIg      810.0\nIb      999.0\nId       80.0\ndtype: float64\n\n\n\ncuerna[[\"To\",\"Ig\"]].min()\n\nTo    15.9\nIg     0.0\ndtype: float64\n\n\n\ncuerna.Ws.std()\n\n0.6771102280054299\n\n\n\ncuerna.To - cuerna.To.mean()\n\ntiempo\n2012-01-01 00:00:00    0.695833\n2012-01-01 01:00:00   -0.004167\n2012-01-01 02:00:00   -0.704167\n2012-01-01 03:00:00   -1.304167\n2012-01-01 04:00:00   -2.004167\n2012-01-01 05:00:00   -2.704167\n2012-01-01 06:00:00   -1.604167\n2012-01-01 07:00:00   -0.604167\n2012-01-01 08:00:00    0.395833\n2012-01-01 09:00:00    1.395833\n2012-01-01 10:00:00    1.395833\n2012-01-01 11:00:00    1.395833\n2012-01-01 12:00:00    2.395833\n2012-01-01 13:00:00    3.395833\n2012-01-01 14:00:00    3.095833\n2012-01-01 15:00:00    2.695833\n2012-01-01 16:00:00    2.395833\n2012-01-01 17:00:00    0.395833\n2012-01-01 18:00:00   -1.504167\n2012-01-01 19:00:00   -1.604167\n2012-01-01 20:00:00   -1.304167\n2012-01-01 21:00:00   -1.604167\n2012-01-01 22:00:00   -2.004167\n2012-01-01 23:00:00   -2.704167\nName: To, dtype: float64\n\n\n\ncuerna.To **2\n\ntiempo\n2012-01-01 00:00:00    372.49\n2012-01-01 01:00:00    345.96\n2012-01-01 02:00:00    320.41\n2012-01-01 03:00:00    299.29\n2012-01-01 04:00:00    275.56\n2012-01-01 05:00:00    252.81\n2012-01-01 06:00:00    289.00\n2012-01-01 07:00:00    324.00\n2012-01-01 08:00:00    361.00\n2012-01-01 09:00:00    400.00\n2012-01-01 10:00:00    400.00\n2012-01-01 11:00:00    400.00\n2012-01-01 12:00:00    441.00\n2012-01-01 13:00:00    484.00\n2012-01-01 14:00:00    470.89\n2012-01-01 15:00:00    453.69\n2012-01-01 16:00:00    441.00\n2012-01-01 17:00:00    361.00\n2012-01-01 18:00:00    292.41\n2012-01-01 19:00:00    289.00\n2012-01-01 20:00:00    299.29\n2012-01-01 21:00:00    289.00\n2012-01-01 22:00:00    275.56\n2012-01-01 23:00:00    252.81\nName: To, dtype: float64\n\n\n\n(cuerna.To - cuerna.To.mean()).abs()\n\ntiempo\n2012-01-01 00:00:00    0.695833\n2012-01-01 01:00:00    0.004167\n2012-01-01 02:00:00    0.704167\n2012-01-01 03:00:00    1.304167\n2012-01-01 04:00:00    2.004167\n2012-01-01 05:00:00    2.704167\n2012-01-01 06:00:00    1.604167\n2012-01-01 07:00:00    0.604167\n2012-01-01 08:00:00    0.395833\n2012-01-01 09:00:00    1.395833\n2012-01-01 10:00:00    1.395833\n2012-01-01 11:00:00    1.395833\n2012-01-01 12:00:00    2.395833\n2012-01-01 13:00:00    3.395833\n2012-01-01 14:00:00    3.095833\n2012-01-01 15:00:00    2.695833\n2012-01-01 16:00:00    2.395833\n2012-01-01 17:00:00    0.395833\n2012-01-01 18:00:00    1.504167\n2012-01-01 19:00:00    1.604167\n2012-01-01 20:00:00    1.304167\n2012-01-01 21:00:00    1.604167\n2012-01-01 22:00:00    2.004167\n2012-01-01 23:00:00    2.704167\nName: To, dtype: float64\n\n\n\ncuerna[\"To_avg\"]  = cuerna.To.mean() #Esta puede ser con operaciones mas complejas\n\n\ndel cuerna[\"To_avg\"]\n\n\ncuerna.columns\n\nIndex(['To', 'Ws', 'Wd', 'P', 'Ig', 'Ib', 'Id'], dtype='object')\n\n\n\ncuerna[\"To_avg\"]  = cuerna.To.mean() #Esta puede ser con operaciones mas complejas\n\n\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\nTo_avg\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n18.604167\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n18.604167\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n18.604167\n\n\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n18.604167\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n18.604167\n\n\n\n\n\n\n\n\n\ncuerna.drop(columns=[\"To\",\"To_avg\"])\n\n\n\n\n\n\n\n\n\nWs\nWd\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n0.0\n26\n87415\n0\n0\n0\n\n\n2012-01-01 01:00:00\n0.0\n26\n87602\n0\n0\n0\n\n\n2012-01-01 02:00:00\n0.0\n30\n87788\n0\n0\n0\n\n\n2012-01-01 03:00:00\n0.0\n30\n87554\n0\n0\n0\n\n\n2012-01-01 04:00:00\n0.0\n27\n87321\n0\n0\n0\n\n\n2012-01-01 05:00:00\n0.0\n26\n87087\n0\n0\n0\n\n\n2012-01-01 06:00:00\n0.0\n27\n87096\n0\n0\n0\n\n\n2012-01-01 07:00:00\n0.0\n34\n87140\n20\n151\n11\n\n\n2012-01-01 08:00:00\n0.0\n61\n87185\n164\n522\n37\n\n\n2012-01-01 09:00:00\n0.0\n95\n87229\n369\n812\n58\n\n\n2012-01-01 10:00:00\n1.0\n108\n87229\n568\n931\n68\n\n\n2012-01-01 11:00:00\n2.1\n160\n87229\n717\n981\n75\n\n\n2012-01-01 12:00:00\n1.8\n135\n87273\n800\n999\n79\n\n\n2012-01-01 13:00:00\n1.5\n160\n87316\n810\n998\n80\n\n\n2012-01-01 14:00:00\n1.3\n164\n87302\n747\n977\n79\n\n\n2012-01-01 15:00:00\n1.2\n176\n87287\n617\n932\n74\n\n\n2012-01-01 16:00:00\n1.0\n140\n87273\n433\n846\n65\n\n\n2012-01-01 17:00:00\n0.0\n198\n87185\n219\n650\n46\n\n\n2012-01-01 18:00:00\n0.0\n221\n87104\n0\n0\n0\n\n\n2012-01-01 19:00:00\n0.0\n269\n87101\n0\n0\n0\n\n\n2012-01-01 20:00:00\n0.0\n50\n87115\n0\n0\n0\n\n\n2012-01-01 21:00:00\n0.2\n85\n87080\n0\n0\n0\n\n\n2012-01-01 22:00:00\n0.5\n89\n87089\n0\n0\n0\n\n\n2012-01-01 23:00:00\n0.8\n93\n87143\n0\n0\n0\n\n\n\n\n\n\n\n\n\ncuerna\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\nTo_avg\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n18.604167\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n18.604167\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n18.604167\n\n\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n18.604167\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n18.604167\n\n\n2012-01-01 05:00:00\n15.9\n0.0\n26\n87087\n0\n0\n0\n18.604167\n\n\n2012-01-01 06:00:00\n17.0\n0.0\n27\n87096\n0\n0\n0\n18.604167\n\n\n2012-01-01 07:00:00\n18.0\n0.0\n34\n87140\n20\n151\n11\n18.604167\n\n\n2012-01-01 08:00:00\n19.0\n0.0\n61\n87185\n164\n522\n37\n18.604167\n\n\n2012-01-01 09:00:00\n20.0\n0.0\n95\n87229\n369\n812\n58\n18.604167\n\n\n2012-01-01 10:00:00\n20.0\n1.0\n108\n87229\n568\n931\n68\n18.604167\n\n\n2012-01-01 11:00:00\n20.0\n2.1\n160\n87229\n717\n981\n75\n18.604167\n\n\n2012-01-01 12:00:00\n21.0\n1.8\n135\n87273\n800\n999\n79\n18.604167\n\n\n2012-01-01 13:00:00\n22.0\n1.5\n160\n87316\n810\n998\n80\n18.604167\n\n\n2012-01-01 14:00:00\n21.7\n1.3\n164\n87302\n747\n977\n79\n18.604167\n\n\n2012-01-01 15:00:00\n21.3\n1.2\n176\n87287\n617\n932\n74\n18.604167\n\n\n2012-01-01 16:00:00\n21.0\n1.0\n140\n87273\n433\n846\n65\n18.604167\n\n\n2012-01-01 17:00:00\n19.0\n0.0\n198\n87185\n219\n650\n46\n18.604167\n\n\n2012-01-01 18:00:00\n17.1\n0.0\n221\n87104\n0\n0\n0\n18.604167\n\n\n2012-01-01 19:00:00\n17.0\n0.0\n269\n87101\n0\n0\n0\n18.604167\n\n\n2012-01-01 20:00:00\n17.3\n0.0\n50\n87115\n0\n0\n0\n18.604167\n\n\n2012-01-01 21:00:00\n17.0\n0.2\n85\n87080\n0\n0\n0\n18.604167\n\n\n2012-01-01 22:00:00\n16.6\n0.5\n89\n87089\n0\n0\n0\n18.604167\n\n\n2012-01-01 23:00:00\n15.9\n0.8\n93\n87143\n0\n0\n0\n18.604167\n\n\n\n\n\n\n\n\n\ncuerna.drop(columns=[\"To\",\"To_avg\"],inplace=True)\n\n\ncuerna\n\n\n\n\n\n\n\n\n\nWs\nWd\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n0.0\n26\n87415\n0\n0\n0\n\n\n2012-01-01 01:00:00\n0.0\n26\n87602\n0\n0\n0\n\n\n2012-01-01 02:00:00\n0.0\n30\n87788\n0\n0\n0\n\n\n2012-01-01 03:00:00\n0.0\n30\n87554\n0\n0\n0\n\n\n2012-01-01 04:00:00\n0.0\n27\n87321\n0\n0\n0\n\n\n2012-01-01 05:00:00\n0.0\n26\n87087\n0\n0\n0\n\n\n2012-01-01 06:00:00\n0.0\n27\n87096\n0\n0\n0\n\n\n2012-01-01 07:00:00\n0.0\n34\n87140\n20\n151\n11\n\n\n2012-01-01 08:00:00\n0.0\n61\n87185\n164\n522\n37\n\n\n2012-01-01 09:00:00\n0.0\n95\n87229\n369\n812\n58\n\n\n2012-01-01 10:00:00\n1.0\n108\n87229\n568\n931\n68\n\n\n2012-01-01 11:00:00\n2.1\n160\n87229\n717\n981\n75\n\n\n2012-01-01 12:00:00\n1.8\n135\n87273\n800\n999\n79\n\n\n2012-01-01 13:00:00\n1.5\n160\n87316\n810\n998\n80\n\n\n2012-01-01 14:00:00\n1.3\n164\n87302\n747\n977\n79\n\n\n2012-01-01 15:00:00\n1.2\n176\n87287\n617\n932\n74\n\n\n2012-01-01 16:00:00\n1.0\n140\n87273\n433\n846\n65\n\n\n2012-01-01 17:00:00\n0.0\n198\n87185\n219\n650\n46\n\n\n2012-01-01 18:00:00\n0.0\n221\n87104\n0\n0\n0\n\n\n2012-01-01 19:00:00\n0.0\n269\n87101\n0\n0\n0\n\n\n2012-01-01 20:00:00\n0.0\n50\n87115\n0\n0\n0\n\n\n2012-01-01 21:00:00\n0.2\n85\n87080\n0\n0\n0\n\n\n2012-01-01 22:00:00\n0.5\n89\n87089\n0\n0\n0\n\n\n2012-01-01 23:00:00\n0.8\n93\n87143\n0\n0\n0",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Operaciones básicas con DataFrames</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/uso_loc.html",
    "href": "notebooks/semanaUno/uso_loc.html",
    "title": "16  Localizar y reemplazar información en Pandas",
    "section": "",
    "text": "En esta sesión veremos el uso de la función .loc[ ]. Aprenderás a localizar y modificar información dentro de un DataFrame de manera efectiva. Descubrirás cómo seleccionar datos concretos, segmentar secciones específicas y aplicar filtros para ajustarse a tus requerimientos de análisis de datos.\nUtilizala para extraer subconjuntos de filas, eligiendo rangos específicos basados en etiquetas. Establece condiciones para acceder a segmentos del DataFrame que satisfagan criterios definidos, asegurando así la obtención de datos precisos y pertinentes. Prepara tus datos para análisis futuros con .loc[ ], una herramienta esencial para seleccionar, filtrar y modificar la información clave de tu DataFrame.\n\nimport pandas as pd\n\n\nf = \"../data/Cuernavaca_Enero_comas.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n58\n87415\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n59\n87602\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n61\n87788\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n66\n87554\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n71\n87321\n0.0\n27\n0\n0\n0\n\n\n\n\n\n\n\n\n\ncuerna.loc[\"2012-1-2\"]\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-02 00:00:00\n15.1\n40\n87190\n1.0\n91\n0\n0\n0\n\n\n2012-01-02 01:00:00\n14.7\n44\n87280\n1.0\n78\n0\n0\n0\n\n\n2012-01-02 02:00:00\n14.2\n47\n87319\n1.0\n330\n0\n0\n0\n\n\n2012-01-02 03:00:00\n14.2\n49\n87237\n0.8\n69\n0\n0\n0\n\n\n2012-01-02 04:00:00\n14.9\n51\n87179\n0.5\n67\n0\n0\n0\n\n\n2012-01-02 05:00:00\n16.1\n51\n87147\n0.2\n360\n0\n0\n0\n\n\n2012-01-02 06:00:00\n15.0\n55\n87006\n0.0\n71\n0\n0\n0\n\n\n2012-01-02 07:00:00\n17.0\n52\n87095\n0.0\n66\n14\n42\n11\n\n\n2012-01-02 08:00:00\n19.0\n49\n87185\n0.0\n79\n148\n399\n44\n\n\n2012-01-02 09:00:00\n23.0\n36\n87360\n2.1\n160\n347\n679\n68\n\n\n2012-01-02 10:00:00\n23.5\n35\n87381\n1.5\n171\n551\n882\n78\n\n\n2012-01-02 11:00:00\n24.0\n34\n87403\n1.0\n130\n699\n937\n86\n\n\n2012-01-02 12:00:00\n25.5\n30\n87466\n1.0\n191\n783\n959\n90\n\n\n2012-01-02 13:00:00\n27.0\n26\n87530\n1.0\n150\n795\n958\n93\n\n\n2012-01-02 14:00:00\n27.0\n24\n87530\n1.0\n205\n681\n768\n157\n\n\n2012-01-02 15:00:00\n27.0\n23\n87530\n1.0\n150\n553\n712\n154\n\n\n2012-01-02 16:00:00\n26.0\n26\n87488\n0.0\n212\n423\n778\n82\n\n\n2012-01-02 17:00:00\n25.0\n30\n87445\n0.0\n216\n213\n566\n58\n\n\n2012-01-02 18:00:00\n19.4\n45\n86992\n0.4\n229\n0\n0\n0\n\n\n2012-01-02 19:00:00\n18.4\n47\n86893\n0.5\n239\n0\n0\n0\n\n\n2012-01-02 20:00:00\n17.5\n49\n86811\n0.6\n320\n0\n0\n0\n\n\n2012-01-02 21:00:00\n15.9\n53\n87027\n0.6\n244\n0\n0\n0\n\n\n2012-01-02 22:00:00\n14.3\n56\n87121\n0.9\n247\n0\n0\n0\n\n\n2012-01-02 23:00:00\n12.6\n60\n87290\n1.0\n340\n0\n0\n0\n\n\n\n\n\n\n\n\n\ncuerna.loc[\"2012-01-10\":\"2012-01-17\"]\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-10 00:00:00\n16.4\n42\n87080\n1.0\n16\n0\n0\n0\n\n\n2012-01-10 01:00:00\n15.9\n46\n87224\n1.0\n10\n0\n0\n0\n\n\n2012-01-10 02:00:00\n15.5\n50\n87368\n1.0\n270\n0\n0\n0\n\n\n2012-01-10 03:00:00\n15.4\n52\n87277\n0.8\n10\n0\n0\n0\n\n\n2012-01-10 04:00:00\n15.2\n54\n87187\n0.5\n13\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2012-01-17 19:00:00\n20.9\n34\n87273\n0.2\n233\n0\n0\n0\n\n\n2012-01-17 20:00:00\n18.8\n37\n87186\n0.2\n279\n0\n0\n0\n\n\n2012-01-17 21:00:00\n18.3\n38\n87162\n0.3\n314\n0\n0\n0\n\n\n2012-01-17 22:00:00\n17.9\n39\n87137\n0.4\n337\n0\n0\n0\n\n\n2012-01-17 23:00:00\n17.4\n41\n87112\n0.5\n348\n0\n0\n0\n\n\n\n\n192 rows × 8 columns\n\n\n\n\n\n#Si queremos seleccionar donde ocurre algo, por ejemplo donde Ig &gt; 0\ncuerna.Ig&gt;0.\n\ntiempo\n2012-01-01 00:00:00    False\n2012-01-01 01:00:00    False\n2012-01-01 02:00:00    False\n2012-01-01 03:00:00    False\n2012-01-01 04:00:00    False\n                       ...  \n2012-01-31 19:00:00    False\n2012-01-31 20:00:00    False\n2012-01-31 21:00:00    False\n2012-01-31 22:00:00    False\n2012-01-31 23:00:00    False\nName: Ig, Length: 744, dtype: bool\n\n\n\ncuerna.loc[cuerna.Ig&gt;0]\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 07:00:00\n18.0\n70\n87140\n0.0\n34\n20\n151\n11\n\n\n2012-01-01 08:00:00\n19.0\n68\n87185\n0.0\n61\n164\n522\n37\n\n\n2012-01-01 09:00:00\n20.0\n60\n87229\n0.0\n95\n369\n812\n58\n\n\n2012-01-01 10:00:00\n20.0\n64\n87229\n1.0\n108\n568\n931\n68\n\n\n2012-01-01 11:00:00\n20.0\n68\n87229\n2.1\n160\n717\n981\n75\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2012-01-31 13:00:00\n25.0\n19\n87445\n2.6\n180\n878\n990\n90\n\n\n2012-01-31 14:00:00\n26.0\n20\n87488\n3.1\n240\n827\n978\n88\n\n\n2012-01-31 15:00:00\n26.0\n21\n87488\n3.1\n190\n705\n941\n84\n\n\n2012-01-31 16:00:00\n25.0\n22\n87445\n2.6\n210\n523\n872\n75\n\n\n2012-01-31 17:00:00\n23.0\n27\n87360\n0.0\n234\n301\n722\n59\n\n\n\n\n341 rows × 8 columns\n\n\n\n\n\nmascara = cuerna.Ig&gt;0\ncuerna.loc[mascara]\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 07:00:00\n18.0\n70\n87140\n0.0\n34\n20\n151\n11\n\n\n2012-01-01 08:00:00\n19.0\n68\n87185\n0.0\n61\n164\n522\n37\n\n\n2012-01-01 09:00:00\n20.0\n60\n87229\n0.0\n95\n369\n812\n58\n\n\n2012-01-01 10:00:00\n20.0\n64\n87229\n1.0\n108\n568\n931\n68\n\n\n2012-01-01 11:00:00\n20.0\n68\n87229\n2.1\n160\n717\n981\n75\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2012-01-31 13:00:00\n25.0\n19\n87445\n2.6\n180\n878\n990\n90\n\n\n2012-01-31 14:00:00\n26.0\n20\n87488\n3.1\n240\n827\n978\n88\n\n\n2012-01-31 15:00:00\n26.0\n21\n87488\n3.1\n190\n705\n941\n84\n\n\n2012-01-31 16:00:00\n25.0\n22\n87445\n2.6\n210\n523\n872\n75\n\n\n2012-01-31 17:00:00\n23.0\n27\n87360\n0.0\n234\n301\n722\n59\n\n\n\n\n341 rows × 8 columns\n\n\n\n\n\nmascara = (cuerna.Ig&gt;0) & (cuerna.Ws != 0)\ncuerna.loc[mascara]\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 10:00:00\n20.0\n64\n87229\n1.0\n108\n568\n931\n68\n\n\n2012-01-01 11:00:00\n20.0\n68\n87229\n2.1\n160\n717\n981\n75\n\n\n2012-01-01 12:00:00\n21.0\n60\n87273\n1.8\n135\n800\n999\n79\n\n\n2012-01-01 13:00:00\n22.0\n53\n87316\n1.5\n160\n810\n998\n80\n\n\n2012-01-01 14:00:00\n21.7\n53\n87302\n1.3\n164\n747\n977\n79\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2012-01-31 09:00:00\n20.0\n30\n87229\n3.1\n150\n377\n786\n62\n\n\n2012-01-31 13:00:00\n25.0\n19\n87445\n2.6\n180\n878\n990\n90\n\n\n2012-01-31 14:00:00\n26.0\n20\n87488\n3.1\n240\n827\n978\n88\n\n\n2012-01-31 15:00:00\n26.0\n21\n87488\n3.1\n190\n705\n941\n84\n\n\n2012-01-31 16:00:00\n25.0\n22\n87445\n2.6\n210\n523\n872\n75\n\n\n\n\n181 rows × 8 columns\n\n\n\n\n\ncuerna.loc[cuerna.Ig==0,\"Ig\"] = -999\n\n\ncuerna.Ig.plot()\n\n\n\n\n\n\n\n\n\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n58\n87415\n0.0\n26\n-999\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n59\n87602\n0.0\n26\n-999\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n61\n87788\n0.0\n30\n-999\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n66\n87554\n0.0\n30\n-999\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n71\n87321\n0.0\n27\n-999\n0\n0\n\n\n\n\n\n\n\n\n\n# .loc no sirve para localizar columnas, eso se hace directamente\n# cuerna.loc[\"To\"]\n\n\ncuerna[\"To\"]\n\ntiempo\n2012-01-01 00:00:00    19.3\n2012-01-01 01:00:00    18.6\n2012-01-01 02:00:00    17.9\n2012-01-01 03:00:00    17.3\n2012-01-01 04:00:00    16.6\n                       ... \n2012-01-31 19:00:00    17.9\n2012-01-31 20:00:00    16.9\n2012-01-31 21:00:00    16.5\n2012-01-31 22:00:00    16.3\n2012-01-31 23:00:00    16.2\nName: To, Length: 744, dtype: float64",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Localizar y reemplazar información en Pandas</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/warnings.html",
    "href": "notebooks/semanaUno/warnings.html",
    "title": "17  Warnings",
    "section": "",
    "text": "¡Bienvenidos a esta sesión! Hoy vamos a revisar el tema de las advertencias en Pandas y cómo estas afectan tu análisis de datos. Aprenderemos a interpretar los mensajes de alerta que surgen en tu libreta de Jupyter y a manejarlos de manera efectiva.\nLas advertencias en Pandas son más que simples notificaciones; son indicadores cruciales que pueden tener un impacto significativo en tu análisis. Estos mensajes no solo sirven para señalar problemas menores, sino que también son herramientas valiosas que te orientan para identificar posibles inconvenientes y perfeccionar tu código.\nEs importante aprender a identificar advertencias relacionadas con funciones que están quedando obsoletas o que han experimentado cambios en su sintaxis. Esto te permitirá mantener tu código al día y evitar posibles errores en versiones futuras de Pandas.\n\n# pip uninstall pyarrow --y\n\n\nimport pandas as pd\n\n/var/folders/2z/fh3yv7r50rxgy804jm3f7b0c0000gn/T/ipykernel_62846/4080736814.py:1: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n\n\n\nf = \"../data/Cuernavaca_Enero_comas.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n58\n87415\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n59\n87602\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n61\n87788\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n66\n87554\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n71\n87321\n0.0\n27\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2012-01-31 19:00:00\n17.9\n41\n86878\n0.9\n264\n0\n0\n0\n\n\n2012-01-31 20:00:00\n16.9\n44\n86839\n1.0\n269\n0\n0\n0\n\n\n2012-01-31 21:00:00\n16.5\n45\n86887\n1.0\n208\n0\n0\n0\n\n\n2012-01-31 22:00:00\n16.3\n46\n87020\n1.0\n148\n0\n0\n0\n\n\n2012-01-31 23:00:00\n16.2\n45\n87238\n1.0\n170\n0\n0\n0\n\n\n\n\n744 rows × 8 columns\n\n\n\n\n\ncuerna_1dia = cuerna.loc[\"2012-01-01\"]\ncuerna_1dia.tail()\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 19:00:00\n17.0\n69\n87101\n0.0\n269\n0\n0\n0\n\n\n2012-01-01 20:00:00\n17.3\n67\n87115\n0.0\n50\n0\n0\n0\n\n\n2012-01-01 21:00:00\n17.0\n56\n87080\n0.2\n85\n0\n0\n0\n\n\n2012-01-01 22:00:00\n16.6\n49\n87089\n0.5\n89\n0\n0\n0\n\n\n2012-01-01 23:00:00\n15.9\n44\n87143\n0.8\n93\n0\n0\n0\n\n\n\n\n\n\n\n\n\ncuerna_1dia[\"To\"] = 10\ncuerna_1dia\n\n/var/folders/2z/fh3yv7r50rxgy804jm3f7b0c0000gn/T/ipykernel_62846/3724519935.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  cuerna_1dia[\"To\"] = 10\n\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n10\n58\n87415\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 01:00:00\n10\n59\n87602\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 02:00:00\n10\n61\n87788\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 03:00:00\n10\n66\n87554\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 04:00:00\n10\n71\n87321\n0.0\n27\n0\n0\n0\n\n\n2012-01-01 05:00:00\n10\n76\n87087\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 06:00:00\n10\n72\n87096\n0.0\n27\n0\n0\n0\n\n\n2012-01-01 07:00:00\n10\n70\n87140\n0.0\n34\n20\n151\n11\n\n\n2012-01-01 08:00:00\n10\n68\n87185\n0.0\n61\n164\n522\n37\n\n\n2012-01-01 09:00:00\n10\n60\n87229\n0.0\n95\n369\n812\n58\n\n\n2012-01-01 10:00:00\n10\n64\n87229\n1.0\n108\n568\n931\n68\n\n\n2012-01-01 11:00:00\n10\n68\n87229\n2.1\n160\n717\n981\n75\n\n\n2012-01-01 12:00:00\n10\n60\n87273\n1.8\n135\n800\n999\n79\n\n\n2012-01-01 13:00:00\n10\n53\n87316\n1.5\n160\n810\n998\n80\n\n\n2012-01-01 14:00:00\n10\n53\n87302\n1.3\n164\n747\n977\n79\n\n\n2012-01-01 15:00:00\n10\n53\n87287\n1.2\n176\n617\n932\n74\n\n\n2012-01-01 16:00:00\n10\n53\n87273\n1.0\n140\n433\n846\n65\n\n\n2012-01-01 17:00:00\n10\n64\n87185\n0.0\n198\n219\n650\n46\n\n\n2012-01-01 18:00:00\n10\n69\n87104\n0.0\n221\n0\n0\n0\n\n\n2012-01-01 19:00:00\n10\n69\n87101\n0.0\n269\n0\n0\n0\n\n\n2012-01-01 20:00:00\n10\n67\n87115\n0.0\n50\n0\n0\n0\n\n\n2012-01-01 21:00:00\n10\n56\n87080\n0.2\n85\n0\n0\n0\n\n\n2012-01-01 22:00:00\n10\n49\n87089\n0.5\n89\n0\n0\n0\n\n\n2012-01-01 23:00:00\n10\n44\n87143\n0.8\n93\n0\n0\n0\n\n\n\n\n\n\n\n\n\ncuerna_1dia = cuerna.loc[\"2012-01-01\"].copy()\ncuerna_1dia[\"To\"] = 10\n\n\ncuerna.loc[cuerna.To&gt;19,\"RH\"] = 'a' \n\n/var/folders/2z/fh3yv7r50rxgy804jm3f7b0c0000gn/T/ipykernel_62846/2653515496.py:1: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'a' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  cuerna.loc[cuerna.To&gt;19,\"RH\"] = 'a'\n\n\n\ncuerna\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\na\n87415\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n59\n87602\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n61\n87788\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n66\n87554\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n71\n87321\n0.0\n27\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2012-01-31 19:00:00\n17.9\n41\n86878\n0.9\n264\n0\n0\n0\n\n\n2012-01-31 20:00:00\n16.9\n44\n86839\n1.0\n269\n0\n0\n0\n\n\n2012-01-31 21:00:00\n16.5\n45\n86887\n1.0\n208\n0\n0\n0\n\n\n2012-01-31 22:00:00\n16.3\n46\n87020\n1.0\n148\n0\n0\n0\n\n\n2012-01-31 23:00:00\n16.2\n45\n87238\n1.0\n170\n0\n0\n0\n\n\n\n\n744 rows × 8 columns\n\n\n\n\n\ncuerna.RH\n\ntiempo\n2012-01-01 00:00:00     a\n2012-01-01 01:00:00    59\n2012-01-01 02:00:00    61\n2012-01-01 03:00:00    66\n2012-01-01 04:00:00    71\n                       ..\n2012-01-31 19:00:00    41\n2012-01-31 20:00:00    44\n2012-01-31 21:00:00    45\n2012-01-31 22:00:00    46\n2012-01-31 23:00:00    45\nName: RH, Length: 744, dtype: object\n\n\n\nf = \"../data/Cuernavaca_1dia_comas_duplicado.csv\"\n\ndf = pd.read_csv(f,index_col=0,parse_dates=True)\ndf\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n\n\n2012-01-01 05:00:00\n15.9\n0.0\n26\n87087\n0\n0\n0\n\n\n2012-01-01 06:00:00\n17.0\n0.0\n27\n87096\n0\n0\n0\n\n\n2012-01-01 07:00:00\n18.0\n0.0\n34\n87140\n20\n151\n11\n\n\n2012-01-01 08:00:00\n19.0\n0.0\n61\n87185\n164\n522\n37\n\n\n2012-01-01 09:00:00\n20.0\n0.0\n95\n87229\n369\n812\n58\n\n\n2012-01-01 10:00:00\n20.0\n1.0\n108\n87229\n568\n931\n68\n\n\n2012-01-01 11:00:00\n20.0\n2.1\n160\n87229\n717\n981\n75\n\n\n2012-01-01 12:00:00\n21.0\n1.8\n135\n87273\n800\n999\n79\n\n\n2012-01-01 13:00:00\n22.0\n1.5\n160\n87316\n810\n998\n80\n\n\n2012-01-01 14:00:00\n21.7\n1.3\n164\n87302\n747\n977\n79\n\n\n2012-01-01 15:00:00\n21.3\n1.2\n176\n87287\n617\n932\n74\n\n\n2012-01-01 16:00:00\n21.0\n1.0\n140\n87273\n433\n846\n65\n\n\n2012-01-01 17:00:00\n19.0\n0.0\n198\n87185\n219\n650\n46\n\n\n2012-01-01 18:00:00\n17.1\n0.0\n221\n87104\n0\n0\n0\n\n\n2012-01-01 19:00:00\n17.0\n0.0\n269\n87101\n0\n0\n0\n\n\n2012-01-01 20:00:00\n17.3\n0.0\n50\n87115\n0\n0\n0\n\n\n2012-01-01 21:00:00\n17.0\n0.2\n85\n87080\n0\n0\n0\n\n\n2012-01-01 22:00:00\n16.6\n0.5\n89\n87089\n0\n0\n0\n\n\n2012-01-01 23:00:00\n15.9\n0.8\n93\n87143\n0\n0\n0\n\n\n2012-01-01 23:00:00\n15.9\n0.8\n93\n87143\n0\n0\n0\n\n\n\n\n\n\n\n\n\nf = \"../data/Cuernavaca_1dia_comas_duplicado.csv\"\n\ndf = pd.read_csv(f)\ndf.tiempo = pd.to_datetime(df.tiempo,yearfirst=True)\n# df.set_index('tiempo',inplace=True)\ndf.set_index('tiempo',inplace=True,verify_integrity=True)\ndf\n\nValueError: Index has duplicate keys: DatetimeIndex(['2012-01-01 23:00:00'], dtype='datetime64[ns]', name='tiempo', freq=None)\n\n\n\n\nf = \"../data/Cuernavaca_1dia_comas_duplicado.csv\"\n\ndf = pd.read_csv(f)\ndf.tiempo = pd.to_datetime(df.tiempo,yearfirst=True)\n# df.set_index('tiempo',inplace=True)\ndf.drop_duplicates(subset=\"tiempo\",inplace=True,keep=\"first\")\ndf.set_index('tiempo',inplace=True,verify_integrity=True,)\ndf\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n\n\n2012-01-01 05:00:00\n15.9\n0.0\n26\n87087\n0\n0\n0\n\n\n2012-01-01 06:00:00\n17.0\n0.0\n27\n87096\n0\n0\n0\n\n\n2012-01-01 07:00:00\n18.0\n0.0\n34\n87140\n20\n151\n11\n\n\n2012-01-01 08:00:00\n19.0\n0.0\n61\n87185\n164\n522\n37\n\n\n2012-01-01 09:00:00\n20.0\n0.0\n95\n87229\n369\n812\n58\n\n\n2012-01-01 10:00:00\n20.0\n1.0\n108\n87229\n568\n931\n68\n\n\n2012-01-01 11:00:00\n20.0\n2.1\n160\n87229\n717\n981\n75\n\n\n2012-01-01 12:00:00\n21.0\n1.8\n135\n87273\n800\n999\n79\n\n\n2012-01-01 13:00:00\n22.0\n1.5\n160\n87316\n810\n998\n80\n\n\n2012-01-01 14:00:00\n21.7\n1.3\n164\n87302\n747\n977\n79\n\n\n2012-01-01 15:00:00\n21.3\n1.2\n176\n87287\n617\n932\n74\n\n\n2012-01-01 16:00:00\n21.0\n1.0\n140\n87273\n433\n846\n65\n\n\n2012-01-01 17:00:00\n19.0\n0.0\n198\n87185\n219\n650\n46\n\n\n2012-01-01 18:00:00\n17.1\n0.0\n221\n87104\n0\n0\n0\n\n\n2012-01-01 19:00:00\n17.0\n0.0\n269\n87101\n0\n0\n0\n\n\n2012-01-01 20:00:00\n17.3\n0.0\n50\n87115\n0\n0\n0\n\n\n2012-01-01 21:00:00\n17.0\n0.2\n85\n87080\n0\n0\n0\n\n\n2012-01-01 22:00:00\n16.6\n0.5\n89\n87089\n0\n0\n0\n\n\n2012-01-01 23:00:00\n15.9\n0.8\n93\n87143\n0\n0\n0",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Warnings</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/manejo_columnas.html",
    "href": "notebooks/semanaUno/manejo_columnas.html",
    "title": "18  Cambia y localiza nombres de columnas",
    "section": "",
    "text": "En esta sesión, exploraremos cómo renombrar columnas de DataFrames en Pandas.\nDescubre estrategias prácticas para mantener una nomenclatura clara y consistente, vital para la integridad de tus análisis. Aprenderás a mejorar la legibilidad de tus DataFrames con nombres de columnas descriptivos y coherentes para tener una narrativa computacional en tus proyectos.\nUna nomenclatura clara y consistente puede transformar tu análisis de datos para que sea robusto, reproducible y colaborativo.\n\nimport pandas as pd\n\n\nf = \"../data/Cuernavaca_1dia_comas.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n\n\n\n\n\n\n\n\n\ncolumnas = cuerna.columns\ncolumnas\n\nIndex(['To', 'Ws', 'Wd', 'P', 'Ig', 'Ib', 'Id'], dtype='object')\n\n\n\nnombres = {\n    \"Wd\":\"wind_direction\",\n    \"Ws\":\"WindSpeed\"\n}\n\n\ncuerna.rename(columns=nombres)\n\n\n\n\n\n\n\n\n\nTo\nWindSpeed\nwind_direction\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n\n\n2012-01-01 05:00:00\n15.9\n0.0\n26\n87087\n0\n0\n0\n\n\n2012-01-01 06:00:00\n17.0\n0.0\n27\n87096\n0\n0\n0\n\n\n2012-01-01 07:00:00\n18.0\n0.0\n34\n87140\n20\n151\n11\n\n\n2012-01-01 08:00:00\n19.0\n0.0\n61\n87185\n164\n522\n37\n\n\n2012-01-01 09:00:00\n20.0\n0.0\n95\n87229\n369\n812\n58\n\n\n2012-01-01 10:00:00\n20.0\n1.0\n108\n87229\n568\n931\n68\n\n\n2012-01-01 11:00:00\n20.0\n2.1\n160\n87229\n717\n981\n75\n\n\n2012-01-01 12:00:00\n21.0\n1.8\n135\n87273\n800\n999\n79\n\n\n2012-01-01 13:00:00\n22.0\n1.5\n160\n87316\n810\n998\n80\n\n\n2012-01-01 14:00:00\n21.7\n1.3\n164\n87302\n747\n977\n79\n\n\n2012-01-01 15:00:00\n21.3\n1.2\n176\n87287\n617\n932\n74\n\n\n2012-01-01 16:00:00\n21.0\n1.0\n140\n87273\n433\n846\n65\n\n\n2012-01-01 17:00:00\n19.0\n0.0\n198\n87185\n219\n650\n46\n\n\n2012-01-01 18:00:00\n17.1\n0.0\n221\n87104\n0\n0\n0\n\n\n2012-01-01 19:00:00\n17.0\n0.0\n269\n87101\n0\n0\n0\n\n\n2012-01-01 20:00:00\n17.3\n0.0\n50\n87115\n0\n0\n0\n\n\n2012-01-01 21:00:00\n17.0\n0.2\n85\n87080\n0\n0\n0\n\n\n2012-01-01 22:00:00\n16.6\n0.5\n89\n87089\n0\n0\n0\n\n\n2012-01-01 23:00:00\n15.9\n0.8\n93\n87143\n0\n0\n0\n\n\n\n\n\n\n\n\n\ncuerna\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n\n\n2012-01-01 05:00:00\n15.9\n0.0\n26\n87087\n0\n0\n0\n\n\n2012-01-01 06:00:00\n17.0\n0.0\n27\n87096\n0\n0\n0\n\n\n2012-01-01 07:00:00\n18.0\n0.0\n34\n87140\n20\n151\n11\n\n\n2012-01-01 08:00:00\n19.0\n0.0\n61\n87185\n164\n522\n37\n\n\n2012-01-01 09:00:00\n20.0\n0.0\n95\n87229\n369\n812\n58\n\n\n2012-01-01 10:00:00\n20.0\n1.0\n108\n87229\n568\n931\n68\n\n\n2012-01-01 11:00:00\n20.0\n2.1\n160\n87229\n717\n981\n75\n\n\n2012-01-01 12:00:00\n21.0\n1.8\n135\n87273\n800\n999\n79\n\n\n2012-01-01 13:00:00\n22.0\n1.5\n160\n87316\n810\n998\n80\n\n\n2012-01-01 14:00:00\n21.7\n1.3\n164\n87302\n747\n977\n79\n\n\n2012-01-01 15:00:00\n21.3\n1.2\n176\n87287\n617\n932\n74\n\n\n2012-01-01 16:00:00\n21.0\n1.0\n140\n87273\n433\n846\n65\n\n\n2012-01-01 17:00:00\n19.0\n0.0\n198\n87185\n219\n650\n46\n\n\n2012-01-01 18:00:00\n17.1\n0.0\n221\n87104\n0\n0\n0\n\n\n2012-01-01 19:00:00\n17.0\n0.0\n269\n87101\n0\n0\n0\n\n\n2012-01-01 20:00:00\n17.3\n0.0\n50\n87115\n0\n0\n0\n\n\n2012-01-01 21:00:00\n17.0\n0.2\n85\n87080\n0\n0\n0\n\n\n2012-01-01 22:00:00\n16.6\n0.5\n89\n87089\n0\n0\n0\n\n\n2012-01-01 23:00:00\n15.9\n0.8\n93\n87143\n0\n0\n0\n\n\n\n\n\n\n\n\n\ncuerna.rename(columns=nombres,inplace=True)\n\n\ncuerna.columns\n\nIndex(['To', 'WindSpeed', 'wind_direction', 'P', 'Ig', 'Ib', 'Id'], dtype='object')\n\n\n\ncolumnas = cuerna.columns\n\n\nwind = [columna for columna in columnas if \"wind\" in columna]\nwind\n\n['wind_direction']\n\n\n\nwind = [columna for columna in columnas if \"wind\" in columna.lower()]\nwind\n\n['WindSpeed', 'wind_direction']\n\n\n\ncuerna[wind].head()\n\n\n\n\n\n\n\n\n\nWindSpeed\nwind_direction\n\n\ntiempo\n\n\n\n\n\n\n2012-01-01 00:00:00\n0.0\n26\n\n\n2012-01-01 01:00:00\n0.0\n26\n\n\n2012-01-01 02:00:00\n0.0\n30\n\n\n2012-01-01 03:00:00\n0.0\n30\n\n\n2012-01-01 04:00:00\n0.0\n27",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Cambia y localiza nombres de columnas</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaUno/cambia_frecuencia.html",
    "href": "notebooks/semanaUno/cambia_frecuencia.html",
    "title": "19  Cambia la frecuencia de tus datos",
    "section": "",
    "text": "Adentrémonos en la función resample, una herramienta esencial para quienes trabajan con datos y series temporales. En esta sesión, descubrirás cómo cambiar la frecuencia de tus datos temporales, ajustando series de minutos a horas o de días a semanas, abriendo un mundo de posibilidades para un análisis más profundo y significativo.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nf = '../data/Temixco_2018_10Min.csv'\ntmx = pd.read_csv(f,index_col=0,parse_dates=True)\ntmx.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 52560 entries, 2018-01-01 00:00:00 to 2018-12-31 23:50:00\nData columns (total 7 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Ib      52423 non-null  float64\n 1   Ig      52423 non-null  float64\n 2   To      52560 non-null  float64\n 3   RH      52560 non-null  float64\n 4   WS      52560 non-null  float64\n 5   WD      52560 non-null  float64\n 6   P       52560 non-null  float64\ndtypes: float64(7)\nmemory usage: 3.2 MB\n\n\n\ntmx.plot(subplots=True);\n\n\n\n\n\n\n\n\n\ntmx.loc['2018-03-10','To'].plot(subplots=True,figsize=(12,3),style='o');\n\n\n\n\n\n\n\n\n\ntmx[['To']].resample('H').max()\n\n\n\n\n\n\n\n\n\nTo\n\n\ntime\n\n\n\n\n\n2018-01-01 00:00:00\n19.23\n\n\n2018-01-01 01:00:00\n19.25\n\n\n2018-01-01 02:00:00\n18.24\n\n\n2018-01-01 03:00:00\n17.49\n\n\n2018-01-01 04:00:00\n16.58\n\n\n...\n...\n\n\n2018-12-31 19:00:00\n22.39\n\n\n2018-12-31 20:00:00\n19.58\n\n\n2018-12-31 21:00:00\n19.29\n\n\n2018-12-31 22:00:00\n18.94\n\n\n2018-12-31 23:00:00\n18.61\n\n\n\n\n8760 rows × 1 columns\n\n\n\n\n\ntmx[['To']].resample('H',closed=\"right\").max()\n\n\n\n\n\n\n\n\n\nTo\n\n\ntime\n\n\n\n\n\n2017-12-31 23:00:00\n18.70\n\n\n2018-01-01 00:00:00\n19.23\n\n\n2018-01-01 01:00:00\n19.25\n\n\n2018-01-01 02:00:00\n18.24\n\n\n2018-01-01 03:00:00\n17.49\n\n\n...\n...\n\n\n2018-12-31 19:00:00\n21.87\n\n\n2018-12-31 20:00:00\n19.49\n\n\n2018-12-31 21:00:00\n19.11\n\n\n2018-12-31 22:00:00\n18.94\n\n\n2018-12-31 23:00:00\n18.51\n\n\n\n\n8761 rows × 1 columns\n\n\n\n\n\ntmx.loc['2018-03-10','To'].plot(subplots=True,figsize=(12,3),style='.')\ntmx.loc['2018-03-10','To'].resample('H').max().plot(subplots=True,\n                                                    figsize=(12,3),\n                                                    style='o',\n                                                   color='red',\n                                                   alpha=0.7)\n\narray([&lt;Axes: xlabel='time'&gt;], dtype=object)\n\n\n\n\n\n\n\n\n\n\ntmx.loc['2018-03-10','To'].plot(subplots=True,figsize=(12,3),style='.')\ntmx.loc['2018-03-10','To'].resample('H').max().plot(figsize=(12,3),\n                                                    style='o',\n                                                    color='red',\n                                                    alpha=0.7)\ntmx.loc['2018-03-10','To'].resample('H').mean().plot(figsize=(12,3),\n                                                     style='*',\n                                                     color='black',\n                                                     alpha=0.7)\n\n\n\n\n\n\n\n\n\ntmx.To.resample('D').mean()\n\ntime\n2018-01-01    21.073333\n2018-01-02    19.813264\n2018-01-03    19.910069\n2018-01-04    19.705417\n2018-01-05    20.782639\n                ...    \n2018-12-27    20.374861\n2018-12-28    19.778750\n2018-12-29    20.654167\n2018-12-30    20.726944\n2018-12-31    20.230903\nFreq: D, Name: To, Length: 365, dtype: float64\n\n\n\ntmx.To.resample('Y').agg(['mean','std','max','min','sum'])\n\n\n\n\n\n\n\n\n\nmean\nstd\nmax\nmin\nsum\n\n\ntime\n\n\n\n\n\n\n\n\n\n2018-12-31\n22.838098\n4.443339\n35.87\n8.16\n1200370.41\n\n\n\n\n\n\n\n\n\ntmx.To.resample('30S').max()  # min, std, no funciona\n\ntime\n2018-01-01 00:00:00    18.70\n2018-01-01 00:00:30      NaN\n2018-01-01 00:01:00      NaN\n2018-01-01 00:01:30      NaN\n2018-01-01 00:02:00      NaN\n                       ...  \n2018-12-31 23:48:00      NaN\n2018-12-31 23:48:30      NaN\n2018-12-31 23:49:00      NaN\n2018-12-31 23:49:30      NaN\n2018-12-31 23:50:00    17.75\nFreq: 30S, Name: To, Length: 1051181, dtype: float64\n\n\n\ntmx.To.resample('30S').interpolate()\n\ntime\n2018-01-01 00:00:00    18.7000\n2018-01-01 00:00:30    18.7125\n2018-01-01 00:01:00    18.7250\n2018-01-01 00:01:30    18.7375\n2018-01-01 00:02:00    18.7500\n                        ...   \n2018-12-31 23:48:00    17.7980\n2018-12-31 23:48:30    17.7860\n2018-12-31 23:49:00    17.7740\n2018-12-31 23:49:30    17.7620\n2018-12-31 23:50:00    17.7500\nFreq: 30S, Name: To, Length: 1051181, dtype: float64\n\n\n\ntmx.loc['2018-03-10 10:00':'2018-03-10 10:30','To'].resample('30S').interpolate().plot(figsize=(12,3),\n                                                                                       style='o',\n                                                                                       color='red',\n                                                                                       alpha=0.5\n                                                                                      )\ntmx.loc['2018-03-10 10:00':'2018-03-10 10:30','To'].plot(style='*',\n                                                         color='k')",
    "crumbs": [
      "Semana Uno",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Cambia la frecuencia de tus datos</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaDos/semana2.html",
    "href": "notebooks/semanaDos/semana2.html",
    "title": "Semana Dos",
    "section": "",
    "text": "En esta semana aprenderas:\n\nFamiliarizarte con la anatomía de una gráfica en Matplotlib.\nEntender el concepto de figuras y ejes (fig y axis) para crear múltiples gráficos en la misma figura y controlar su disposición y elementos asociados.\nExplorar los diferentes tipos de gráficas que se pueden crear con Matplotlib, desde gráficos de barras hasta gráficos de dispersión.\nCrear la primera gráfica y aprender a visualizar series temporales de manera efectiva.\nAprender a personalizar figuras ajustando colores, etiquetas y estilos para hacer que las visualizaciones sean más claras e informativas.\nExplorar cómo crear múltiples gráficas en una misma figura para comparar datos y patrones en diferentes conjuntos de información.\nAprender a crear gráficas con arreglos avanzados utilizando GridSpec.\nExplorar opciones para hacer gráficas interactivas, permitiendo a los usuarios explorar y analizar datos de manera dinámica, útil en aplicaciones web, análisis de datos avanzados y tableros de información.",
    "crumbs": [
      "Semana Dos"
    ]
  },
  {
    "objectID": "notebooks/semanaDos/IntroMatplotlib.html",
    "href": "notebooks/semanaDos/IntroMatplotlib.html",
    "title": "20  Introducción a Matplotlib",
    "section": "",
    "text": "Bienvenidos a esta sección dedicada a explorar una de las herramientas más poderosas y versátiles en el arsenal de cualquier analista de datos: Matplotlib. En este viaje, nos sumergiremos en el fascinante mundo de la visualización de datos en Python, donde Matplotlib se erige como el campeón indiscutible.\nMatplotlib, una biblioteca robusta y altamente flexible, ideal para descubrir patrones, tendencias y relaciones dentro de nuestros conjuntos de datos. Con su amplio conjunto de funciones y capacidades, Matplotlib nos permite convertir números crudos en imágenes claras para transmitir ideas.\nExploraremos algunas maneras de Matplotlib, desde su capacidad para crear gráficos estáticos hasta sus características avanzadas para generar visualizaciones dinámicas e interactivas. Descubriremos cómo esta herramienta puede convertir datos crudos en obras de arte informativas, desde simples histogramas hasta complejos mapas de calor.\nUna de las características más impresionantes de Matplotlib es su capacidad de personalización sin límites. Desde la elección de colores hasta la disposición de anotaciones, cada aspecto de una visualización puede ser moldeado a nuestro gusto.\nMatplotlib se integra perfectamente con otras bibliotecas de Python, como Pandas, simplificando el proceso de visualización y análisis de datos. Veremos cómo podemos pasar fácilmente DataFrames y Series a Matplotlib, reduciendo la complejidad y la cantidad de código necesarios para generar visualizaciones.\nPero primero lo primero: se dará la serie de comandos necesarios para instalar por primera vez esta librería:\n\nimport matplotlib as mpl\n\n\nmpl.__version__\n\n'3.7.1'\n\n\n\npip install matplotlib\n\nWARNING: The directory '/Users/gbv/Library/Caches/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.7.1)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.1.0)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.40.0)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: numpy&gt;=1.20 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.24.2)\nRequirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (23.0)\nRequirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.1.0)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /Users/gbv/Library/Python/3.10/lib/python/site-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\npip install matplotlib --upgrade\n\n\npip install numpy #se usa en muchos de los ejemplos para crear datos y hacer figuras\n\nmatplotlib",
    "crumbs": [
      "Semana Dos",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introducción a Matplotlib</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaDos/Anatomy_of_a_figure.html",
    "href": "notebooks/semanaDos/Anatomy_of_a_figure.html",
    "title": "21  Anatomía de una gráfica",
    "section": "",
    "text": "En esta sección exploraremos la anatomía de las figuras en Matplotlib, un conocimiento fundamental para cualquier persona que se dedique a la visualización de datos. Descubriremos los componentes básicos de una figura para construir visualizaciones claras y efectivas.\nConocer la anatomía de una figura en Matplotlib es como aprender la gramática antes de escribir una novela; es el primer paso para dominar el arte de la visualización de datos. Desde los ‘Axes’ hasta los ‘Ticks’, cada parte de una figura desempeña un papel crucial en la creación y personalización de gráficos que se ajusten a nuestras necesidades específicas de análisis y formato.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom matplotlib.patches import Circle\nfrom matplotlib.patheffects import withStroke\nfrom matplotlib.ticker import AutoMinorLocator, MultipleLocator\n\nroyal_blue = [0, 20/256, 82/256]\n\n\n# make the figure\n\nnp.random.seed(19680801)\n\nX = np.linspace(0.5, 3.5, 100)\nY1 = 3+np.cos(X)\nY2 = 1+np.cos(1+X/0.75)/2\nY3 = np.random.uniform(Y1, Y2, len(X))\n\nfig = plt.figure(figsize=(7.5, 7.5))\nax = fig.add_axes([0.2, 0.17, 0.68, 0.7], aspect=1)\n\nax.xaxis.set_major_locator(MultipleLocator(1.000))\nax.xaxis.set_minor_locator(AutoMinorLocator(4))\nax.yaxis.set_major_locator(MultipleLocator(1.000))\nax.yaxis.set_minor_locator(AutoMinorLocator(4))\nax.xaxis.set_minor_formatter(\"{x:.2f}\")\n\nax.set_xlim(0, 4)\nax.set_ylim(0, 4)\n\nax.tick_params(which='major', width=1.0, length=10, labelsize=14)\nax.tick_params(which='minor', width=1.0, length=5, labelsize=10,\n               labelcolor='0.25')\n\nax.grid(linestyle=\"--\", linewidth=0.5, color='.25', zorder=-10)\n\nax.plot(X, Y1, c='C0', lw=2.5, label=\"Blue signal\", zorder=10)\nax.plot(X, Y2, c='C1', lw=2.5, label=\"Orange signal\")\nax.plot(X[::3], Y3[::3], linewidth=0, markersize=9,\n        marker='s', markerfacecolor='none', markeredgecolor='C4',\n        markeredgewidth=2.5)\n\nax.set_title(\"Anatomy of a figure\", fontsize=20, verticalalignment='bottom')\nax.set_xlabel(\"x Axis label\", fontsize=14)\nax.set_ylabel(\"y Axis label\", fontsize=14)\nax.legend(loc=\"upper right\", fontsize=14)\n\n\n# Annotate the figure\n\ndef annotate(x, y, text, code):\n    # Circle marker\n    c = Circle((x, y), radius=0.15, clip_on=False, zorder=10, linewidth=2.5,\n               edgecolor=royal_blue + [0.6], facecolor='none',\n               path_effects=[withStroke(linewidth=7, foreground='white')])\n    ax.add_artist(c)\n\n    # use path_effects as a background for the texts\n    # draw the path_effects and the colored text separately so that the\n    # path_effects cannot clip other texts\n    for path_effects in [[withStroke(linewidth=7, foreground='white')], []]:\n        color = 'white' if path_effects else royal_blue\n        ax.text(x, y-0.2, text, zorder=100,\n                ha='center', va='top', weight='bold', color=color,\n                style='italic', fontfamily='monospace',\n                path_effects=path_effects)\n\n        color = 'white' if path_effects else 'black'\n        ax.text(x, y-0.33, code, zorder=100,\n                ha='center', va='top', weight='normal', color=color,\n                fontfamily='monospace', fontsize='medium',\n                path_effects=path_effects)\n\n\nannotate(3.5, -0.13, \"Minor tick label\", \"ax.xaxis.set_minor_formatter\")\nannotate(-0.03, 1.0, \"Major tick\", \"ax.yaxis.set_major_locator\")\nannotate(0.00, 3.75, \"Minor tick\", \"ax.yaxis.set_minor_locator\")\nannotate(-0.15, 3.00, \"Major tick label\", \"ax.yaxis.set_major_formatter\")\nannotate(1.68, -0.39, \"xlabel\", \"ax.set_xlabel\")\nannotate(-0.38, 1.67, \"ylabel\", \"ax.set_ylabel\")\nannotate(1.52, 4.15, \"Title\", \"ax.set_title\")\nannotate(1.75, 2.80, \"Line\", \"ax.plot\")\nannotate(2.25, 1.54, \"Markers\", \"ax.scatter\")\nannotate(3.00, 3.00, \"Grid\", \"ax.grid\")\nannotate(3.60, 3.58, \"Legend\", \"ax.legend\")\nannotate(2.5, 0.55, \"Axes\", \"fig.subplots\")\nannotate(4, 4.5, \"Figure\", \"plt.figure\")\nannotate(0.65, 0.01, \"x Axis\", \"ax.xaxis\")\nannotate(0, 0.36, \"y Axis\", \"ax.yaxis\")\nannotate(4.0, 0.7, \"Spine\", \"ax.spines\")\n\n# frame around figure\nfig.patch.set(linewidth=4, edgecolor='0.5')\nplt.show()",
    "crumbs": [
      "Semana Dos",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Anatomía de una gráfica</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaDos/fig_ax.html",
    "href": "notebooks/semanaDos/fig_ax.html",
    "title": "22  Concepto de figuras y ejes (fig, ax)",
    "section": "",
    "text": "En esta sesión, exploraremos dos enfoques fundamentales para crear gráficos: el rápido y sencillo plt.plot() y la versátil interfaz orientada a objetos con fig y ax. Descubriremos cómo plt.plot() permite trazados rápidos con una sola línea de código, mientras que fig, ax = plt.subplots() ofrece un control y personalización exhaustivos sobre cada aspecto del gráfico.\nDesde entender la diferencia entre la figura completa y los ejes de un gráfico hasta dominar la creación de visualizaciones complejas y compuestas, exploraremos cómo aprovechar al máximo Matplotlib en nuestro análisis de datos.\nAdemás, acompañaremos nuestra exploración con ejemplos prácticos, importando conjuntos de datos y demostrando cómo aplicar estos enfoques dentro de la libreta de Jupyter.\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n\nf = '../data/Cuernavaca_Enero_comas.csv'\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n58\n87415\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n59\n87602\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n61\n87788\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n66\n87554\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n71\n87321\n0.0\n27\n0\n0\n0\n\n\n\n\n\n\n\n\n\nplt.plot()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\n\n\n\n\n\n\n\n\nplt.plot(cuerna.To)\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\nax.plot(cuerna.To)",
    "crumbs": [
      "Semana Dos",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Concepto de figuras y ejes (fig, ax)</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaDos/Tipos_graficos.html",
    "href": "notebooks/semanaDos/Tipos_graficos.html",
    "title": "23  Tipos de gráficas",
    "section": "",
    "text": "En esta sección del curso, exploraremos las técnicas visuales disponibles en Matplotlib para representar datos por pares, o Pairwise data.\nDesde el gráfico de líneas hasta herramientas como fill_between y stackplot, descubriremos cómo cada tipo de gráfico nos brinda una perspectiva única sobre la relación entre dos variables cuantitativas.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom dateutil.parser import parse\n\n\nf = '../data/Cuernavaca_1dia_comas.csv'\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\nax.plot(cuerna.To)\nax.set_title('plot')\n\nText(0.5, 1.0, 'plot')\n\n\n\n\n\n\n\n\n\n\nfig, ax =  plt.subplots()\n\nax.scatter(cuerna.index,cuerna.To)\nax.set_title('Scatter')\n\nText(0.5, 1.0, 'Scatter')\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n# f1 = parse(\"2012-01-01\")\n# f2 = f1 + pd.Timedelta(\"10H\")\n\nax.bar(cuerna.index,cuerna.To)\n# ax.bar(cuerna.index,cuerna.To,width=1/25)\n\nax.set_title('Bars')\n\n\n# ax.set_xlim(f1,f2)\n\nText(0.5, 1.0, 'Bars')\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\nax.stem(cuerna.To)\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\nax.fill_between(cuerna.index,cuerna.To.mean(),cuerna.To)\nax.plot(cuerna.To,'r-')\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\nax.stairs(cuerna.To)\n\n\n\n\n\n\n\n\nPor supuesto hay que escoger cada tipo de gr’afica de acuerdo a los datos y lo que queremos transmitir.\n\nfig, ax = plt.subplots()\n\nax.scatter(cuerna.To, cuerna.Ig)\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\nax.stem(cuerna.To, cuerna.Ig)",
    "crumbs": [
      "Semana Dos",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Tipos de gráficas</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaDos/graficas_individuales.html",
    "href": "notebooks/semanaDos/graficas_individuales.html",
    "title": "24  Gráficas individuales",
    "section": "",
    "text": "En esta sección del curso, revisaremos el uso de dos herramientas clave en la biblioteca de matplotlib: plt.plot() y plt.scatter(). A través de estos métodos, exploraremos cómo generar gráficos de líneas y dispersión de manera rápida y sencilla.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nf = \"../data/Cuernavaca_Enero_comas.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n58\n87415\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n59\n87602\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n61\n87788\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n66\n87554\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n71\n87321\n0.0\n27\n0\n0\n0\n\n\n\n\n\n\n\n\n\nplt.plot(cuerna.To)\n\n\n\n\n\n\n\n\n\nplt.scatter(cuerna.To, cuerna.RH)",
    "crumbs": [
      "Semana Dos",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Gráficas individuales</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaDos/mi_primera_figura.html",
    "href": "notebooks/semanaDos/mi_primera_figura.html",
    "title": "25  Mi primera gráfica temporal",
    "section": "",
    "text": "Bienvenidos a una nueva sesión donde exploraremos una herramienta fundamental de visualización de datos en Python: plt.subplots(). Aprenderemos cómo esta función nos ofrece un control absoluto sobre la creación de figuras de series temporales, permitiéndonos organizar múltiples gráficos de manera eficiente.\nExploraremos como usar ax.scatter, ax.plot para finalizar haciendo una gráfica de datos de una serie temporal con tres componentes de radiación solar.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nf = \"../data/Cuernavaca_Enero_comas.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n58\n87415\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n59\n87602\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n61\n87788\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n66\n87554\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n71\n87321\n0.0\n27\n0\n0\n0\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots() #crea la figura\n\nax.plot(cuerna.To,cuerna.RH)\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots() #crea la figura\n\nax.plot(\"To\",\"RH\",data=cuerna)\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\nax.scatter(cuerna.To,cuerna.RH)\n\n\n\n\n\n\n\n\n\nf = '../data/Cuernavaca_1dia_comas.csv'\ncuerna1dia = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna1dia.head()\n\n\n\n\n\n\n\n\n\nTo\nWs\nWd\nP\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(12,4))\n\nax.plot(cuerna1dia.Ig)\nax.plot(cuerna1dia.Id)\nax.plot(cuerna1dia.Ib)",
    "crumbs": [
      "Semana Dos",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Mi primera gráfica temporal</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaDos/personaliza_figura.html",
    "href": "notebooks/semanaDos/personaliza_figura.html",
    "title": "26  Personaliza tus figuras",
    "section": "",
    "text": "En esta sesión, nos veremos la creación de gráficas con múltiples elementos y totalmente adaptadas a nuestras necesidades.\nAprenderemos a cambiar el tamaño predeterminado de las gráficas, a jugar con los estilos de las líneas y a añadir leyendas a los ejes y etiquetas a las gráficas para mejorar la claridad y la comprensión.\nTambién exploraremos cómo utilizar LaTeX para garantizar que nuestros símbolos y fórmulas sean perfectos en cada representación visual.\n\n\n\nimage.png\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom dateutil.parser import parse\n\n\nf = \"../data/Cuernavaca_Enero_comas.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.index\n\nDatetimeIndex(['2012-01-01 00:00:00', '2012-01-01 01:00:00',\n               '2012-01-01 02:00:00', '2012-01-01 03:00:00',\n               '2012-01-01 04:00:00', '2012-01-01 05:00:00',\n               '2012-01-01 06:00:00', '2012-01-01 07:00:00',\n               '2012-01-01 08:00:00', '2012-01-01 09:00:00',\n               ...\n               '2012-01-31 14:00:00', '2012-01-31 15:00:00',\n               '2012-01-31 16:00:00', '2012-01-31 17:00:00',\n               '2012-01-31 18:00:00', '2012-01-31 19:00:00',\n               '2012-01-31 20:00:00', '2012-01-31 21:00:00',\n               '2012-01-31 22:00:00', '2012-01-31 23:00:00'],\n              dtype='datetime64[ns]', name='tiempo', length=744, freq=None)\n\n\n\nfig, ax = plt.subplots()\n\nax.plot(cuerna.Ig)\nax.plot(cuerna.Ib)\nax.plot(cuerna.Id)\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\nf1 = parse(\"2012-01-10\")\nf2 = f1 + pd.Timedelta(\"1d\")\n\nax.plot(cuerna.Ig)\nax.plot(cuerna.Ib)\nax.plot(cuerna.Id)\n\nax.set_xlim(f1,f2)\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\nf1 = parse(\"2012-01-10\")\nf2 = f1 + pd.Timedelta(\"1d\")\n\nax.plot(cuerna.Ig,label=\"Ig\")\nax.plot(cuerna.Ib,label=\"Ib\")\nax.plot(cuerna.Id,label=\"Id\")\n\nax.legend()\nax.set_xlim(f1,f2)\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10,4))\n\nf1 = parse(\"2012-01-10\")\nf2 = f1 + pd.Timedelta(\"1d\")\n\nax.plot(cuerna.Ig,label=\"Ig\")\nax.plot(cuerna.Ib,label=\"Ib\")\nax.plot(cuerna.Id,label=\"Id\")\n\nax.legend()\nax.set_xlim(f1,f2)\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10,4))\n\nf1 = parse(\"2012-01-10\")\nf2 = f1 + pd.Timedelta(\"1d\")\n\nax.plot(cuerna.Ig,label=\"Ig\")\nax.plot(cuerna.Ib,label=\"Ib\")\nax.plot(cuerna.Id,label=\"Id\")\n\nax.legend()\nax.grid()\nax.set_xlim(f1,f2)\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10,4))\n\nf1 = parse(\"2012-01-10\")\nf2 = f1 + pd.Timedelta(\"1d\")\n\nax.plot(cuerna.Ig,label=\"Ig\")\nax.plot(cuerna.Ib,label=\"Ib\")\nax.plot(cuerna.Id,label=\"Id\")\n\nax.legend()\nax.grid()\nax.set_xlim(f1,f2)\nax.set_ylabel(\"Irradiancia [$W/m^2$]\")\nax.set_xlabel(\"Tiempo [mm-dd HH]\")\nax.set_title(\"Irradiancia en Cuernavaca\")\n\nText(0.5, 1.0, 'Irradiancia en Cuernavaca')\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10,4))\n\nf1 = parse(\"2012-01-10\")\nf2 = f1 + pd.Timedelta(\"1d\")\n\nax.plot(cuerna.Ig,\"r-\", label=\"Ig\")\nax.plot(cuerna.Ib,\"k--\",label=\"Ib\")\nax.plot(cuerna.Id,\"bo-\",label=\"Id\")\n\nax.legend()\nax.grid()\nax.set_xlim(f1,f2)\nax.set_ylabel(\"Irradiancia [$W/m^2$]\")\nax.set_xlabel(\"Tiempo [mm-dd HH]\")\nax.set_title(\"Irradiancia en Cuernavaca\")\n\nText(0.5, 1.0, 'Irradiancia en Cuernavaca')",
    "crumbs": [
      "Semana Dos",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Personaliza tus figuras</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaDos/multiples_graficas.html",
    "href": "notebooks/semanaDos/multiples_graficas.html",
    "title": "27  Múltiples gráficas",
    "section": "",
    "text": "En esta sesión daremos un paso adelante en nuestra comprensión de la representación gráfica de datos al aprender cómo crear una gráfica con múltiples subgráficos.\nA través de plt.subplots() estableceremos una estructura organizada donde cada eje representa un espacio único para un gráfico individual.\nEsta disposición nos permitirá explorar nuestros datos de manera más profunda, identificando correlaciones y patrones de manera visual.\n\n\n\nimage.png\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom dateutil.parser import parse\n\n\nf = \"../data/Cuernavaca_Enero_comas.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.index\n\nDatetimeIndex(['2012-01-01 00:00:00', '2012-01-01 01:00:00',\n               '2012-01-01 02:00:00', '2012-01-01 03:00:00',\n               '2012-01-01 04:00:00', '2012-01-01 05:00:00',\n               '2012-01-01 06:00:00', '2012-01-01 07:00:00',\n               '2012-01-01 08:00:00', '2012-01-01 09:00:00',\n               ...\n               '2012-01-31 14:00:00', '2012-01-31 15:00:00',\n               '2012-01-31 16:00:00', '2012-01-31 17:00:00',\n               '2012-01-31 18:00:00', '2012-01-31 19:00:00',\n               '2012-01-31 20:00:00', '2012-01-31 21:00:00',\n               '2012-01-31 22:00:00', '2012-01-31 23:00:00'],\n              dtype='datetime64[ns]', name='tiempo', length=744, freq=None)\n\n\n\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n58\n87415\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n59\n87602\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n61\n87788\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n66\n87554\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n71\n87321\n0.0\n27\n0\n0\n0\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(2,figsize=(10,4),sharex=True)\n\nf1 = parse(\"2012-01-18\")\nf2 = f1 + pd.Timedelta(\"3d12h\")\n\nax[0].plot(cuerna.Ig,label=\"Ig\")\nax[0].plot(cuerna.Ib,label=\"Ib\")\nax[0].plot(cuerna.Id,label=\"Id\")\n\nax[1].plot(cuerna.To,label=\"To\")\n\nax[0].set_xlim(f1,f2)\nax[0].legend()\n# ax[0].grid()\nax[0].set_ylabel(\"Irradiancia[$W/m^2$]\")\nax[0].set_ylim(0,1200)\n\nax[1].legend()\nax[1].set_xlabel(\"Tiempo [mm-dd HH]\")\nax[1].set_ylabel(\"Temperatura [$^oC$]\")\nax[1].set_ylim(0,30)\n# ax[1].grid()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(2,figsize=(10,4),sharex=True)\n\nf1 = parse(\"2012-01-18\")\nf2 = f1 + pd.Timedelta(\"3d12h\")\n\nax1.plot(cuerna.Ig,label=\"Ig\")\nax1.plot(cuerna.Ib,label=\"Ib\")\nax1.plot(cuerna.Id,label=\"Id\")\n\nax2.plot(cuerna.To,label=\"To\")\n\nax1.set_xlim(f1,f2)\nax1.legend()\nax1.set_ylabel(\"Irradiancia[$W/m^2$]\")\n\nax2.legend()\nax2.set_xlabel(\"Tiempo [mm-dd HH]\")\nax2.set_ylabel(\"Temperatura [$^oC$]\")\n\nText(0, 0.5, 'Temperatura [$^oC$]')",
    "crumbs": [
      "Semana Dos",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Múltiples gráficas</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaDos/gridspec.html",
    "href": "notebooks/semanaDos/gridspec.html",
    "title": "28  Múltiples gráficas con patrones complejos",
    "section": "",
    "text": "En esta sesión, se explorará la herramienta GridSpec, la cual no solo nos permite crear gráficos complejos, sino que también nos otorga un control sin igual sobre la disposición y el tamaño de los subplots dentro de una figura. En conjunto, aprenderemos cómo esta herramienta puede mejorar nuestras composiciones gráficas, permitiéndonos diseñar visualizaciones que se adapten perfectamente a nuestras necesidades.\n\n\n\nimage.png\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom dateutil.parser import parse\n\n\nf = \"../data/Cuernavaca_Enero_comas.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.index\n\nDatetimeIndex(['2012-01-01 00:00:00', '2012-01-01 01:00:00',\n               '2012-01-01 02:00:00', '2012-01-01 03:00:00',\n               '2012-01-01 04:00:00', '2012-01-01 05:00:00',\n               '2012-01-01 06:00:00', '2012-01-01 07:00:00',\n               '2012-01-01 08:00:00', '2012-01-01 09:00:00',\n               ...\n               '2012-01-31 14:00:00', '2012-01-31 15:00:00',\n               '2012-01-31 16:00:00', '2012-01-31 17:00:00',\n               '2012-01-31 18:00:00', '2012-01-31 19:00:00',\n               '2012-01-31 20:00:00', '2012-01-31 21:00:00',\n               '2012-01-31 22:00:00', '2012-01-31 23:00:00'],\n              dtype='datetime64[ns]', name='tiempo', length=744, freq=None)\n\n\n\ncuerna.columns\n\nIndex(['To', 'RH', 'P', 'Ws', 'Wd', 'Ig', 'Ib', 'Id'], dtype='object')\n\n\n\nfig = plt.figure(figsize=(10,4))\ngs = gridspec.GridSpec(2, 2)\n\nax1  = fig.add_subplot(gs[0,:])\nax2 = fig.add_subplot(gs[1,:1])\nax3 = fig.add_subplot(gs[1,1:])\n\n\n\nax1.plot(cuerna.To)\n\nax2.scatter(cuerna.To,cuerna.RH)\n\nax3.plot(cuerna.Ig)\nax3.plot(cuerna.Id)\nax3.plot(cuerna.Ib)\nf1 = parse(\"2012-01-01\")\nf2 = f1 + pd.Timedelta(\"1D\")\nax3.set_xlim(f1,f2)",
    "crumbs": [
      "Semana Dos",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Múltiples gráficas con patrones complejos</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaDos/graficas_interactivas.html",
    "href": "notebooks/semanaDos/graficas_interactivas.html",
    "title": "29  Gráficas interactivas con ipywidgets",
    "section": "",
    "text": "Estas herramientas interactivas en HTML nos permiten llevar nuestra exploración de datos al siguiente nivel, todo mientras permanecemos dentro del entorno familiar de Jupyter. Desde simples deslizadores hasta botones y casillas de verificación, ipywidgets nos brinda la capacidad de interactuar en tiempo real con nuestros datos.\nIpywidgets solo funciona en el entorno de Jupyter Notebook, así que ten cuidado si estás usando JupyterLab u otro IDE.\n\n# pip install ipywidgets --upgrade --user\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, widgets\n\n\ndef f(x):\n    return print(f\"el numero es {x}\")\n\n\ninteract(f,x=-10)\n\n\nf = \"../data/Cuernavaca_Enero_comas.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.head()\n\n\n\n\n\n\n\n\n\nTo\nRH\nP\nWs\nWd\nIg\nIb\nId\n\n\ntiempo\n\n\n\n\n\n\n\n\n\n\n\n\n2012-01-01 00:00:00\n19.3\n58\n87415\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 01:00:00\n18.6\n59\n87602\n0.0\n26\n0\n0\n0\n\n\n2012-01-01 02:00:00\n17.9\n61\n87788\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 03:00:00\n17.3\n66\n87554\n0.0\n30\n0\n0\n0\n\n\n2012-01-01 04:00:00\n16.6\n71\n87321\n0.0\n27\n0\n0\n0\n\n\n\n\n\n\n\n\n\ndef grafica_serie(start, end):\n    # Filtrar la serie temporal por el rango de fechas\n    filtrado = cuerna[start:end]\n    \n    # Graficar la serie temporal filtrada\n    fig, ax = plt.subplots(figsize=(10, 5))\n    ax.plot(filtrado.To)\n    ax.set_xlabel('Fecha')\n    ax.set_ylabel('Valor')\n    ax.grid()\n\n\ninicio_picker = widgets.DatePicker(description='Fecha inicio', value=pd.to_datetime('2012-01-01'))\nfin_picker    = widgets.DatePicker(description='Fecha fin'   , value=pd.to_datetime('2012-01-31'))\n\n\nwidgets.interact(grafica_serie, start=inicio_picker, end=fin_picker)\n\n\n\n\n&lt;function __main__.grafica_serie(start, end)&gt;",
    "crumbs": [
      "Semana Dos",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Gráficas interactivas con ipywidgets</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaDos/prepara_figura.html",
    "href": "notebooks/semanaDos/prepara_figura.html",
    "title": "30  Prepara tu figura para publicación",
    "section": "",
    "text": "En el mundo de la investigación académica y científica, la presentación de figuras con calidad de impresión es fundamental para transmitir de manera efectiva los hallazgos y resultados. En esta sesión veremos el proceso de exportación de figuras utilizando las Matplotlib. Aprenderemos a especificar los puntos por pulgada para garantizar la nitidez y claridad de nuestras figuras en cualquier formato de impresión. Además, exploraremos cómo exportar estas figuras en dos formatos ampliamente utilizados: PDF y PNG. Estas habilidades son esenciales para presentar tus gráficos de manera profesional en tus publicaciones, asegurando que tus ideas sean comunicadas de manera efectiva.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom dateutil.parser import parse\n\n\nf = \"../data/Cuernavaca_Enero_comas.csv\"\ncuerna = pd.read_csv(f,index_col=0,parse_dates=True)\ncuerna.index\n\nDatetimeIndex(['2012-01-01 00:00:00', '2012-01-01 01:00:00',\n               '2012-01-01 02:00:00', '2012-01-01 03:00:00',\n               '2012-01-01 04:00:00', '2012-01-01 05:00:00',\n               '2012-01-01 06:00:00', '2012-01-01 07:00:00',\n               '2012-01-01 08:00:00', '2012-01-01 09:00:00',\n               ...\n               '2012-01-31 14:00:00', '2012-01-31 15:00:00',\n               '2012-01-31 16:00:00', '2012-01-31 17:00:00',\n               '2012-01-31 18:00:00', '2012-01-31 19:00:00',\n               '2012-01-31 20:00:00', '2012-01-31 21:00:00',\n               '2012-01-31 22:00:00', '2012-01-31 23:00:00'],\n              dtype='datetime64[ns]', name='tiempo', length=744, freq=None)\n\n\n\nfig, ax = plt.subplots(figsize=(6,3))\n\nf1 = parse(\"2012-01-10\")\nf2 = f1 + pd.Timedelta(\"1d\")\n\nax.plot(cuerna.Ig,\"r-\", label=\"Ig\")\nax.plot(cuerna.Ib,\"k--\",label=\"Ib\")\nax.plot(cuerna.Id,\"bo-\",label=\"Id\")\n\nax.legend()\nax.grid()\nax.set_xlim(f1,f2)\n\nax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(mdates.AutoDateLocator()))\nax.set_ylabel(\"Irradiancia [$W/m^2$]\")\nax.set_xlabel(\"Tiempo\")\nax.set_title(\"Irradiancia en Cuernavaca\")\nfig.tight_layout()\n\nfig.savefig(\"../figs/irradiancia.png\",dpi=200)\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(6,3))\n\nf1 = parse(\"2012-01-10\")\nf2 = f1 + pd.Timedelta(\"1d\")\n\nax.plot(cuerna.Ig,\"r-\", label=\"Ig\")\nax.plot(cuerna.Ib,\"k--\",label=\"Ib\")\nax.plot(cuerna.Id,\"bo-\",label=\"Id\")\n\nax.legend()\nax.grid()\nax.set_xlim(f1,f2)\n\nax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(mdates.AutoDateLocator()))\nax.set_ylabel(\"Irradiancia [$W/m^2$]\")\nax.set_xlabel(\"Tiempo\")\nax.set_title(\"Irradiancia en Cuernavaca\")\nfig.tight_layout()\n\nfig.savefig(\"../figs/irradiancia.pdf\",dpi=200)",
    "crumbs": [
      "Semana Dos",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Prepara tu figura para publicación</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaTres/semana3.html",
    "href": "notebooks/semanaTres/semana3.html",
    "title": "Semana Tres",
    "section": "",
    "text": "¡Hola a todes! En esta tercera semana de nuestro curso, estudiaremos NumPy, la biblioteca esencial para la computación numérica en Python. Descubriremos cómo NumPy revoluciona la manipulación de datos con sus poderosos arrays, superando las limitaciones de las listas convencionales de Python. Desde la importación de datos hasta la transformación y procesamiento de imágenes, exploraremos cada faceta de esta poderosa herramienta, brindándote las habilidades esenciales para la ciencia de datos.\nDurante esta semana de nuestro curso, exploraremos una serie de temas fundamentales en el uso de NumPy, empezando por su introducción y el manejo de arrays, seguido de la importación de archivos de datos y la exploración de atributos y propiedades de los arrays. Avanzaremos hacia operaciones básicas, como cálculos aritméticos, y aprenderemos a utilizar el slicing para extraer subconjuntos de datos. Además, nos sumergiremos en el mundo de las imágenes como arrays multidimensionales, y aprenderemos a crear datos con arange y linspace, así como a transformar su forma. No nos olvidaremos de la importancia de guardar nuestros datos procesados con NumPy, ni de explorar herramientas esenciales como meshgrid. Finalmente, cerraremos la semana explorando las herramientas de álgebra lineal de NumPy, fundamentales para la modelación matemática y la resolución de sistemas de ecuaciones, así como para otras áreas como el machine learning.",
    "crumbs": [
      "Semana Tres"
    ]
  },
  {
    "objectID": "notebooks/semanaTres/Instala_Numpy_array.html",
    "href": "notebooks/semanaTres/Instala_Numpy_array.html",
    "title": "31  Introducción a NumPy y arrays",
    "section": "",
    "text": "¿Listes para explorar NumPy? La biblioteca esencial de Python que ha revolucionado el análisis y la manipulación de datos numéricos.\nDesde la creación de arrays hasta la optimización de operaciones numéricas, exploraremos cada rincón de NumPy. Te guiaremos desde los fundamentos, como la definición de arrays, hasta las técnicas avanzadas que te permitirán realizar operaciones matemáticas y estadísticas con una eficiencia sin precedentes.\nA medida que nos sumergimos en las profundidades de NumPy, descubrirás cómo los arrays y las herramientas avanzadas pueden potenciar tu análisis de datos, llevándolo a un nivel más alto. Configura tu entorno Python y acompáñanos en este viaje hacia el dominio total de NumPy, donde cada función y método abre un nuevo camino hacia el conocimiento en la ciencia de datos.\n\nimport numpy as np\n\n\npip install numpy\n\nRequirement already satisfied: numpy in /Users/gbv/virtualenvs/alldays/alldays/lib/python3.10/site-packages (1.24.2)\n\n[notice] A new release of pip is available: 23.1.2 -&gt; 23.3.2\n[notice] To update, run: pip install --upgrade pip\nNote: you may need to restart the kernel to use updated packages.\n\n\n\npip install numpy --upgrade\n\n\nnp.__version__\n\n'1.24.2'\n\n\nnumpy.org\n\na1 = np.array([1])\n\n\ntype(a1)\n\nnumpy.ndarray\n\n\n\na2 = np.array([2])\n\n\na1+a2\n\narray([3])\n\n\n\na1*a2\n\narray([2])\n\n\n\na2**a1\n\narray([2])\n\n\n\na3 = np.array([1,2,3])\na3\n\narray([1, 2, 3])\n\n\n\na4 = np.array(\n    [\n        [1,2,3],\n        [4,5,6]\n    ]\n)\na4\n\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n\n\nlista = [\n    [1,2,3],\n    [4,5,6],\n    [7,8,9]\n]\nnp.array(lista)\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\n\n\nlista = [[1,2,3],[4,5,6],[7,8,9]] # 3 listas en una lista\nnp.array(lista)\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])",
    "crumbs": [
      "Semana Tres",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Introducción a NumPy y arrays</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaTres/Carga_datos_numpy.html",
    "href": "notebooks/semanaTres/Carga_datos_numpy.html",
    "title": "32  Importar archivos con NumPy",
    "section": "",
    "text": "¿Preparades para explorar las opciones de carga de datos en NumPy? En esta sesión nos sumergiremos en las profundidades de las funciones loadtxt y genfromtxt, dos pilares fundamentales para la importación de datos en esta poderosa biblioteca.\nCon loadtxt, experimentarás la simplicidad y la velocidad al trabajar con datos homogéneos. Esta función es ideal para cargar datos simples y uniformes, permitiéndote un flujo de trabajo ágil y sin complicaciones. Por otro lado, genfromtxt se destaca por su capacidad para manejar la complejidad. Ya sea que estés lidiando con valores faltantes o estructuras irregulares, esta herramienta se adapta a tus necesidades, ofreciendo una flexibilidad inigualable.\nA lo largo de esta sesión, no solo identificarás las características únicas de tus datos, sino que también aprenderás a seleccionar la herramienta adecuada para cada escenario. Al final de la sesión, tendrás el conocimiento para decidir cuál función se alinea mejor con tus objetivos analíticos, optimizando así tu flujo de trabajo en el análisis de datos.\n\nimport numpy as np\n\n\nf   = '../data/matriz3x3.txt'\nm3x3 = np.loadtxt(f)\nm3x3\n\narray([[1.   , 0.674, 0.392],\n       [0.183, 1.   , 0.729],\n       [0.438, 0.255, 1.   ]])\n\n\n\ntype(m3x3[0,0])\n\nnumpy.float64\n\n\n\nm3x3[0]\n\narray([1.   , 0.674, 0.392])\n\n\n\nm3x3[0][0]\n\n1.0\n\n\n\ntype(m3x3[0][0])\n\nnumpy.float64\n\n\n\nf = '../data/matriz10x10.txt'\nm10x10 = np.genfromtxt(f)\nm10x10\n\narray([[1.        , 0.891773  , 0.96366276, 0.38344152, 0.79172504,\n        0.52889492, 0.56804456, 0.92559664, 0.07103606, 0.0871293 ],\n       [0.0202184 , 1.        , 0.77815675, 0.87001215, 0.97861834,\n        0.79915856, 0.46147936, 0.78052918, 0.11827443, 0.63992102],\n       [0.14335329, 0.94466892, 1.        , 0.41466194, 0.26455561,\n        0.77423369, 0.45615033, 0.56843395, 0.0187898 , 0.6176355 ],\n       [0.61209572, 0.616934  , 0.94374808, 1.        , 0.3595079 ,\n        0.43703195, 0.6976312 , 0.06022547, 0.66676672, 0.67063787],\n       [0.21038256, 0.1289263 , 0.31542835, 0.36371077, 1.        ,\n        0.43860151, 0.98837384, 0.10204481, 0.20887676, 0.16130952],\n       [0.65310833, 0.2532916 , 0.46631077, 0.24442559, 0.15896958,\n        1.        , 0.65632959, 0.13818295, 0.19658236, 0.36872517],\n       [0.82099323, 0.09710128, 0.83794491, 0.09609841, 0.97645947,\n        0.4686512 , 1.        , 0.60484552, 0.73926358, 0.03918779],\n       [0.28280696, 0.12019656, 0.2961402 , 0.11872772, 0.31798318,\n        0.41426299, 0.0641475 , 1.        , 0.56660145, 0.26538949],\n       [0.52324805, 0.09394051, 0.5759465 , 0.9292962 , 0.31856895,\n        0.66741038, 0.13179786, 0.7163272 , 1.        , 0.18319136],\n       [0.58651293, 0.02010755, 0.82894003, 0.00469548, 0.67781654,\n        0.27000797, 0.73519402, 0.96218855, 0.24875314, 1.        ]])\n\n\n\nnp.loadtxt(f)\n\narray([[1.        , 0.891773  , 0.96366276, 0.38344152, 0.79172504,\n        0.52889492, 0.56804456, 0.92559664, 0.07103606, 0.0871293 ],\n       [0.0202184 , 1.        , 0.77815675, 0.87001215, 0.97861834,\n        0.79915856, 0.46147936, 0.78052918, 0.11827443, 0.63992102],\n       [0.14335329, 0.94466892, 1.        , 0.41466194, 0.26455561,\n        0.77423369, 0.45615033, 0.56843395, 0.0187898 , 0.6176355 ],\n       [0.61209572, 0.616934  , 0.94374808, 1.        , 0.3595079 ,\n        0.43703195, 0.6976312 , 0.06022547, 0.66676672, 0.67063787],\n       [0.21038256, 0.1289263 , 0.31542835, 0.36371077, 1.        ,\n        0.43860151, 0.98837384, 0.10204481, 0.20887676, 0.16130952],\n       [0.65310833, 0.2532916 , 0.46631077, 0.24442559, 0.15896958,\n        1.        , 0.65632959, 0.13818295, 0.19658236, 0.36872517],\n       [0.82099323, 0.09710128, 0.83794491, 0.09609841, 0.97645947,\n        0.4686512 , 1.        , 0.60484552, 0.73926358, 0.03918779],\n       [0.28280696, 0.12019656, 0.2961402 , 0.11872772, 0.31798318,\n        0.41426299, 0.0641475 , 1.        , 0.56660145, 0.26538949],\n       [0.52324805, 0.09394051, 0.5759465 , 0.9292962 , 0.31856895,\n        0.66741038, 0.13179786, 0.7163272 , 1.        , 0.18319136],\n       [0.58651293, 0.02010755, 0.82894003, 0.00469548, 0.67781654,\n        0.27000797, 0.73519402, 0.96218855, 0.24875314, 1.        ]])\n\n\n\nf = '../data/matriz3x3_comment01.txt'\nnp.loadtxt(f)\n\narray([[1.   , 0.674, 0.392],\n       [0.183, 1.   , 0.729],\n       [0.438, 0.255, 1.   ]])\n\n\n\nf = '../data/matriz3x3_comment02.txt'\nnp.loadtxt(f)\n\nValueError: could not convert string '--' to float64 at row 0, column 1.\n\n\n\nf = '../data/matriz3x3_comment02.txt'\nnp.loadtxt(f,comments='--')\n\narray([[1.   , 0.674, 0.392],\n       [0.183, 1.   , 0.729],\n       [0.438, 0.255, 1.   ]])\n\n\n\nf = '../data/matriz3x3_comment02.txt'\nnp.loadtxt(f,skiprows=1)\n\narray([[1.   , 0.674, 0.392],\n       [0.183, 1.   , 0.729],\n       [0.438, 0.255, 1.   ]])\n\n\n\nf = '../data/matriz3x3_comment02.txt'\nnp.loadtxt(f,skiprows=1,usecols=[0])\n\narray([1.   , 0.183, 0.438])\n\n\n\nf = '../data/matriz3x3_comment02.txt'\nnp.loadtxt(f,skiprows=1,usecols=[0,2])\n\narray([[1.   , 0.392],\n       [0.183, 0.729],\n       [0.438, 1.   ]])\n\n\n\nf = '../data/matriz3x3_faltantes.txt'\nnp.loadtxt(f)\n\nValueError: could not convert string 'Nulo' to float64 at row 1, column 2.\n\n\n\nf = '../data/matriz3x3_faltantes.txt'\nnp.genfromtxt(f)\n\narray([[1.   , 0.674, 0.392],\n       [0.183,   nan, 0.729],\n       [0.438, 0.255, 1.   ]])\n\n\n\nf = '../data/matriz3x3_faltantes.txt'\nnp.genfromtxt(f,filling_values=0)\n\narray([[1.   , 0.674, 0.392],\n       [0.183, 0.   , 0.729],\n       [0.438, 0.255, 1.   ]])",
    "crumbs": [
      "Semana Tres",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Importar archivos con NumPy</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaTres/caracteristicas_arrays.html",
    "href": "notebooks/semanaTres/caracteristicas_arrays.html",
    "title": "33  Atributos y propiedades de arrays",
    "section": "",
    "text": "¡Bienvenides a esta sesión dedicada a explorar tres atributos fundamentales de los arreglos en NumPy! Hoy nos sumergiremos en los conceptos de ndim, shape y size, que son esenciales para comprender la estructura y las dimensiones de los arreglos en NumPy.\nEl atributo ndim revela el número de dimensiones de un arreglo. Comprender este aspecto es fundamental para visualizar la complejidad de tus datos y prepararte para operaciones más avanzadas, shape, por su parte, te proporciona la forma exacta del arreglo, detallando el tamaño de cada dimensión, size te indica el total de elementos dentro del arreglo. Conocer este dato te permite estimar la magnitud de los cálculos y la memoria necesaria para tus operaciones.\nAprenderás a distinguir entre la cantidad de dimensiones, la forma o estructura y el tamaño total de tus datos, permitiéndote manejarlos con mayor precisión y eficiencia. Con esta comprensión, podrás manejar tus datos con una precisión y eficiencia sin precedentes, aprovechando al máximo las capacidades de esta poderosa biblioteca.\n\nimport numpy as np\n\n\nf = '../data/matriz10x10.txt'\nm = np.loadtxt(f)\nm\n\narray([[1.        , 0.891773  , 0.96366276, 0.38344152, 0.79172504,\n        0.52889492, 0.56804456, 0.92559664, 0.07103606, 0.0871293 ],\n       [0.0202184 , 1.        , 0.77815675, 0.87001215, 0.97861834,\n        0.79915856, 0.46147936, 0.78052918, 0.11827443, 0.63992102],\n       [0.14335329, 0.94466892, 1.        , 0.41466194, 0.26455561,\n        0.77423369, 0.45615033, 0.56843395, 0.0187898 , 0.6176355 ],\n       [0.61209572, 0.616934  , 0.94374808, 1.        , 0.3595079 ,\n        0.43703195, 0.6976312 , 0.06022547, 0.66676672, 0.67063787],\n       [0.21038256, 0.1289263 , 0.31542835, 0.36371077, 1.        ,\n        0.43860151, 0.98837384, 0.10204481, 0.20887676, 0.16130952],\n       [0.65310833, 0.2532916 , 0.46631077, 0.24442559, 0.15896958,\n        1.        , 0.65632959, 0.13818295, 0.19658236, 0.36872517],\n       [0.82099323, 0.09710128, 0.83794491, 0.09609841, 0.97645947,\n        0.4686512 , 1.        , 0.60484552, 0.73926358, 0.03918779],\n       [0.28280696, 0.12019656, 0.2961402 , 0.11872772, 0.31798318,\n        0.41426299, 0.0641475 , 1.        , 0.56660145, 0.26538949],\n       [0.52324805, 0.09394051, 0.5759465 , 0.9292962 , 0.31856895,\n        0.66741038, 0.13179786, 0.7163272 , 1.        , 0.18319136],\n       [0.58651293, 0.02010755, 0.82894003, 0.00469548, 0.67781654,\n        0.27000797, 0.73519402, 0.96218855, 0.24875314, 1.        ]])\n\n\n\ntype(m)\n\nnumpy.ndarray\n\n\n\nm.dtype\n\ndtype('float64')\n\n\n\nm.ndim\n\n2\n\n\n\nm.shape\n\n(10, 10)\n\n\n\nm.size\n\n100",
    "crumbs": [
      "Semana Tres",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Atributos y propiedades de arrays</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaTres/Operaciones_basicas.html",
    "href": "notebooks/semanaTres/Operaciones_basicas.html",
    "title": "34  Operaciones básicas con arrays",
    "section": "",
    "text": "¡Hola a todes! En esta sesión, veremos las operaciones básicas en NumPy. Aprenderemos cómo crear arreglos multidimensionales utilizando funciones como np.zeros, np.ones, np.eye y np.identity, esenciales para la manipulación de datos en NumPy.\nComenzaremos explorando cómo crear arreglos multidimensionales utilizando diversas funciones proporcionadas por NumPy. Luego, nos sumergiremos en las operaciones fundamentales como suma, resta, multiplicación y división en NumPy, destacando la flexibilidad de realizar estas operaciones elemento a elemento. Aprenderas las herramientas esenciales para crear y manipular arrays multidimensionales, realizar operaciones matemáticas con precisión y rapidez, y aprovechar las ventajas de las operaciones para optimizar tu código.\nAl final de esta sesión, tendrás las habilidades fundamentales para realizar un análisis de datos efectivo en NumPy, llevando tus capacidades de programación al siguiente nivel. ¡Empecemos!\n\nimport numpy as np\n\n\nnp.zeros((3,3))\n\narray([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]])\n\n\n\nnp.ones((5,5))\n\narray([[1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.]])\n\n\n\nnp.eye(5)\n\narray([[1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1.]])\n\n\n\nnp.identity(5)\n\narray([[1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1.]])\n\n\n\nnp.full((3,3),-10)\n\narray([[-10, -10, -10],\n       [-10, -10, -10],\n       [-10, -10, -10]])\n\n\n\nnp.random.rand(3,3)\n\narray([[0.20019819, 0.26774823, 0.5968878 ],\n       [0.3274227 , 0.09136412, 0.51176598],\n       [0.71619371, 0.37696918, 0.55026843]])\n\n\n\nnp.random.randint(0,10,(10,10))\n\narray([[2, 6, 1, 7, 3, 4, 1, 1, 9, 9],\n       [0, 2, 1, 2, 0, 5, 7, 0, 9, 2],\n       [0, 2, 3, 0, 9, 4, 1, 7, 5, 2],\n       [9, 8, 6, 9, 5, 2, 4, 2, 2, 8],\n       [2, 0, 4, 2, 3, 4, 5, 4, 5, 8],\n       [3, 3, 2, 7, 9, 1, 9, 0, 2, 2],\n       [8, 6, 4, 5, 5, 0, 1, 7, 8, 6],\n       [0, 1, 3, 8, 0, 9, 1, 8, 5, 3],\n       [7, 5, 8, 8, 0, 5, 0, 5, 0, 6],\n       [9, 3, 8, 3, 9, 3, 5, 0, 0, 9]])\n\n\n\n35 Suma\n\nunos = np.ones((3,3))\nunos\n\narray([[1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.]])\n\n\n\nazar = np.random.randint(0,3,(3,3))\nazar\n\narray([[1, 1, 1],\n       [1, 0, 1],\n       [2, 0, 0]])\n\n\n\nunos.shape\n\n(3, 3)\n\n\n\nazar.shape\n\n(3, 3)\n\n\n\nunos + azar\n\narray([[2., 2., 2.],\n       [2., 1., 2.],\n       [3., 1., 1.]])\n\n\n\nunos * azar\n\narray([[1., 1., 1.],\n       [1., 0., 1.],\n       [2., 0., 0.]])\n\n\n\nunos/azar\n\n/var/folders/5r/jn_g7h3n0pv3v9fbjgr05h8w0000gn/T/ipykernel_50648/2903940513.py:1: RuntimeWarning: divide by zero encountered in divide\n  unos/azar\n\n\narray([[1. , 1. , 1. ],\n       [1. , inf, 1. ],\n       [0.5, inf, inf]])\n\n\n\nunos += 2\nunos\n\narray([[3., 3., 3.],\n       [3., 3., 3.],\n       [3., 3., 3.]])\n\n\n\nazar *= azar\nazar\n\narray([[1, 1, 1],\n       [1, 0, 1],\n       [4, 0, 0]])\n\n\n\na = np.array([1,2,3])\nb = np.array([4,4,4])\nprint(np.dot(a,b), 4+8+12)\n\n24 24",
    "crumbs": [
      "Semana Tres",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Operaciones básicas con arrays</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaTres/Slicing.html",
    "href": "notebooks/semanaTres/Slicing.html",
    "title": "35  Slicing y fancy indexing en NumPy",
    "section": "",
    "text": "¿Listes para sumergirse en las técnicas de slicing y fancy slicing en NumPy? En esta sesión, descubriremos cómo el slicing nos permite acceder a segmentos específicos de arreglos de forma eficiente y cómo el fancy slicing nos abre las puertas a patrones más elaborados y complejos dentro de los arreglos. Estas técnicas son esenciales para la extracción flexible de datos, cruciales en campos como análisis de datos, ciencia de datos y machine learning.\nExploraremos cómo el slicing facilita la selección de segmentos de arreglos de manera intuitiva y eficaz, mientras que el fancy slicing nos equipa para manejar patrones más intrincados. Te guiaremos a través de estas técnicas avanzadas, que te empoderarán para extraer información valiosa de tus arreglos con gran flexibilidad y precisión.\n\nimport numpy as np\n\n\nf = \"../data/m10x10_int.txt\"\nm = np.loadtxt(f)\nm\n\narray([[6., 0., 8., 5., 2., 0., 5., 7., 9., 3.],\n       [7., 3., 1., 8., 6., 0., 6., 2., 7., 2.],\n       [7., 6., 3., 5., 5., 0., 5., 8., 5., 5.],\n       [7., 3., 3., 9., 3., 3., 8., 1., 9., 7.],\n       [0., 3., 0., 7., 0., 4., 3., 7., 4., 9.],\n       [4., 8., 8., 3., 7., 4., 5., 7., 4., 3.],\n       [2., 6., 6., 8., 9., 9., 7., 9., 6., 5.],\n       [4., 9., 9., 9., 1., 8., 6., 9., 8., 9.],\n       [5., 8., 6., 8., 4., 8., 2., 7., 8., 7.],\n       [5., 8., 5., 7., 7., 3., 4., 3., 5., 6.]])\n\n\n\nm.shape\n\n(10, 10)\n\n\n\n\n\nimage-3.png\n\n\n\nm[:2]\n\narray([[6., 0., 8., 5., 2., 0., 5., 7., 9., 3.],\n       [7., 3., 1., 8., 6., 0., 6., 2., 7., 2.]])\n\n\n\n\n\nimage-2.png\n\n\n\nm[:8,:]\n\narray([[6., 0., 8., 5., 2., 0., 5., 7., 9., 3.],\n       [7., 3., 1., 8., 6., 0., 6., 2., 7., 2.],\n       [7., 6., 3., 5., 5., 0., 5., 8., 5., 5.],\n       [7., 3., 3., 9., 3., 3., 8., 1., 9., 7.],\n       [0., 3., 0., 7., 0., 4., 3., 7., 4., 9.],\n       [4., 8., 8., 3., 7., 4., 5., 7., 4., 3.],\n       [2., 6., 6., 8., 9., 9., 7., 9., 6., 5.],\n       [4., 9., 9., 9., 1., 8., 6., 9., 8., 9.]])\n\n\n\nm[:8,4:-1]\n\narray([[2., 0., 5., 7., 9.],\n       [6., 0., 6., 2., 7.],\n       [5., 0., 5., 8., 5.],\n       [3., 3., 8., 1., 9.],\n       [0., 4., 3., 7., 4.],\n       [7., 4., 5., 7., 4.],\n       [9., 9., 7., 9., 6.],\n       [1., 8., 6., 9., 8.]])\n\n\n\nm[:8,4:9]\n\narray([[2., 0., 5., 7., 9.],\n       [6., 0., 6., 2., 7.],\n       [5., 0., 5., 8., 5.],\n       [3., 3., 8., 1., 9.],\n       [0., 4., 3., 7., 4.],\n       [7., 4., 5., 7., 4.],\n       [9., 9., 7., 9., 6.],\n       [1., 8., 6., 9., 8.]])\n\n\n\nm333 = np.random.randint(0,10,(3,3,3))\nm333\n\narray([[[7, 8, 2],\n        [3, 6, 1],\n        [4, 4, 5]],\n\n       [[4, 9, 4],\n        [3, 0, 9],\n        [2, 6, 3]],\n\n       [[9, 9, 5],\n        [9, 8, 2],\n        [2, 2, 2]]])\n\n\n\nm333[:,:,:]\n\narray([[[7, 8, 2],\n        [3, 6, 1],\n        [4, 4, 5]],\n\n       [[4, 9, 4],\n        [3, 0, 9],\n        [2, 6, 3]],\n\n       [[9, 9, 5],\n        [9, 8, 2],\n        [2, 2, 2]]])\n\n\n\nm333[:,:,0]\n\narray([[7, 3, 4],\n       [4, 3, 2],\n       [9, 9, 2]])\n\n\n\nm = np.random.randint(0,10,(15,15))\nm\n\narray([[4, 3, 7, 2, 8, 8, 3, 9, 8, 9, 5, 4, 0, 2, 5],\n       [8, 4, 7, 8, 6, 6, 1, 3, 8, 8, 0, 5, 4, 4, 9],\n       [7, 9, 1, 6, 9, 1, 4, 6, 5, 3, 9, 1, 2, 9, 3],\n       [0, 4, 6, 7, 7, 6, 1, 0, 7, 6, 4, 1, 7, 2, 7],\n       [9, 4, 0, 2, 1, 3, 2, 0, 7, 0, 2, 0, 8, 4, 4],\n       [5, 1, 0, 2, 6, 5, 0, 0, 7, 1, 2, 3, 5, 6, 4],\n       [9, 4, 6, 6, 0, 1, 4, 9, 3, 6, 6, 4, 6, 0, 4],\n       [2, 6, 5, 5, 8, 0, 2, 5, 3, 3, 9, 6, 6, 3, 6],\n       [8, 3, 2, 2, 3, 8, 1, 8, 6, 4, 7, 1, 7, 4, 5],\n       [5, 5, 6, 5, 0, 5, 8, 1, 7, 7, 1, 3, 2, 0, 5],\n       [0, 3, 5, 1, 4, 0, 7, 1, 9, 6, 6, 2, 2, 4, 4],\n       [5, 6, 3, 8, 1, 8, 4, 9, 3, 5, 8, 7, 0, 3, 1],\n       [1, 9, 7, 2, 6, 6, 1, 2, 7, 2, 8, 8, 7, 6, 9],\n       [4, 1, 0, 1, 4, 8, 2, 7, 3, 6, 8, 9, 8, 3, 4],\n       [2, 5, 9, 4, 0, 0, 7, 5, 1, 5, 2, 9, 7, 1, 5]])\n\n\n\nm[1:10:3,::3]\n\narray([[8, 8, 1, 8, 4],\n       [9, 2, 2, 0, 8],\n       [2, 5, 2, 3, 6]])\n\n\n\n36 Fancy slicing\n\nm\n\narray([[4, 3, 7, 2, 8, 8, 3, 9, 8, 9, 5, 4, 0, 2, 5],\n       [8, 4, 7, 8, 6, 6, 1, 3, 8, 8, 0, 5, 4, 4, 9],\n       [7, 9, 1, 6, 9, 1, 4, 6, 5, 3, 9, 1, 2, 9, 3],\n       [0, 4, 6, 7, 7, 6, 1, 0, 7, 6, 4, 1, 7, 2, 7],\n       [9, 4, 0, 2, 1, 3, 2, 0, 7, 0, 2, 0, 8, 4, 4],\n       [5, 1, 0, 2, 6, 5, 0, 0, 7, 1, 2, 3, 5, 6, 4],\n       [9, 4, 6, 6, 0, 1, 4, 9, 3, 6, 6, 4, 6, 0, 4],\n       [2, 6, 5, 5, 8, 0, 2, 5, 3, 3, 9, 6, 6, 3, 6],\n       [8, 3, 2, 2, 3, 8, 1, 8, 6, 4, 7, 1, 7, 4, 5],\n       [5, 5, 6, 5, 0, 5, 8, 1, 7, 7, 1, 3, 2, 0, 5],\n       [0, 3, 5, 1, 4, 0, 7, 1, 9, 6, 6, 2, 2, 4, 4],\n       [5, 6, 3, 8, 1, 8, 4, 9, 3, 5, 8, 7, 0, 3, 1],\n       [1, 9, 7, 2, 6, 6, 1, 2, 7, 2, 8, 8, 7, 6, 9],\n       [4, 1, 0, 1, 4, 8, 2, 7, 3, 6, 8, 9, 8, 3, 4],\n       [2, 5, 9, 4, 0, 0, 7, 5, 1, 5, 2, 9, 7, 1, 5]])\n\n\n\nm[[0,3]]\n\narray([[4, 3, 7, 2, 8, 8, 3, 9, 8, 9, 5, 4, 0, 2, 5],\n       [0, 4, 6, 7, 7, 6, 1, 0, 7, 6, 4, 1, 7, 2, 7]])\n\n\n\nm[m&lt;=2]\n\narray([2, 0, 2, 1, 0, 1, 1, 1, 2, 0, 1, 0, 1, 2, 0, 2, 1, 2, 0, 0, 2, 0,\n       1, 0, 2, 0, 0, 1, 2, 0, 1, 0, 2, 0, 2, 2, 2, 1, 1, 0, 1, 1, 2, 0,\n       0, 1, 0, 1, 2, 2, 1, 0, 1, 1, 2, 1, 2, 2, 1, 0, 1, 2, 2, 0, 0, 1,\n       2, 1])\n\n\n\nm[:,[0,2]]\n\narray([[4, 7],\n       [8, 7],\n       [7, 1],\n       [0, 6],\n       [9, 0],\n       [5, 0],\n       [9, 6],\n       [2, 5],\n       [8, 2],\n       [5, 6],\n       [0, 5],\n       [5, 3],\n       [1, 7],\n       [4, 0],\n       [2, 9]])",
    "crumbs": [
      "Semana Tres",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Slicing y fancy indexing en NumPy</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaTres/imagenes.html",
    "href": "notebooks/semanaTres/imagenes.html",
    "title": "36  Manipula imagenes con NumPy",
    "section": "",
    "text": "¡Bienvenides a el arte de manipular imágenes con NumPy! En esta sesión, aprenderemos cómo NumPy, con su habilidad para manejar arreglos multidimensionales, se convierte en una herramienta poderosa para cargar, analizar y ejecutar operaciones complejas en imágenes. Desde ajustar colores hasta realizar transformaciones, NumPy nos ofrece un nivel de control y flexibilidad sin precedentes en el procesamiento de imágenes.\nNos equiparemos con Matplotlib y PIL (Python Imaging Library) para visualizar y manipular imágenes de manera efectiva en Python. A través de ejemplos prácticos, descubriremos cómo NumPy facilita la manipulación de imágenes en un entorno de Jupyter, revelando su potencial para revolucionar nuestro enfoque en el procesamiento de imágenes.\nPrepárate para explorar las vastas posibilidades que NumPy ofrece en el mundo del análisis y manipulación de imágenes. ¡Vamos a desbloquear el potencial de NumPy en el procesamiento de imágenes!\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n\nf = '../data/python.png'\nlogo = Image.open(f)\nlogo\n\n\n\n\n\n\n\n\n\nimg = np.array(logo)\nimg\n\narray([[[0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        ...,\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0]],\n\n       [[0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        ...,\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0]],\n\n       [[0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        ...,\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0]],\n\n       ...,\n\n       [[0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        ...,\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0]],\n\n       [[0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        ...,\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0]],\n\n       [[0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        ...,\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0]]], dtype=uint8)\n\n\n\nimg.shape # RGBAlpha\n\n(400, 400, 4)\n\n\n\nalpha = img[:,:,3]\nalpha.shape\n\n(400, 400)\n\n\n\nalpha\n\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)\n\n\n\nfig, ax = plt.subplots()\n\na = ax.imshow(alpha,cmap='gray')\nfig.colorbar(a)\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(4,figsize=(10,12))\n\na = ax[0].imshow(img[:,:,0],cmap='gray')\nb = ax[1].imshow(img[:,:,1],cmap='gray')\nc = ax[2].imshow(img[:,:,2],cmap='gray')\nd = ax[3].imshow(img[:,:,3],cmap='gray')\n\nfig.colorbar(a)\nfig.colorbar(b)\nfig.colorbar(c)\nfig.colorbar(d)",
    "crumbs": [
      "Semana Tres",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Manipula imagenes con NumPy</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaTres/glob.html",
    "href": "notebooks/semanaTres/glob.html",
    "title": "37  Manejo de multiples archivos con glob",
    "section": "",
    "text": "¡Bienvenide al mundo del listado de archivos eficiente con glob en Python! En esta sesión, te presentaremos el paquete glob como una herramienta poderosa para automatizar tareas que involucran el manejo de múltiples archivos y directorios. Aprenderás a utilizar patrones de coincidencia de caracteres, conocidos como “wildcards” o comodines, para seleccionar archivos específicos o grupos de archivos según tus necesidades. Descubrirás cómo glob te permite simplificar tu código, ahorrar tiempo y organizar tus datos de manera eficiente.\n\nimport glob\n\n\n#Todos los archivos de un folder\nglob.glob(\"../data/*\")\n\n['../data/matriz3x3_faltantes.txt',\n '../data/matriz10x10.txt',\n '../data/python.png',\n '../data/m10x10_int.txt',\n '../data/Cuernavaca_1dia_comas.csv',\n '../data/Cuernavaca_1dia_comas_Nans.csv',\n '../data/Cuernavaca_1dia_comas_duplicado.csv',\n '../data/Cuernavaca_To_1dia_comas.csv',\n '../data/Cuernavaca_To_1dia_comas.xlsx',\n '../data/obstacle2',\n '../data/Cuernavaca_1dia_comas_NULOS.csv',\n '../data/cuerna.epw',\n '../data/matriz3x3.txt',\n '../data/Cuernavaca_Enero_comas.csv',\n '../data/obstacle',\n '../data/matriz3x3_comment02.txt',\n '../data/matriz3x3_comment01.txt',\n '../data/Cuernavca_T1dia_tabulador.csv']\n\n\n\n#Todos los archivos que terminen en csv\nglob.glob(\"../data/*.csv\")\n\n['../data/Cuernavaca_1dia_comas.csv',\n '../data/Cuernavaca_1dia_comas_Nans.csv',\n '../data/Cuernavaca_1dia_comas_duplicado.csv',\n '../data/Cuernavaca_To_1dia_comas.csv',\n '../data/Cuernavaca_1dia_comas_NULOS.csv',\n '../data/Cuernavaca_Enero_comas.csv',\n '../data/Cuernavca_T1dia_tabulador.csv']\n\n\n\n#Todos los archivos que empiecen con Cuerna\nglob.glob(\"../data/Cuerna*\")\n\n['../data/Cuernavaca_1dia_comas.csv',\n '../data/Cuernavaca_1dia_comas_Nans.csv',\n '../data/Cuernavaca_1dia_comas_duplicado.csv',\n '../data/Cuernavaca_To_1dia_comas.csv',\n '../data/Cuernavaca_To_1dia_comas.xlsx',\n '../data/Cuernavaca_1dia_comas_NULOS.csv',\n '../data/Cuernavaca_Enero_comas.csv',\n '../data/Cuernavca_T1dia_tabulador.csv']\n\n\n\n#Todos los archivos que tengan un primer caracter y luego uerna y cualquier terminacion\nglob.glob(\"../data/?uerna*\")\n\n['../data/Cuernavaca_1dia_comas.csv',\n '../data/Cuernavaca_1dia_comas_Nans.csv',\n '../data/Cuernavaca_1dia_comas_duplicado.csv',\n '../data/Cuernavaca_To_1dia_comas.csv',\n '../data/Cuernavaca_To_1dia_comas.xlsx',\n '../data/Cuernavaca_1dia_comas_NULOS.csv',\n '../data/cuerna.epw',\n '../data/Cuernavaca_Enero_comas.csv',\n '../data/Cuernavca_T1dia_tabulador.csv']\n\n\n\nglob.glob('../data/**/*', recursive=True)\n\n['../data/matriz3x3_faltantes.txt',\n '../data/matriz10x10.txt',\n '../data/python.png',\n '../data/m10x10_int.txt',\n '../data/Cuernavaca_1dia_comas.csv',\n '../data/Cuernavaca_1dia_comas_Nans.csv',\n '../data/Cuernavaca_1dia_comas_duplicado.csv',\n '../data/Cuernavaca_To_1dia_comas.csv',\n '../data/Cuernavaca_To_1dia_comas.xlsx',\n '../data/obstacle2',\n '../data/Cuernavaca_1dia_comas_NULOS.csv',\n '../data/cuerna.epw',\n '../data/matriz3x3.txt',\n '../data/Cuernavaca_Enero_comas.csv',\n '../data/obstacle',\n '../data/matriz3x3_comment02.txt',\n '../data/matriz3x3_comment01.txt',\n '../data/Cuernavca_T1dia_tabulador.csv',\n '../data/obstacle2/unica.png',\n '../data/obstacle/u_norm_183.png',\n '../data/obstacle/u_norm_182.png',\n '../data/obstacle/u_norm_180.png',\n '../data/obstacle/u_norm_181.png',\n '../data/obstacle/u_norm_185.png',\n '../data/obstacle/u_norm_191.png',\n '../data/obstacle/u_norm_190.png',\n '../data/obstacle/u_norm_184.png',\n '../data/obstacle/u_norm_192.png',\n '../data/obstacle/u_norm_186.png',\n '../data/obstacle/u_norm_179.png',\n '../data/obstacle/u_norm_178.png',\n '../data/obstacle/u_norm_187.png',\n '../data/obstacle/u_norm_175.png',\n '../data/obstacle/u_norm_174.png',\n '../data/obstacle/u_norm_189.png',\n '../data/obstacle/u_norm_176.png',\n '../data/obstacle/u_norm_177.png',\n '../data/obstacle/u_norm_188.png',\n '../data/obstacle/u_norm_173.png']\n\n\n\nglob.glob('../data/*/*', recursive=True)\n\n['../data/obstacle2/unica.png',\n '../data/obstacle/u_norm_183.png',\n '../data/obstacle/u_norm_182.png',\n '../data/obstacle/u_norm_180.png',\n '../data/obstacle/u_norm_181.png',\n '../data/obstacle/u_norm_185.png',\n '../data/obstacle/u_norm_191.png',\n '../data/obstacle/u_norm_190.png',\n '../data/obstacle/u_norm_184.png',\n '../data/obstacle/u_norm_192.png',\n '../data/obstacle/u_norm_186.png',\n '../data/obstacle/u_norm_179.png',\n '../data/obstacle/u_norm_178.png',\n '../data/obstacle/u_norm_187.png',\n '../data/obstacle/u_norm_175.png',\n '../data/obstacle/u_norm_174.png',\n '../data/obstacle/u_norm_189.png',\n '../data/obstacle/u_norm_176.png',\n '../data/obstacle/u_norm_177.png',\n '../data/obstacle/u_norm_188.png',\n '../data/obstacle/u_norm_173.png']\n\n\n\nimgs = glob.glob(\"../data/obstacle/*\")\nimgs\n\n['../data/obstacle/u_norm_183.png',\n '../data/obstacle/u_norm_182.png',\n '../data/obstacle/u_norm_180.png',\n '../data/obstacle/u_norm_181.png',\n '../data/obstacle/u_norm_185.png',\n '../data/obstacle/u_norm_191.png',\n '../data/obstacle/u_norm_190.png',\n '../data/obstacle/u_norm_184.png',\n '../data/obstacle/u_norm_192.png',\n '../data/obstacle/u_norm_186.png',\n '../data/obstacle/u_norm_179.png',\n '../data/obstacle/u_norm_178.png',\n '../data/obstacle/u_norm_187.png',\n '../data/obstacle/u_norm_175.png',\n '../data/obstacle/u_norm_174.png',\n '../data/obstacle/u_norm_189.png',\n '../data/obstacle/u_norm_176.png',\n '../data/obstacle/u_norm_177.png',\n '../data/obstacle/u_norm_188.png',\n '../data/obstacle/u_norm_173.png']\n\n\n\nimgs.sort()\nimgs\n\n['../data/obstacle/u_norm_173.png',\n '../data/obstacle/u_norm_174.png',\n '../data/obstacle/u_norm_175.png',\n '../data/obstacle/u_norm_176.png',\n '../data/obstacle/u_norm_177.png',\n '../data/obstacle/u_norm_178.png',\n '../data/obstacle/u_norm_179.png',\n '../data/obstacle/u_norm_180.png',\n '../data/obstacle/u_norm_181.png',\n '../data/obstacle/u_norm_182.png',\n '../data/obstacle/u_norm_183.png',\n '../data/obstacle/u_norm_184.png',\n '../data/obstacle/u_norm_185.png',\n '../data/obstacle/u_norm_186.png',\n '../data/obstacle/u_norm_187.png',\n '../data/obstacle/u_norm_188.png',\n '../data/obstacle/u_norm_189.png',\n '../data/obstacle/u_norm_190.png',\n '../data/obstacle/u_norm_191.png',\n '../data/obstacle/u_norm_192.png']",
    "crumbs": [
      "Semana Tres",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Manejo de multiples archivos con glob</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaTres/carga_flujo_obstaculo.html",
    "href": "notebooks/semanaTres/carga_flujo_obstaculo.html",
    "title": "38  Flujo de trabajo en NumPy con imagenes",
    "section": "",
    "text": "¡Bienvenides a esta sección donde nos adentraremos en el análisis de imágenes de flujos de fluidos utilizando NumPy, PIL, Matplotlib y glob! En esta sesión, enfrentaremos un desafío fascinante: recopilar imágenes de velocidad de flujo en arreglos por canal para analizar la dinámica del flujo. Emplearemos glob para localizar las imágenes, PIL para cargarlas, NumPy para procesarlas y Matplotlib para visualizar los resultados.\nNos prepararemos para explorar cómo cada una de estas herramientas se integra para procesar y visualizar imágenes de manera efectiva. Esta habilidad es clave para desentrañar los misterios de la dinámica de fluidos y mejorar nuestra comprensión de este fenómeno.\n\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport glob as glob\n\n\nvels = glob.glob(\"../data/obstacle/*.png\")\nvels.sort()\nvels\n\n['../data/obstacle/u_norm_173.png',\n '../data/obstacle/u_norm_174.png',\n '../data/obstacle/u_norm_175.png',\n '../data/obstacle/u_norm_176.png',\n '../data/obstacle/u_norm_177.png',\n '../data/obstacle/u_norm_178.png',\n '../data/obstacle/u_norm_179.png',\n '../data/obstacle/u_norm_180.png',\n '../data/obstacle/u_norm_181.png',\n '../data/obstacle/u_norm_182.png',\n '../data/obstacle/u_norm_183.png',\n '../data/obstacle/u_norm_184.png',\n '../data/obstacle/u_norm_185.png',\n '../data/obstacle/u_norm_186.png',\n '../data/obstacle/u_norm_187.png',\n '../data/obstacle/u_norm_188.png',\n '../data/obstacle/u_norm_189.png',\n '../data/obstacle/u_norm_190.png',\n '../data/obstacle/u_norm_191.png',\n '../data/obstacle/u_norm_192.png']\n\n\n\ndef transforma_imagen(imagen):\n    img = Image.open(imagen)\n    img = np.array(img)\n    img = img[:,:,:3]\n    return img\n\n\nimagen = transforma_imagen(vels[10])\nfig, ax = plt.subplots()\nax.imshow(imagen,cmap=\"hot\")\nimagen.shape\n\n\n\n\n\n\n\n\n\n# imagen[:,:,3]  #0,1,2\n\n\nimagen = transforma_imagen(vels[1])\nfig, ax = plt.subplots(3)\nax[0].imshow(imagen[:,:,0],cmap=\"hot\")\nax[1].imshow(imagen[:,:,1],cmap=\"hot\")\nax[2].imshow(imagen[:,:,2],cmap=\"hot\")\n\n\n\n\n\n\n\n\n\nvels\n\n['../data/obstacle/u_norm_173.png',\n '../data/obstacle/u_norm_174.png',\n '../data/obstacle/u_norm_175.png',\n '../data/obstacle/u_norm_176.png',\n '../data/obstacle/u_norm_177.png',\n '../data/obstacle/u_norm_178.png',\n '../data/obstacle/u_norm_179.png',\n '../data/obstacle/u_norm_180.png',\n '../data/obstacle/u_norm_181.png',\n '../data/obstacle/u_norm_182.png',\n '../data/obstacle/u_norm_183.png',\n '../data/obstacle/u_norm_184.png',\n '../data/obstacle/u_norm_185.png',\n '../data/obstacle/u_norm_186.png',\n '../data/obstacle/u_norm_187.png',\n '../data/obstacle/u_norm_188.png',\n '../data/obstacle/u_norm_189.png',\n '../data/obstacle/u_norm_190.png',\n '../data/obstacle/u_norm_191.png',\n '../data/obstacle/u_norm_192.png']\n\n\n\nimg0 = transforma_imagen(vels[0])\nimg1 = transforma_imagen(vels[1])\n\n\nrojas  = np.dstack([img0[:,:,0],img1[:,:,0]])\nverdes = np.dstack([img0[:,:,1],img1[:,:,1]])\nazules = np.dstack([img0[:,:,2],img1[:,:,2]])\nrojas.shape,verdes.shape,azules.shape\n\n((894, 4800, 2), (894, 4800, 2), (894, 4800, 2))\n\n\n\nlista = []\nfor vel in vels:\n    lista.append(transforma_imagen(vel)[:,:,0])\nrojas = np.dstack(lista)\nrojas.shape\n\n(894, 4800, 20)\n\n\n\nrojas = np.dstack([transforma_imagen(vel)[:,:,0]for vel in vels])\nrojas.shape\n\n(894, 4800, 20)\n\n\n\n##Que debo cambiar? \nverdes = np.dstack([transforma_imagen(vel)[:,:,0]for vel in vels])\nazules = np.dstack([transforma_imagen(vel)[:,:,0]for vel in vels])",
    "crumbs": [
      "Semana Tres",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Flujo de trabajo en NumPy con imagenes</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaTres/linspace_arange.html",
    "href": "notebooks/semanaTres/linspace_arange.html",
    "title": "39  Creando intervalos con arange y linspace",
    "section": "",
    "text": "Es hora de sumergirnos en el mundo de la creación de arreglos con np.arange y np.linspace en NumPy. Ahora, te guiaremos a través de estas dos funciones esenciales, mostrándote cómo diferenciarlas y utilizarlas para crear arreglos que cumplan con tus requisitos exactos.\nCon np.arange, aprenderás a crear arreglos con pasos específicos, perfecto para cuando necesitas una secuencia numérica con un incremento constante. Por otro lado, np.linspace es ideal para cuando requieres un número fijo de elementos distribuidos uniformemente dentro de un intervalo.\nA lo largo de esta libreat, descubrirás cómo estas dos funciones pueden ser aplicadas para satisfacer diversas necesidades en la manipulación y análisis de datos con NumPy. ¡Prepárate para dominar np.arange y np.linspace!\n\nimport numpy as np\n\n\nrange(0,10)\n\nrange(0, 10)\n\n\n\nfor i in range(0,10):\n    print(i)\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\nfor i in range(0,10,3):\n    print(i)\n\n0\n3\n6\n9\n\n\n\nrange(0,20,.4)\n\nTypeError: 'float' object cannot be interpreted as an integer\n\n\n\nnp.arange(0,10,2.4)\n\narray([0. , 2.4, 4.8, 7.2, 9.6])\n\n\n\nnp.linspace(0,10,100)\n\narray([ 0.        ,  0.1010101 ,  0.2020202 ,  0.3030303 ,  0.4040404 ,\n        0.50505051,  0.60606061,  0.70707071,  0.80808081,  0.90909091,\n        1.01010101,  1.11111111,  1.21212121,  1.31313131,  1.41414141,\n        1.51515152,  1.61616162,  1.71717172,  1.81818182,  1.91919192,\n        2.02020202,  2.12121212,  2.22222222,  2.32323232,  2.42424242,\n        2.52525253,  2.62626263,  2.72727273,  2.82828283,  2.92929293,\n        3.03030303,  3.13131313,  3.23232323,  3.33333333,  3.43434343,\n        3.53535354,  3.63636364,  3.73737374,  3.83838384,  3.93939394,\n        4.04040404,  4.14141414,  4.24242424,  4.34343434,  4.44444444,\n        4.54545455,  4.64646465,  4.74747475,  4.84848485,  4.94949495,\n        5.05050505,  5.15151515,  5.25252525,  5.35353535,  5.45454545,\n        5.55555556,  5.65656566,  5.75757576,  5.85858586,  5.95959596,\n        6.06060606,  6.16161616,  6.26262626,  6.36363636,  6.46464646,\n        6.56565657,  6.66666667,  6.76767677,  6.86868687,  6.96969697,\n        7.07070707,  7.17171717,  7.27272727,  7.37373737,  7.47474747,\n        7.57575758,  7.67676768,  7.77777778,  7.87878788,  7.97979798,\n        8.08080808,  8.18181818,  8.28282828,  8.38383838,  8.48484848,\n        8.58585859,  8.68686869,  8.78787879,  8.88888889,  8.98989899,\n        9.09090909,  9.19191919,  9.29292929,  9.39393939,  9.49494949,\n        9.5959596 ,  9.6969697 ,  9.7979798 ,  9.8989899 , 10.        ])",
    "crumbs": [
      "Semana Tres",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Creando intervalos con arange y linspace</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaTres/reshape.html",
    "href": "notebooks/semanaTres/reshape.html",
    "title": "40  Manipulación de los arreglos de NumPy",
    "section": "",
    "text": "En esta sección veremos cómo las funciones reshape y resize pueden transformar tus arreglos. Con reshape, aprenderás a reorganizar los elementos de tus arreglos manteniendo la misma cantidad de datos, permitiéndote moldearlos en nuevas formas sin perder información. Por otro lado, resize te da la flexibilidad de ajustar el tamaño de tus arreglos, expandiéndolos o recortándolos según sea necesario para adaptarse a tus requerimientos.\nA medida que avances, entenderás no solo cómo utilizar estas herramientas, sino también cuándo es apropiado aplicar cada una. Esto te permitirá optimizar tu código y lograr una representación de datos que se alinee perfectamente con tus objetivos analíticos. Al concluir, tendrás un conocimiento profundo de las ventajas y limitaciones de reshape y resize, y estarás capacitado para seleccionar la opción más efectiva para la transformación de tus arreglos en NumPy, de acuerdo a tus necesidades específicas.\n\nimport numpy as np\n\n\nm = np.arange(15)\nm\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\n\n\n\nm.reshape(3,5)\n\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14]])\n\n\n\nm.reshape(5,3)\n\narray([[ 0,  1,  2],\n       [ 3,  4,  5],\n       [ 6,  7,  8],\n       [ 9, 10, 11],\n       [12, 13, 14]])\n\n\n\nm.reshape(5,-1)\n\narray([[ 0,  1,  2],\n       [ 3,  4,  5],\n       [ 6,  7,  8],\n       [ 9, 10, 11],\n       [12, 13, 14]])\n\n\n\nm.reshape(-1,5)\n\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14]])\n\n\n\nm  = np.random.randint(0,10,(3,3))\nm\n\narray([[8, 6, 6],\n       [2, 6, 0],\n       [1, 3, 7]])\n\n\n\nm.reshape(-1)\n\narray([8, 6, 6, 2, 6, 0, 1, 3, 7])\n\n\n\nm = np.random.rand(100, 100, 3)\nm\n\narray([[[0.28855083, 0.4448362 , 0.61105639],\n        [0.7594402 , 0.14146844, 0.8413415 ],\n        [0.35300805, 0.2530599 , 0.84439888],\n        ...,\n        [0.32595989, 0.1228926 , 0.6839925 ],\n        [0.99648953, 0.73259549, 0.98159695],\n        [0.03416891, 0.11546777, 0.11983525]],\n\n       [[0.64285516, 0.65874085, 0.79734002],\n        [0.19508675, 0.16462806, 0.18633474],\n        [0.0213286 , 0.180198  , 0.00407577],\n        ...,\n        [0.42301049, 0.19846789, 0.24196548],\n        [0.67581364, 0.20125892, 0.57831096],\n        [0.44928922, 0.56309199, 0.20275227]],\n\n       [[0.48089054, 0.41006477, 0.05447949],\n        [0.17197034, 0.05339118, 0.94235308],\n        [0.28689647, 0.03073413, 0.70833623],\n        ...,\n        [0.66505441, 0.96197757, 0.62658938],\n        [0.77754461, 0.92295048, 0.93346172],\n        [0.08562233, 0.76890425, 0.40244845]],\n\n       ...,\n\n       [[0.92479111, 0.77157321, 0.52865719],\n        [0.34680017, 0.72931384, 0.16745821],\n        [0.12111133, 0.63877138, 0.66058845],\n        ...,\n        [0.76397128, 0.10724926, 0.5506581 ],\n        [0.62667808, 0.07396894, 0.75998114],\n        [0.57473675, 0.32789345, 0.97001736]],\n\n       [[0.788409  , 0.04008978, 0.21338734],\n        [0.3717173 , 0.31905299, 0.73703158],\n        [0.70945426, 0.66603974, 0.33342862],\n        ...,\n        [0.09352969, 0.66174332, 0.52223439],\n        [0.5786852 , 0.54348558, 0.40490288],\n        [0.97791061, 0.34607812, 0.07059512]],\n\n       [[0.58027651, 0.66815292, 0.38162642],\n        [0.89692248, 0.98783247, 0.47255848],\n        [0.46729736, 0.34451034, 0.9494893 ],\n        ...,\n        [0.99408918, 0.22895271, 0.15976376],\n        [0.56130945, 0.44999871, 0.23311172],\n        [0.80387757, 0.4984976 , 0.25365452]]])\n\n\n\nn = m.reshape(-1,3)\nn.shape\n\n(10000, 3)\n\n\n\nm.reshape(10,2)\n\nValueError: cannot reshape array of size 15 into shape (10,2)\n\n\n\nm.resize(10,2)\n\nValueError: cannot resize an array that references or is referenced\nby another array in this way.\nUse the np.resize function or refcheck=False\n\n\n\nnp.resize(m,(10,2))\n\narray([[ 0,  1],\n       [ 2,  3],\n       [ 4,  5],\n       [ 6,  7],\n       [ 8,  9],\n       [10, 11],\n       [12, 13],\n       [14,  0],\n       [ 1,  2],\n       [ 3,  4]])\n\n\n\nm",
    "crumbs": [
      "Semana Tres",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Manipulación de los arreglos de NumPy</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaTres/guarda_numpy.html",
    "href": "notebooks/semanaTres/guarda_numpy.html",
    "title": "41  Guardar datos en NumPy",
    "section": "",
    "text": "Ahora, nos enfocaremos en la como guardar nuestros datos procesados de NumPy. Aprenderás el uso de las funciones np.save y np.load, que son clave para almacenar arreglos NumPy en archivos con formato .npy, y así poder cargarlos con facilidad ya sea en futuras sesiones o en diferentes libretas de trabajo.\nTe enseñaremos a emplear np.save para preservar tus arreglos NumPy, asegurando que tus datos se mantengan intactos en archivos .npy. Además, con np.load, podrás recuperar esos datos siempre que lo requieras, facilitando la continuidad de tu trabajo. Estas herramientas no solo te ahorrarán tiempo valioso, sino que también garantizarán que mantengas la estructura de ellos.\n\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport glob as glob\n\n\nvels = glob.glob(\"../data/obstacle/*.png\")\nvels\n\n['../data/obstacle/u_norm_183.png',\n '../data/obstacle/u_norm_182.png',\n '../data/obstacle/u_norm_180.png',\n '../data/obstacle/u_norm_181.png',\n '../data/obstacle/u_norm_185.png',\n '../data/obstacle/u_norm_191.png',\n '../data/obstacle/u_norm_190.png',\n '../data/obstacle/u_norm_184.png',\n '../data/obstacle/u_norm_192.png',\n '../data/obstacle/u_norm_186.png',\n '../data/obstacle/u_norm_179.png',\n '../data/obstacle/u_norm_178.png',\n '../data/obstacle/u_norm_187.png',\n '../data/obstacle/u_norm_175.png',\n '../data/obstacle/u_norm_174.png',\n '../data/obstacle/u_norm_189.png',\n '../data/obstacle/u_norm_176.png',\n '../data/obstacle/u_norm_177.png',\n '../data/obstacle/u_norm_188.png',\n '../data/obstacle/u_norm_173.png']\n\n\n\ndef transforma_imagen(imagen):\n    img = Image.open(imagen)\n    img = np.array(img)\n    img = img[:,:,:3]\n    img = np.mean(img,axis=2)\n    return img\n\n\nimagen = transforma_imagen(vels[10])\nfig, ax = plt.subplots()\nax.imshow(imagen,cmap=\"hot\")\nimagen.shape\n\n\n\n\n\n\n\n\n\nmultiples  = np.dstack([transforma_imagen(vel) for vel in vels])\npromedio   = np.mean(multiples,axis=2)\ndesviacion = np.std(np.dstack([transforma_imagen(vel) for vel in vels]) ,axis=2)\n\n\nfig, ax = plt.subplots(2,figsize=(10,5))\n\nax[0].imshow(promedio,  cmap=\"hot\")\nax[1].imshow(desviacion,cmap=\"hot\")\n\n\n\n\n\n\n\n\n\npromedio.shape\n\n(894, 4800)\n\n\n\nnp.save(\"../data/promedio.npy\",promedio)\n\n\nprom = np.load(\"../data/promedio.npy\")\nprom.shape\n\n(894, 4800)\n\n\n\nfig, ax = plt.subplots(figsize=(10,5))\n\nax.imshow(prom,  cmap=\"hot\")",
    "crumbs": [
      "Semana Tres",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Guardar datos en NumPy</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaTres/meshgrid.html",
    "href": "notebooks/semanaTres/meshgrid.html",
    "title": "42  Mallas para cálculos numéricos con NumPy",
    "section": "",
    "text": "¡Bienvenide al mundo de la visualización de datos con meshgrid en Python! Esta es tu entrada a una herramienta que te permitirá crear mallas de coordenadas para visualizar datos en dos y tres dimensiones de manera efectiva. A través de meshgrid, aprenderás a transformar vectores unidimensionales en matrices de coordenadas, brindándote la capacidad de diseñar gráficos a medida y analizar conjuntos de datos complejos.\nUsarás meshgrid para construir mallas, así como para evaluar funciones sobre diversos rangos de valores. Esto te facilitará la generación de representaciones gráficas que muestren tus datos con precisión y claridad. Al concluir, tendrás una visión clara de cómo meshgrid puede ser usado en tu análisis de datos.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n\n# Creando dos rangos de valores\nx = np.linspace(-5, 0, 10)\ny = np.linspace(-5, 5, 10)\nX, Y = np.meshgrid(x, y)\n\n\nx\n\narray([-5.        , -4.44444444, -3.88888889, -3.33333333, -2.77777778,\n       -2.22222222, -1.66666667, -1.11111111, -0.55555556,  0.        ])\n\n\n\nX\n\narray([[-5.        , -4.44444444, -3.88888889, -3.33333333, -2.77777778,\n        -2.22222222, -1.66666667, -1.11111111, -0.55555556,  0.        ],\n       [-5.        , -4.44444444, -3.88888889, -3.33333333, -2.77777778,\n        -2.22222222, -1.66666667, -1.11111111, -0.55555556,  0.        ],\n       [-5.        , -4.44444444, -3.88888889, -3.33333333, -2.77777778,\n        -2.22222222, -1.66666667, -1.11111111, -0.55555556,  0.        ],\n       [-5.        , -4.44444444, -3.88888889, -3.33333333, -2.77777778,\n        -2.22222222, -1.66666667, -1.11111111, -0.55555556,  0.        ],\n       [-5.        , -4.44444444, -3.88888889, -3.33333333, -2.77777778,\n        -2.22222222, -1.66666667, -1.11111111, -0.55555556,  0.        ],\n       [-5.        , -4.44444444, -3.88888889, -3.33333333, -2.77777778,\n        -2.22222222, -1.66666667, -1.11111111, -0.55555556,  0.        ],\n       [-5.        , -4.44444444, -3.88888889, -3.33333333, -2.77777778,\n        -2.22222222, -1.66666667, -1.11111111, -0.55555556,  0.        ],\n       [-5.        , -4.44444444, -3.88888889, -3.33333333, -2.77777778,\n        -2.22222222, -1.66666667, -1.11111111, -0.55555556,  0.        ],\n       [-5.        , -4.44444444, -3.88888889, -3.33333333, -2.77777778,\n        -2.22222222, -1.66666667, -1.11111111, -0.55555556,  0.        ],\n       [-5.        , -4.44444444, -3.88888889, -3.33333333, -2.77777778,\n        -2.22222222, -1.66666667, -1.11111111, -0.55555556,  0.        ]])\n\n\n\nY\n\narray([[-5.        , -5.        , -5.        , -5.        , -5.        ,\n        -5.        , -5.        , -5.        , -5.        , -5.        ],\n       [-3.88888889, -3.88888889, -3.88888889, -3.88888889, -3.88888889,\n        -3.88888889, -3.88888889, -3.88888889, -3.88888889, -3.88888889],\n       [-2.77777778, -2.77777778, -2.77777778, -2.77777778, -2.77777778,\n        -2.77777778, -2.77777778, -2.77777778, -2.77777778, -2.77777778],\n       [-1.66666667, -1.66666667, -1.66666667, -1.66666667, -1.66666667,\n        -1.66666667, -1.66666667, -1.66666667, -1.66666667, -1.66666667],\n       [-0.55555556, -0.55555556, -0.55555556, -0.55555556, -0.55555556,\n        -0.55555556, -0.55555556, -0.55555556, -0.55555556, -0.55555556],\n       [ 0.55555556,  0.55555556,  0.55555556,  0.55555556,  0.55555556,\n         0.55555556,  0.55555556,  0.55555556,  0.55555556,  0.55555556],\n       [ 1.66666667,  1.66666667,  1.66666667,  1.66666667,  1.66666667,\n         1.66666667,  1.66666667,  1.66666667,  1.66666667,  1.66666667],\n       [ 2.77777778,  2.77777778,  2.77777778,  2.77777778,  2.77777778,\n         2.77777778,  2.77777778,  2.77777778,  2.77777778,  2.77777778],\n       [ 3.88888889,  3.88888889,  3.88888889,  3.88888889,  3.88888889,\n         3.88888889,  3.88888889,  3.88888889,  3.88888889,  3.88888889],\n       [ 5.        ,  5.        ,  5.        ,  5.        ,  5.        ,\n         5.        ,  5.        ,  5.        ,  5.        ,  5.        ]])\n\n\n\n# Visualizando la malla con un gráfico de dispersión\nfig, ax = plt.subplots()\nax.scatter(X, Y)\n\n\n\n\n\n\n\n\n\nZ = X**2 + Y**2\nZ\n\narray([[50.        , 44.75308642, 40.12345679, 36.11111111, 32.71604938,\n        29.9382716 , 27.77777778, 26.2345679 , 25.30864198, 25.        ],\n       [40.12345679, 34.87654321, 30.24691358, 26.2345679 , 22.83950617,\n        20.0617284 , 17.90123457, 16.35802469, 15.43209877, 15.12345679],\n       [32.71604938, 27.4691358 , 22.83950617, 18.82716049, 15.43209877,\n        12.65432099, 10.49382716,  8.95061728,  8.02469136,  7.71604938],\n       [27.77777778, 22.5308642 , 17.90123457, 13.88888889, 10.49382716,\n         7.71604938,  5.55555556,  4.01234568,  3.08641975,  2.77777778],\n       [25.30864198, 20.0617284 , 15.43209877, 11.41975309,  8.02469136,\n         5.24691358,  3.08641975,  1.54320988,  0.61728395,  0.30864198],\n       [25.30864198, 20.0617284 , 15.43209877, 11.41975309,  8.02469136,\n         5.24691358,  3.08641975,  1.54320988,  0.61728395,  0.30864198],\n       [27.77777778, 22.5308642 , 17.90123457, 13.88888889, 10.49382716,\n         7.71604938,  5.55555556,  4.01234568,  3.08641975,  2.77777778],\n       [32.71604938, 27.4691358 , 22.83950617, 18.82716049, 15.43209877,\n        12.65432099, 10.49382716,  8.95061728,  8.02469136,  7.71604938],\n       [40.12345679, 34.87654321, 30.24691358, 26.2345679 , 22.83950617,\n        20.0617284 , 17.90123457, 16.35802469, 15.43209877, 15.12345679],\n       [50.        , 44.75308642, 40.12345679, 36.11111111, 32.71604938,\n        29.9382716 , 27.77777778, 26.2345679 , 25.30864198, 25.        ]])\n\n\n\nZ.shape\n\n(10, 10)\n\n\n\n# Creando la figura y el eje para el gráfico 3D usando subplots\nfig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n\n# Dibujando la superficie\nsurf = ax.plot_surface(X, Y, Z, cmap='viridis')\n\n# Etiquetas y título\nax.set_xlabel('Eje X')\nax.set_ylabel('Eje Y')\nax.set_zlabel('Eje Z')\nax.set_title('Superficie Parabólica')\n\nText(0.5, 0.92, 'Superficie Parabólica')",
    "crumbs": [
      "Semana Tres",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Mallas para cálculos numéricos con NumPy</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaTres/Algebra_lineal.html",
    "href": "notebooks/semanaTres/Algebra_lineal.html",
    "title": "43  Herramientas para álgebral lineal",
    "section": "",
    "text": "¿Preparades para aprender sobre el amplio conjunto de herramientas para álgebra lineal en NumPy? En esta sesión, veremos las funciones especializadas de NumPy para álgebra lineal, fundamentales en áreas como la ciencia de datos y la ingeniería. Veremos desde la descomposición de valores singulares hasta el cálculo de autovalores y autovectores, y veremos cómo NumPy facilita la resolución de problemas complejos en esta área.\n\nimport numpy as np\n\n\nA = np.array([[1, 2], [3, 4]])\nB = np.array([[5, 6], [7, 8]])\n\n\nprint(A)\nprint(B)\n\n[[1 2]\n [3 4]]\n[[5 6]\n [7 8]]\n\n\n\nA = np.arange(1,5).reshape(2,-1)\nB = np.arange(5,9).reshape(2,2)\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nprint(A)\nprint(B)\n\n[[1 2]\n [3 4]]\n[[5 6]\n [7 8]]\n\n\n\nnp.dot(A,B)\n\narray([[19, 22],\n       [43, 50]])\n\n\n\nA@B\n\narray([[19, 22],\n       [43, 50]])\n\n\n\nA.T\n\narray([[1, 3],\n       [2, 4]])\n\n\n\nnp.transpose(A)\n\narray([[1, 3],\n       [2, 4]])\n\n\n\nnp.linalg.inv(A)\n\narray([[-2. ,  1. ],\n       [ 1.5, -0.5]])\n\n\n\nnp.linalg.det(A)\n\n-2.0000000000000004\n\n\n\nb = np.array([9,8])\nx = np.linalg.solve(A,b)\nx\n\narray([-10. ,   9.5])\n\n\n\neigenvalores, eigenvectores = np.linalg.eig(A)\nprint(eigenvalores, eigenvectores)\n\n[-0.37228132  5.37228132] [[-0.82456484 -0.41597356]\n [ 0.56576746 -0.90937671]]\n\n\n\nU, S, V = np.linalg.svd(A)\nprint(U,S,V)\n\n[[-0.40455358 -0.9145143 ]\n [-0.9145143   0.40455358]] [5.4649857  0.36596619] [[-0.57604844 -0.81741556]\n [ 0.81741556 -0.57604844]]",
    "crumbs": [
      "Semana Tres",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Herramientas para álgebral lineal</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaCuatro/semana4.html",
    "href": "notebooks/semanaCuatro/semana4.html",
    "title": "Semana Cuatro",
    "section": "",
    "text": "Los objetivos de esta semana serán:\n\nEntender el concepto de espacio de trabajo y su importancia para organizar y acceder eficientemente a proyectos y datos.\nDominar la narrativa computacional en las libretas, comprendiendo cómo los nombres de variables, el orden de las libretas y la documentación contribuyen a una narrativa coherente que facilita el entendimiento y la colaboración en proyectos.\nAprender a concatenar archivos con pandas para manejar conjuntos de datos grandes o divididos, permitiendo su combinación en una sola estructura de datos para análisis complejos.\nExplorar el uso de multiíndices en columnas e índices de series temporales para manejar datos más complejos, mejorando la organización y el acceso a subconjuntos específicos de datos.\nComprender la importancia del encoding (codificación) en la preparación o importación de datos para asegurar su interpretación correcta por las herramientas de análisis.\nDesarrollar habilidades para crear paquetes locales, permitiendo la reutilización y el intercambio eficiente de código, esencial para modularizar y mejorar la calidad de los proyectos.\nRepasar las buenas prácticas en ciencia de datos, desde la escritura de código limpio hasta la gestión eficaz de proyectos y datos.\nAplicar las buenas prácticas aprendidas en proyectos futuros.\nDemostrar comprensión y habilidad para aplicar conceptos aprendidos en un ejercicio final que resuma las buenas prácticas.\nExplorar recomendaciones de paquetes adicionales para ampliar la caja de herramientas y estar preparado para enfrentar desafíos más complejos en ciencia de datos.",
    "crumbs": [
      "Semana Cuatro"
    ]
  },
  {
    "objectID": "notebooks/semanaCuatro/concatena.html",
    "href": "notebooks/semanaCuatro/concatena.html",
    "title": "44  Concatena archivos con Pandas",
    "section": "",
    "text": "Ejercicio propuesto\nHacer una lista de glob, cargar todos los archivos usando un list comprehension y definiendo una función, concatenando todos los archivos y ordenando el índice.",
    "crumbs": [
      "Semana Cuatro",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Concatena archivos con Pandas</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaCuatro/multiindex_columnas.html",
    "href": "notebooks/semanaCuatro/multiindex_columnas.html",
    "title": "45  Multi-índice en las columnas de series temporales",
    "section": "",
    "text": "En el vasto campo del análisis de datos con Pandas, la capacidad de organizar y estructurar nuestros datos de manera eficiente es esencial para una exploración y análisis efectivos. En esta sesión, conoceremos el concepto de multiíndice, también conocido como índice jerárquico, que nos permite tener múltiples niveles de índices en DataFrames. Descubriremos cómo esta característica puede simplificar la organización de datos complejos al facilitar su accesibilidad y comprensión. Exploraremos cómo aplicar multiíndices a las columnas de un DataFrame nos permite agrupar variables relacionadas bajo un mismo índice superior, lo que resulta especialmente útil en conjuntos de datos de series temporales.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nf = '../data/Ti_blanco.csv'\nTi_b = pd.read_csv(f,index_col=0,parse_dates=True)\n\nf = '../data/Ti_negro.csv'\nTi_n = pd.read_csv(f,index_col=0,parse_dates=True)\n\n\nTi_n\n\n\n\n\n\n\n\n\n\nTi_C\nTi_R1\nTi_R2\nTi_S\n\n\ndate\n\n\n\n\n\n\n\n\n2006-01-01 00:10:00\n19.038413\n19.047696\n19.087096\n19.129994\n\n\n2006-01-01 00:20:00\n19.035998\n19.045313\n19.084383\n19.128110\n\n\n2006-01-01 00:30:00\n19.033880\n19.043235\n19.082035\n19.126533\n\n\n2006-01-01 00:40:00\n19.031973\n19.041355\n19.079928\n19.125138\n\n\n2006-01-01 00:50:00\n19.030158\n19.039552\n19.077921\n19.123787\n\n\n...\n...\n...\n...\n...\n\n\n2006-12-31 23:20:00\n24.137526\n23.391216\n23.667201\n24.646797\n\n\n2006-12-31 23:30:00\n24.064361\n23.323456\n23.589420\n24.567420\n\n\n2006-12-31 23:40:00\n23.990232\n23.257064\n23.512465\n24.488597\n\n\n2006-12-31 23:50:00\n23.917165\n23.191858\n23.436305\n24.410237\n\n\n2007-01-01 00:00:00\n23.846178\n23.127226\n23.360837\n24.332185\n\n\n\n\n52560 rows × 4 columns\n\n\n\n\n\nTi_b\n\n\n\n\n\n\n\n\n\nTi_C\nTi_R1\nTi_R2\nTi_S\n\n\ndate\n\n\n\n\n\n\n\n\n2006-01-01 00:10:00\n19.014610\n19.024472\n19.065057\n19.106503\n\n\n2006-01-01 00:20:00\n19.012693\n19.022505\n19.062782\n19.104997\n\n\n2006-01-01 00:30:00\n19.011030\n19.020820\n19.060846\n19.103773\n\n\n2006-01-01 00:40:00\n19.009526\n19.019312\n19.059129\n19.102714\n\n\n2006-01-01 00:50:00\n19.008070\n19.017864\n19.057494\n19.101684\n\n\n...\n...\n...\n...\n...\n\n\n2006-12-31 23:20:00\n19.589577\n19.517255\n19.780842\n19.902851\n\n\n2006-12-31 23:30:00\n19.572531\n19.500154\n19.757842\n19.882044\n\n\n2006-12-31 23:40:00\n19.555469\n19.482987\n19.734803\n19.861207\n\n\n2006-12-31 23:50:00\n19.538364\n19.465734\n19.711720\n19.840302\n\n\n2007-01-01 00:00:00\n19.521151\n19.448329\n19.688533\n19.819254\n\n\n\n\n52560 rows × 4 columns\n\n\n\n\n\npd.concat([Ti_b,Ti_n],axis=1)\n\n\n\n\n\n\n\n\n\nTi_C\nTi_R1\nTi_R2\nTi_S\nTi_C\nTi_R1\nTi_R2\nTi_S\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n\n\n2006-01-01 00:10:00\n19.014610\n19.024472\n19.065057\n19.106503\n19.038413\n19.047696\n19.087096\n19.129994\n\n\n2006-01-01 00:20:00\n19.012693\n19.022505\n19.062782\n19.104997\n19.035998\n19.045313\n19.084383\n19.128110\n\n\n2006-01-01 00:30:00\n19.011030\n19.020820\n19.060846\n19.103773\n19.033880\n19.043235\n19.082035\n19.126533\n\n\n2006-01-01 00:40:00\n19.009526\n19.019312\n19.059129\n19.102714\n19.031973\n19.041355\n19.079928\n19.125138\n\n\n2006-01-01 00:50:00\n19.008070\n19.017864\n19.057494\n19.101684\n19.030158\n19.039552\n19.077921\n19.123787\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2006-12-31 23:20:00\n19.589577\n19.517255\n19.780842\n19.902851\n24.137526\n23.391216\n23.667201\n24.646797\n\n\n2006-12-31 23:30:00\n19.572531\n19.500154\n19.757842\n19.882044\n24.064361\n23.323456\n23.589420\n24.567420\n\n\n2006-12-31 23:40:00\n19.555469\n19.482987\n19.734803\n19.861207\n23.990232\n23.257064\n23.512465\n24.488597\n\n\n2006-12-31 23:50:00\n19.538364\n19.465734\n19.711720\n19.840302\n23.917165\n23.191858\n23.436305\n24.410237\n\n\n2007-01-01 00:00:00\n19.521151\n19.448329\n19.688533\n19.819254\n23.846178\n23.127226\n23.360837\n24.332185\n\n\n\n\n52560 rows × 8 columns\n\n\n\n\n\npd.concat([Ti_b,Ti_n],axis=1,keys=['blanco','negro'])\n\n\n\n\n\n\n\n\n\nblanco\nnegro\n\n\n\nTi_C\nTi_R1\nTi_R2\nTi_S\nTi_C\nTi_R1\nTi_R2\nTi_S\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n\n\n2006-01-01 00:10:00\n19.014610\n19.024472\n19.065057\n19.106503\n19.038413\n19.047696\n19.087096\n19.129994\n\n\n2006-01-01 00:20:00\n19.012693\n19.022505\n19.062782\n19.104997\n19.035998\n19.045313\n19.084383\n19.128110\n\n\n2006-01-01 00:30:00\n19.011030\n19.020820\n19.060846\n19.103773\n19.033880\n19.043235\n19.082035\n19.126533\n\n\n2006-01-01 00:40:00\n19.009526\n19.019312\n19.059129\n19.102714\n19.031973\n19.041355\n19.079928\n19.125138\n\n\n2006-01-01 00:50:00\n19.008070\n19.017864\n19.057494\n19.101684\n19.030158\n19.039552\n19.077921\n19.123787\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2006-12-31 23:20:00\n19.589577\n19.517255\n19.780842\n19.902851\n24.137526\n23.391216\n23.667201\n24.646797\n\n\n2006-12-31 23:30:00\n19.572531\n19.500154\n19.757842\n19.882044\n24.064361\n23.323456\n23.589420\n24.567420\n\n\n2006-12-31 23:40:00\n19.555469\n19.482987\n19.734803\n19.861207\n23.990232\n23.257064\n23.512465\n24.488597\n\n\n2006-12-31 23:50:00\n19.538364\n19.465734\n19.711720\n19.840302\n23.917165\n23.191858\n23.436305\n24.410237\n\n\n2007-01-01 00:00:00\n19.521151\n19.448329\n19.688533\n19.819254\n23.846178\n23.127226\n23.360837\n24.332185\n\n\n\n\n52560 rows × 8 columns\n\n\n\n\n\ncasos = pd.concat([Ti_b,Ti_n],axis=1,keys=['blanco','negro'])\n\n\ncasos['blanco']\n\n\n\n\n\n\n\n\n\nTi_C\nTi_R1\nTi_R2\nTi_S\n\n\ndate\n\n\n\n\n\n\n\n\n2006-01-01 00:10:00\n19.014610\n19.024472\n19.065057\n19.106503\n\n\n2006-01-01 00:20:00\n19.012693\n19.022505\n19.062782\n19.104997\n\n\n2006-01-01 00:30:00\n19.011030\n19.020820\n19.060846\n19.103773\n\n\n2006-01-01 00:40:00\n19.009526\n19.019312\n19.059129\n19.102714\n\n\n2006-01-01 00:50:00\n19.008070\n19.017864\n19.057494\n19.101684\n\n\n...\n...\n...\n...\n...\n\n\n2006-12-31 23:20:00\n19.589577\n19.517255\n19.780842\n19.902851\n\n\n2006-12-31 23:30:00\n19.572531\n19.500154\n19.757842\n19.882044\n\n\n2006-12-31 23:40:00\n19.555469\n19.482987\n19.734803\n19.861207\n\n\n2006-12-31 23:50:00\n19.538364\n19.465734\n19.711720\n19.840302\n\n\n2007-01-01 00:00:00\n19.521151\n19.448329\n19.688533\n19.819254\n\n\n\n\n52560 rows × 4 columns\n\n\n\n\n\ncasos['negro']\n\n\n\n\n\n\n\n\n\nTi_C\nTi_R1\nTi_R2\nTi_S\n\n\ndate\n\n\n\n\n\n\n\n\n2006-01-01 00:10:00\n19.038413\n19.047696\n19.087096\n19.129994\n\n\n2006-01-01 00:20:00\n19.035998\n19.045313\n19.084383\n19.128110\n\n\n2006-01-01 00:30:00\n19.033880\n19.043235\n19.082035\n19.126533\n\n\n2006-01-01 00:40:00\n19.031973\n19.041355\n19.079928\n19.125138\n\n\n2006-01-01 00:50:00\n19.030158\n19.039552\n19.077921\n19.123787\n\n\n...\n...\n...\n...\n...\n\n\n2006-12-31 23:20:00\n24.137526\n23.391216\n23.667201\n24.646797\n\n\n2006-12-31 23:30:00\n24.064361\n23.323456\n23.589420\n24.567420\n\n\n2006-12-31 23:40:00\n23.990232\n23.257064\n23.512465\n24.488597\n\n\n2006-12-31 23:50:00\n23.917165\n23.191858\n23.436305\n24.410237\n\n\n2007-01-01 00:00:00\n23.846178\n23.127226\n23.360837\n24.332185\n\n\n\n\n52560 rows × 4 columns\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10,4))\n\nax.plot(casos['blanco']['Ti_C'])\nax.plot(casos['negro']['Ti_C'])\n\n\n\n\n\n\n\n\n\ncasos.columns.get_level_values(0).unique()\n\nIndex(['blanco', 'negro'], dtype='object')\n\n\n\ncasos.columns.levels\n\nFrozenList([['blanco', 'negro'], ['Ti_C', 'Ti_R1', 'Ti_R2', 'Ti_S']])\n\n\n\ncasos.columns.levels[0]\n\nIndex(['blanco', 'negro'], dtype='object')\n\n\n\ncolores = casos.columns.levels[0]\n\nfig, ax = plt.subplots(figsize=(10,4))\n\nfor color in colores:\n    ax.plot(casos[color]['Ti_C'])",
    "crumbs": [
      "Semana Cuatro",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Multi-índice en  las columnas de series temporales</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaCuatro/multiindex_indice.html",
    "href": "notebooks/semanaCuatro/multiindex_indice.html",
    "title": "46  Multi-índices en las columnas de series temporales",
    "section": "",
    "text": "En el análisis de datos, la capacidad de organizar la información de manera jerárquica es esencial para una comprensión más profunda y una exploración eficiente. En esta sesión, veremos cómo crear un multiíndice en el nivel del índice con series temporales. Al crear un multiíndice, establecemos un nivel jerárquico que nos permite acceder a la información de manera estructurada y organizada. Veremos cómo esta técnica puede facilitar el acceso y la exploración de datos, especialmente cuando lidiamos con conjuntos de datos complejos.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nf = '../data/Ti_blanco.csv'\nTi_b = pd.read_csv(f,index_col=0,parse_dates=True)\n\nf = '../data/Ti_negro.csv'\nTi_n = pd.read_csv(f,index_col=0,parse_dates=True)\n\n\nTi_n\n\n\n\n\n\n\n\n\n\nTi_C\nTi_R1\nTi_R2\nTi_S\n\n\ndate\n\n\n\n\n\n\n\n\n2006-01-01 00:10:00\n19.038413\n19.047696\n19.087096\n19.129994\n\n\n2006-01-01 00:20:00\n19.035998\n19.045313\n19.084383\n19.128110\n\n\n2006-01-01 00:30:00\n19.033880\n19.043235\n19.082035\n19.126533\n\n\n2006-01-01 00:40:00\n19.031973\n19.041355\n19.079928\n19.125138\n\n\n2006-01-01 00:50:00\n19.030158\n19.039552\n19.077921\n19.123787\n\n\n...\n...\n...\n...\n...\n\n\n2006-12-31 23:20:00\n24.137526\n23.391216\n23.667201\n24.646797\n\n\n2006-12-31 23:30:00\n24.064361\n23.323456\n23.589420\n24.567420\n\n\n2006-12-31 23:40:00\n23.990232\n23.257064\n23.512465\n24.488597\n\n\n2006-12-31 23:50:00\n23.917165\n23.191858\n23.436305\n24.410237\n\n\n2007-01-01 00:00:00\n23.846178\n23.127226\n23.360837\n24.332185\n\n\n\n\n52560 rows × 4 columns\n\n\n\n\n\nTi_b\n\n\n\n\n\n\n\n\n\nTi_C\nTi_R1\nTi_R2\nTi_S\n\n\ndate\n\n\n\n\n\n\n\n\n2006-01-01 00:10:00\n19.014610\n19.024472\n19.065057\n19.106503\n\n\n2006-01-01 00:20:00\n19.012693\n19.022505\n19.062782\n19.104997\n\n\n2006-01-01 00:30:00\n19.011030\n19.020820\n19.060846\n19.103773\n\n\n2006-01-01 00:40:00\n19.009526\n19.019312\n19.059129\n19.102714\n\n\n2006-01-01 00:50:00\n19.008070\n19.017864\n19.057494\n19.101684\n\n\n...\n...\n...\n...\n...\n\n\n2006-12-31 23:20:00\n19.589577\n19.517255\n19.780842\n19.902851\n\n\n2006-12-31 23:30:00\n19.572531\n19.500154\n19.757842\n19.882044\n\n\n2006-12-31 23:40:00\n19.555469\n19.482987\n19.734803\n19.861207\n\n\n2006-12-31 23:50:00\n19.538364\n19.465734\n19.711720\n19.840302\n\n\n2007-01-01 00:00:00\n19.521151\n19.448329\n19.688533\n19.819254\n\n\n\n\n52560 rows × 4 columns\n\n\n\n\n\npd.concat([Ti_b,Ti_n],axis=1,keys=['blanco','negro'])\n\n\n\n\n\n\n\n\n\nblanco\nnegro\n\n\n\nTi_C\nTi_R1\nTi_R2\nTi_S\nTi_C\nTi_R1\nTi_R2\nTi_S\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n\n\n2006-01-01 00:10:00\n19.014610\n19.024472\n19.065057\n19.106503\n19.038413\n19.047696\n19.087096\n19.129994\n\n\n2006-01-01 00:20:00\n19.012693\n19.022505\n19.062782\n19.104997\n19.035998\n19.045313\n19.084383\n19.128110\n\n\n2006-01-01 00:30:00\n19.011030\n19.020820\n19.060846\n19.103773\n19.033880\n19.043235\n19.082035\n19.126533\n\n\n2006-01-01 00:40:00\n19.009526\n19.019312\n19.059129\n19.102714\n19.031973\n19.041355\n19.079928\n19.125138\n\n\n2006-01-01 00:50:00\n19.008070\n19.017864\n19.057494\n19.101684\n19.030158\n19.039552\n19.077921\n19.123787\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2006-12-31 23:20:00\n19.589577\n19.517255\n19.780842\n19.902851\n24.137526\n23.391216\n23.667201\n24.646797\n\n\n2006-12-31 23:30:00\n19.572531\n19.500154\n19.757842\n19.882044\n24.064361\n23.323456\n23.589420\n24.567420\n\n\n2006-12-31 23:40:00\n19.555469\n19.482987\n19.734803\n19.861207\n23.990232\n23.257064\n23.512465\n24.488597\n\n\n2006-12-31 23:50:00\n19.538364\n19.465734\n19.711720\n19.840302\n23.917165\n23.191858\n23.436305\n24.410237\n\n\n2007-01-01 00:00:00\n19.521151\n19.448329\n19.688533\n19.819254\n23.846178\n23.127226\n23.360837\n24.332185\n\n\n\n\n52560 rows × 8 columns\n\n\n\n\n\npd.MultiIndex.from_product() #help\n\nTypeError: MultiIndex.from_product() missing 1 required positional argument: 'iterables'\n\n\n\n# Crear un MultiIndex combinando la categoría con el índice de fecha y hora existente\nmulti_indice  = pd.MultiIndex.from_product([['blanco'], Ti_b.index], names=['Categoría', 'Fecha'])\n\n# # Asignar el nuevo MultiIndex al DataFrame\n# Ti_b.index = multi_index\n# Ti_b\nmulti_indice\n\n\nTi_bm = Ti_b\nTi_bm.index = multi_indice\nTi_bm\n\nNameError: name 'multi_indice' is not defined\n\n\n\nf = '../data/Ti_blanco.csv'\nTi_b = pd.read_csv(f,index_col=0,parse_dates=True)\nmulti_indice  = pd.MultiIndex.from_product([['blanco'], Ti_b.index], names=['Categoría', 'Fecha'])\nTi_bm = Ti_b\nTi_bm.index = multi_indice\nTi_bm\n\n\n\n\n\n\n\n\n\n\nTi_C\nTi_R1\nTi_R2\nTi_S\n\n\nCategoría\nFecha\n\n\n\n\n\n\n\n\nblanco\n2006-01-01 00:10:00\n19.014610\n19.024472\n19.065057\n19.106503\n\n\n2006-01-01 00:20:00\n19.012693\n19.022505\n19.062782\n19.104997\n\n\n2006-01-01 00:30:00\n19.011030\n19.020820\n19.060846\n19.103773\n\n\n2006-01-01 00:40:00\n19.009526\n19.019312\n19.059129\n19.102714\n\n\n2006-01-01 00:50:00\n19.008070\n19.017864\n19.057494\n19.101684\n\n\n...\n...\n...\n...\n...\n\n\n2006-12-31 23:20:00\n19.589577\n19.517255\n19.780842\n19.902851\n\n\n2006-12-31 23:30:00\n19.572531\n19.500154\n19.757842\n19.882044\n\n\n2006-12-31 23:40:00\n19.555469\n19.482987\n19.734803\n19.861207\n\n\n2006-12-31 23:50:00\n19.538364\n19.465734\n19.711720\n19.840302\n\n\n2007-01-01 00:00:00\n19.521151\n19.448329\n19.688533\n19.819254\n\n\n\n\n52560 rows × 4 columns\n\n\n\n\n\nf = '../data/Ti_blanco.csv'\nTi_b = pd.read_csv(f,index_col=0,parse_dates=True)\nmulti_indice  = pd.MultiIndex.from_product([ Ti_b.index,['blanco']], names=['Categoría', 'Fecha'])\nTi_bm = Ti_b\nTi_bm.index = multi_indice\n\n\nf = '../data/Ti_blanco.csv'\ndef agrega_multi(f,multi):\n    Ti_b = pd.read_csv(f,index_col=0,parse_dates=True)\n    Ti_b = Ti_b.resample('D').mean()\n    multi_indice  = pd.MultiIndex.from_product([ Ti_b.index,[multi]], names=['Categoría', 'Fecha'])\n    Ti_bm = Ti_b\n    Ti_bm.index = multi_indice\n    return Ti_bm\n\nblanco = agrega_multi(f,'blanco')\n\n\nf = '../data/Ti_blanco.csv'\nblanco = agrega_multi(f,'blanco')\n\nf = '../data/Ti_negro.csv'\nnegro  = agrega_multi(f,'negro')\n\n\ncasos = pd.concat([negro,blanco])\ncasos\n\n\n\n\n\n\n\n\n\n\nTi_C\nTi_R1\nTi_R2\nTi_S\n\n\nCategoría\nFecha\n\n\n\n\n\n\n\n\n2006-01-01\nnegro\n18.993764\n18.999711\n19.034391\n19.083183\n\n\n2006-01-02\nnegro\n20.104855\n20.078903\n20.250677\n20.205274\n\n\n2006-01-03\nnegro\n19.309793\n19.118780\n18.991211\n19.123250\n\n\n2006-01-04\nnegro\n17.480913\n16.588023\n16.372463\n17.137445\n\n\n2006-01-05\nnegro\n18.980579\n17.768470\n17.668538\n18.643465\n\n\n...\n...\n...\n...\n...\n...\n\n\n2006-12-28\nblanco\n14.165858\n14.000331\n14.035546\n13.920070\n\n\n2006-12-29\nblanco\n15.896368\n15.731774\n15.864342\n15.855534\n\n\n2006-12-30\nblanco\n17.800614\n17.556038\n17.730885\n17.826264\n\n\n2006-12-31\nblanco\n18.482376\n18.312972\n18.421315\n18.600672\n\n\n2007-01-01\nblanco\n19.521151\n19.448329\n19.688533\n19.819254\n\n\n\n\n732 rows × 4 columns\n\n\n\n\n\ncasos.loc['2006-01','blanco']\n\n\n\n\n\n\n\n\n\nTi_C\nTi_R1\nTi_R2\nTi_S\n\n\nCategoría\n\n\n\n\n\n\n\n\n2006-01-01\n18.961551\n18.968034\n19.002049\n19.050950\n\n\n2006-01-02\n19.413483\n19.425501\n19.520059\n19.542445\n\n\n2006-01-03\n18.138849\n18.032331\n17.872337\n18.046172\n\n\n2006-01-04\n14.431871\n14.147740\n13.754557\n14.007418\n\n\n2006-01-05\n14.295440\n14.057466\n13.901701\n13.993210\n\n\n2006-01-06\n15.620154\n15.377971\n15.416920\n15.425257\n\n\n2006-01-07\n16.198036\n16.104297\n16.049916\n16.044580\n\n\n2006-01-08\n11.876301\n11.592555\n11.122067\n11.163917\n\n\n2006-01-09\n10.507727\n10.213770\n9.851995\n9.714301\n\n\n2006-01-10\n13.602409\n13.486783\n13.594123\n13.352994\n\n\n2006-01-11\n14.092676\n13.894091\n13.824781\n13.781661\n\n\n2006-01-12\n15.369566\n15.237519\n15.217131\n15.146219\n\n\n2006-01-13\n13.955472\n13.684138\n13.461462\n13.520220\n\n\n2006-01-14\n13.934886\n13.618162\n13.469840\n13.552627\n\n\n2006-01-15\n14.817750\n14.560462\n14.529891\n14.595354\n\n\n2006-01-16\n16.393359\n16.239772\n16.396078\n16.424494\n\n\n2006-01-17\n18.052838\n17.857875\n18.041275\n18.168993\n\n\n2006-01-18\n19.496338\n19.301262\n19.477641\n19.735577\n\n\n2006-01-19\n18.503936\n18.204900\n18.066650\n18.486581\n\n\n2006-01-20\n14.183292\n13.769410\n13.327532\n13.635025\n\n\n2006-01-21\n15.626780\n15.475040\n15.454669\n15.371909\n\n\n2006-01-22\n15.983414\n15.810804\n15.825034\n15.827421\n\n\n2006-01-23\n17.513464\n17.322074\n17.450166\n17.513643\n\n\n2006-01-24\n19.045467\n18.870103\n19.011692\n19.106406\n\n\n2006-01-25\n17.247607\n16.939827\n16.725375\n17.002644\n\n\n2006-01-26\n17.874866\n17.771731\n17.882630\n17.955168\n\n\n2006-01-27\n18.996153\n18.947590\n19.051278\n19.158464\n\n\n2006-01-28\n16.146461\n15.844702\n15.577670\n15.841123\n\n\n2006-01-29\n17.558852\n17.435669\n17.569172\n17.670580\n\n\n2006-01-30\n18.897609\n18.699047\n18.844758\n19.049960\n\n\n2006-01-31\n18.736328\n18.485041\n18.501673\n18.882997",
    "crumbs": [
      "Semana Cuatro",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Multi-índices en las columnas de series temporales</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaCuatro/Encoding.html",
    "href": "notebooks/semanaCuatro/Encoding.html",
    "title": "47  El encoding",
    "section": "",
    "text": "Bienvenidos a esta sesión dedicada al encoding y su importancia al importar datos con Pandas. El encoding, o codificación de caracteres, es un proceso fundamental en el mundo digital que determina cómo se representan los caracteres de texto en formatos digitales. En esta sesión, exploraremos los diferentes tipos de encoding, con un enfoque especial en el popular UTF-8, y analizaremos por qué especificar correctamente el encoding al importar datos con Pandas es esencial para evitar errores y garantizar la integridad de los datos. Sin el encoding adecuado, podríamos enfrentarnos a problemas como caracteres no reconocidos o datos corruptos, especialmente al trabajar con idiomas que utilizan caracteres especiales. Aprenderemos cómo verificar el encoding de un archivo de datos y cómo Pandas nos permite especificar el encoding mediante el argumento ‘encoding’ en funciones como ‘read_csv’. Además, exploraremos una herramienta útil en Windows para identificar y cambiar el encoding de un archivo: Notepad++.\n\nimport pandas as pd\n\n\nf = \"../data/Cuernavaca_1dia_comas_Encoding.txt\"\ncuerna = pd.read_csv(f)\ncuerna\n\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x8e in position 25: invalid start byte\n\n\n\nf = \"../data/Cuernavaca_1dia_comas_Encoding.txt\"\ncuerna = pd.read_csv(f,encoding=\"Shift-JIS\")\ncuerna\n\n\n\n\n\n\n\n\n\ntiempo\nTo\nWs\nWd\nP\nIg\nIb\n?字/漢字\n\n\n\n\n0\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n\n\n1\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n\n\n2\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n\n\n3\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n\n\n4\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n\n\n5\n2012-01-01 05:00:00\n15.9\n0.0\n26\n87087\n0\n0\n0\n\n\n6\n2012-01-01 06:00:00\n17.0\n0.0\n27\n87096\n0\n0\n0\n\n\n7\n2012-01-01 07:00:00\n18.0\n0.0\n34\n87140\n20\n151\n11\n\n\n8\n2012-01-01 08:00:00\n19.0\n0.0\n61\n87185\n164\n522\n37\n\n\n9\n2012-01-01 09:00:00\n20.0\n0.0\n95\n87229\n369\n812\n58\n\n\n10\n2012-01-01 10:00:00\n20.0\n1.0\n108\n87229\n568\n931\n68\n\n\n11\n2012-01-01 11:00:00\n20.0\n2.1\n160\n87229\n717\n981\n75\n\n\n12\n2012-01-01 12:00:00\n21.0\n1.8\n135\n87273\n800\n999\n79\n\n\n13\n2012-01-01 13:00:00\n22.0\n1.5\n160\n87316\n810\n998\n80\n\n\n14\n2012-01-01 14:00:00\n21.7\n1.3\n164\n87302\n747\n977\n79\n\n\n15\n2012-01-01 15:00:00\n21.3\n1.2\n176\n87287\n617\n932\n74\n\n\n16\n2012-01-01 16:00:00\n21.0\n1.0\n140\n87273\n433\n846\n65\n\n\n17\n2012-01-01 17:00:00\n19.0\n0.0\n198\n87185\n219\n650\n46\n\n\n18\n2012-01-01 18:00:00\n17.1\n0.0\n221\n87104\n0\n0\n0\n\n\n19\n2012-01-01 19:00:00\n17.0\n0.0\n269\n87101\n0\n0\n0\n\n\n20\n2012-01-01 20:00:00\n17.3\n0.0\n50\n87115\n0\n0\n0\n\n\n21\n2012-01-01 21:00:00\n17.0\n0.2\n85\n87080\n0\n0\n0\n\n\n22\n2012-01-01 22:00:00\n16.6\n0.5\n89\n87089\n0\n0\n0\n\n\n23\n2012-01-01 23:00:00\n15.9\n0.8\n93\n87143\n0\n0\n0\n\n\n\n\n\n\n\n\n\nf = \"../data/Cuernavaca_1dia_comas_Encoding_UTF8.txt\"\ncuerna = pd.read_csv(f)\ncuerna\n\n\n\n\n\n\n\n\n\ntiempo\nTo\nWs\nWd\nP\nIg\nIb\n汉字/漢字\n\n\n\n\n0\n2012-01-01 00:00:00\n19.3\n0.0\n26\n87415\n0\n0\n0\n\n\n1\n2012-01-01 01:00:00\n18.6\n0.0\n26\n87602\n0\n0\n0\n\n\n2\n2012-01-01 02:00:00\n17.9\n0.0\n30\n87788\n0\n0\n0\n\n\n3\n2012-01-01 03:00:00\n17.3\n0.0\n30\n87554\n0\n0\n0\n\n\n4\n2012-01-01 04:00:00\n16.6\n0.0\n27\n87321\n0\n0\n0\n\n\n5\n2012-01-01 05:00:00\n15.9\n0.0\n26\n87087\n0\n0\n0\n\n\n6\n2012-01-01 06:00:00\n17.0\n0.0\n27\n87096\n0\n0\n0\n\n\n7\n2012-01-01 07:00:00\n18.0\n0.0\n34\n87140\n20\n151\n11\n\n\n8\n2012-01-01 08:00:00\n19.0\n0.0\n61\n87185\n164\n522\n37\n\n\n9\n2012-01-01 09:00:00\n20.0\n0.0\n95\n87229\n369\n812\n58\n\n\n10\n2012-01-01 10:00:00\n20.0\n1.0\n108\n87229\n568\n931\n68\n\n\n11\n2012-01-01 11:00:00\n20.0\n2.1\n160\n87229\n717\n981\n75\n\n\n12\n2012-01-01 12:00:00\n21.0\n1.8\n135\n87273\n800\n999\n79\n\n\n13\n2012-01-01 13:00:00\n22.0\n1.5\n160\n87316\n810\n998\n80\n\n\n14\n2012-01-01 14:00:00\n21.7\n1.3\n164\n87302\n747\n977\n79\n\n\n15\n2012-01-01 15:00:00\n21.3\n1.2\n176\n87287\n617\n932\n74\n\n\n16\n2012-01-01 16:00:00\n21.0\n1.0\n140\n87273\n433\n846\n65\n\n\n17\n2012-01-01 17:00:00\n19.0\n0.0\n198\n87185\n219\n650\n46\n\n\n18\n2012-01-01 18:00:00\n17.1\n0.0\n221\n87104\n0\n0\n0\n\n\n19\n2012-01-01 19:00:00\n17.0\n0.0\n269\n87101\n0\n0\n0\n\n\n20\n2012-01-01 20:00:00\n17.3\n0.0\n50\n87115\n0\n0\n0\n\n\n21\n2012-01-01 21:00:00\n17.0\n0.2\n85\n87080\n0\n0\n0\n\n\n22\n2012-01-01 22:00:00\n16.6\n0.5\n89\n87089\n0\n0\n0\n\n\n23\n2012-01-01 23:00:00\n15.9\n0.8\n93\n87143\n0\n0\n0",
    "crumbs": [
      "Semana Cuatro",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>El encoding</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaCuatro/paquetes_locales.html",
    "href": "notebooks/semanaCuatro/paquetes_locales.html",
    "title": "48  Desarrolla paquetes locales",
    "section": "",
    "text": "En el vasto y dinámico mundo de Python, la organización eficiente del código es fundamental para el éxito de cualquier proyecto. En esta sesión, nos adentraremos en el concepto de los paquetes locales, explorando cuándo y cómo pasar tus funciones de Python para que puedan ser llamadas como un paquete, similar al paquete de Pandas. Un paquete local, es esencialmente un directorio con archivos .py y un archivo init.py, facilita la modularización del código y promueve prácticas de desarrollo sólidas. Descubriremos cómo agrupar funcionalidades relacionadas en módulos dentro de un paquete local puede mejorar la claridad, el mantenimiento y la reutilización del código. Desde la distribución del código a otros usuarios hasta la colaboración en proyectos a gran escala, la implementación de paquetes locales en Python es una estrategia poderosa para hacer que tu código sea más accesible y fácil de mantener.\n\nCrea una carpeta con el nombre del paquete \nCrea un archivo init.py vacio adentro de esa carpeta \nAgrupa tus funciones por archivos \nEn cada archivo.py carga paquetes y escribe funciones o clases \nImporta paquetes locales\n\n\nfrom iertools.read import read_sql\n\n\ndef funcion_prueba(nombre, mensaje='Hola mundo'):\n    return f'{mensaje} de {nombre}'\n\n\nfuncion_prueba('memo')\n\n'Hola mundo de memo'",
    "crumbs": [
      "Semana Cuatro",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Desarrolla paquetes locales</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaCuatro/EF_EDA.html",
    "href": "notebooks/semanaCuatro/EF_EDA.html",
    "title": "49  Ejercicio Final - Parte 1: exploración visual de datos",
    "section": "",
    "text": "En este emocionante cierre de curso, nos embarcaremos en un ejercicio final aplicando las buenas prácticas recomendadas en nuestro recorrido. El desafío que enfrentamos es intrigante: tenemos dos archivos CSV que contienen datos de temperatura registrados por torres de termopares, cada una con 12 puntos de medición, y nuestro objetivo es graficar la temperatura promedio de cada conjunto de 12 puntos cada 10 minutos a lo largo del tiempo. Este problema se divide en tres videos, y en esta primera parte nos enfocaremos en una exploración rápida de los datos para decidir cómo limpiarlos al importarlos. En los siguientes videos, importaremos los datos, los limpiaremos y los prepararemos para el análisis, y finalmente, en el tercer video, cargaremos los datos y obtendremos la gráfica deseada.\n\n50 Problema\nDos torres con 12 termopares cada una. Se desea calcular el promedio cada 10 minutos de las temperaturas de cada torre y compararlas en una gráfica de las 12 a las 17 horas.\n\n\n\nimage-2.png\n\n\n\nimport pandas as pd\n\n\nf = '../data/termopares/centro_cafeteria.csv'\nTcafe = pd.read_csv(f,index_col=0,parse_dates=True)\n\nf = '../data/termopares/exterior.csv'\nText = pd.read_csv(f,index_col=0,parse_dates=True)\n\n\nTcafe.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 1632 entries, 2023-04-03 10:48:00 to 2023-04-04 13:59:00\nData columns (total 12 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   TMP1    471 non-null    float64\n 1   TMP2    471 non-null    float64\n 2   TMP3    471 non-null    float64\n 3   TMP4    471 non-null    float64\n 4   TMP5    471 non-null    float64\n 5   TMP6    471 non-null    float64\n 6   TMP7    471 non-null    float64\n 7   TMP8    471 non-null    float64\n 8   TMP11   454 non-null    float64\n 9   TMP12   454 non-null    float64\n 10  TMP10   454 non-null    float64\n 11  TMP9    454 non-null    float64\ndtypes: float64(12)\nmemory usage: 165.8 KB\n\n\n\nText.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 1619 entries, 2023-04-03 11:01:00 to 2023-04-04 13:59:00\nData columns (total 12 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   TMP1    1619 non-null   float64\n 1   TMP10   1619 non-null   float64\n 2   TMP11   1619 non-null   float64\n 3   TMP12   1619 non-null   float64\n 4   TMP2    1619 non-null   float64\n 5   TMP3    1619 non-null   float64\n 6   TMP4    1619 non-null   float64\n 7   TMP5    1619 non-null   float64\n 8   TMP6    1619 non-null   float64\n 9   TMP7    1619 non-null   float64\n 10  TMP8    1619 non-null   float64\n 11  TMP9    1619 non-null   float64\ndtypes: float64(12)\nmemory usage: 164.4 KB\n\n\n\nTcafe.plot(figsize=(12,2))\n\n\n\n\n\n\n\n\n\nText.plot(figsize=(12,2))\n\n\n\n\n\n\n\n\n\nText.plot(figsize=(12,10),subplots=True);\n\n\n\n\n\n\n\n\n\nText.describe()\n\n\n\n\n\n\n\n\n\nTMP1\nTMP10\nTMP11\nTMP12\nTMP2\nTMP3\nTMP4\nTMP5\nTMP6\nTMP7\nTMP8\nTMP9\n\n\n\n\ncount\n1619.000000\n1619.000000\n1619.000000\n1619.000000\n1619.000000\n1619.000000\n1619.000000\n1619.000000\n1619.000000\n1.619000e+03\n1619.000000\n1619.000000\n\n\nmean\n27.857400\n28.032980\n27.793535\n27.359272\n27.713543\n27.501829\n27.452916\n18.674083\n27.485951\n-8.960000e+00\n27.598910\n28.734695\n\n\nstd\n4.994949\n5.186105\n5.267671\n5.321998\n4.972734\n5.060342\n5.148783\n275.614825\n4.884075\n1.776906e-15\n4.898396\n5.123670\n\n\nmin\n-8.240000\n-7.920000\n-8.860000\n-7.770000\n19.270000\n-8.540000\n-8.780000\n-10194.370000\n-8.340000\n-8.960000e+00\n-7.440000\n-7.800000\n\n\n25%\n23.840000\n23.740000\n23.470000\n22.975000\n23.470000\n23.335000\n23.240000\n23.790000\n23.490000\n-8.960000e+00\n23.530000\n24.540000\n\n\n50%\n27.105000\n27.305000\n27.045000\n26.570000\n26.895000\n26.755000\n26.660000\n27.065000\n26.920000\n-8.960000e+00\n26.930000\n27.960000\n\n\n75%\n32.250000\n32.585000\n32.335000\n31.870000\n32.030000\n31.880000\n31.940000\n31.580000\n31.600000\n-8.960000e+00\n31.890000\n33.250000\n\n\nmax\n37.850000\n38.940000\n40.105000\n39.370000\n37.940000\n37.790000\n37.850000\n37.035000\n37.370000\n-8.960000e+00\n37.460000\n39.470000\n\n\n\n\n\n\n\n\n\n\n51 Limpieza de Text\n\nTirar TMP5\nTirar datos &lt; 0\nRenombrar columnas a T1, T2…\nResample cada 10 minutos con promedio\n\n\n\n52 Limpieza de Tcafe\n\nRenombrar columnas a T1, T2…\nResample cada 10 minutos con promedio\n\n\n\n53 Ambos conjuntos, datos de 12 a 5pm",
    "crumbs": [
      "Semana Cuatro",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Ejercicio Final - Parte 1: exploración visual de datos</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaCuatro/EF_LimpiezaDatos.html",
    "href": "notebooks/semanaCuatro/EF_LimpiezaDatos.html",
    "title": "50  Ejercicio Final - Parte 2: Limpieza de datos",
    "section": "",
    "text": "import pandas as pd\n\n\n51 Limpieza de Text\n\nTirar TMP5\nTirar datos &lt; 0\nRenombrar columnas a T1, T2…\nResample cada 10 minutos con promedio\n\n\nf = '../data/termopares/exterior.csv'\nText = pd.read_csv(f,index_col=0,parse_dates=True)\nnombres = Text.columns.to_list()\nnombres.remove('TMP5')\nText = Text[nombres]\nnombres = Text.columns.to_list()\nnombres = [nombre.replace('MP','') for nombre in nombres]\nText.columns = nombres\nText = Text[Text[nombres]&gt;0]\nText = Text.resample('10Min').mean()\n\n\nText.plot()\n\n\n\n\n\n\n\n\n\n\n52 Limpieza de Tcafe\n\nRenombrar columnas a T1, T2…\nResample cada 10 minutos con promedio\n\n\nf = '../data/termopares/exterior.csv'\nTcafe = pd.read_csv(f,index_col=0,parse_dates=True)\nnombres = Tcafe.columns.to_list()\nnombres = [nombre.replace('MP','') for nombre in nombres]\nTcafe.columns = nombres\nTcafe = Tcafe.resample('10Min').mean()\nTcafe\n\n\n\n\n\n\n\n\n\nT1\nT10\nT11\nT12\nT2\nT3\nT4\nT5\nT6\nT7\nT8\nT9\n\n\nts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2023-04-03 11:00:00\n24.719444\n24.891667\n24.783333\n24.278889\n25.737778\n24.4700\n24.363889\n-451.577222\n24.401667\n-8.96\n24.702222\n25.284444\n\n\n2023-04-03 11:10:00\n27.934000\n28.483000\n28.106000\n27.599000\n27.887000\n27.7005\n27.652000\n27.673000\n27.588500\n-8.96\n27.659500\n28.883500\n\n\n2023-04-03 11:20:00\n28.386000\n28.808500\n28.464500\n27.942000\n28.229500\n28.0725\n27.979500\n27.937000\n27.900500\n-8.96\n27.999500\n29.334000\n\n\n2023-04-03 11:30:00\n28.463500\n28.917000\n28.589500\n28.130000\n28.292500\n28.1500\n28.182000\n28.060500\n27.977500\n-8.96\n28.185500\n29.489000\n\n\n2023-04-03 11:40:00\n28.915000\n29.428500\n29.039000\n28.549000\n28.806000\n28.6770\n28.636000\n28.547500\n28.510000\n-8.96\n28.604000\n29.969500\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2023-04-04 13:10:00\n25.503000\n29.645500\n29.395500\n28.925000\n26.424500\n27.4210\n28.431500\n26.553500\n25.655500\n-8.96\n24.986500\n30.062500\n\n\n2023-04-04 13:20:00\n29.087500\n30.188000\n29.814000\n29.331500\n29.149500\n29.2525\n29.444500\n28.840500\n28.540500\n-8.96\n28.666000\n30.730000\n\n\n2023-04-04 13:30:00\n30.240500\n30.622000\n30.341000\n29.937500\n30.082500\n29.9245\n29.940500\n29.617000\n29.727500\n-8.96\n29.890500\n31.201000\n\n\n2023-04-04 13:40:00\n29.118000\n28.901500\n28.542000\n28.081500\n28.900000\n28.6615\n28.605500\n28.811000\n28.790000\n-8.96\n28.852000\n29.551000\n\n\n2023-04-04 13:50:00\n30.364500\n30.529000\n30.310000\n29.783000\n30.191000\n29.9700\n30.002500\n29.917500\n30.008000\n-8.96\n30.154000\n31.199000\n\n\n\n\n162 rows × 12 columns\n\n\n\n\n\n\n53 Ambos conjuntos de 12 a 15 horas\n\nf1 = '2023-04-03 12:00'\nf2 = '2023-04-03 17:00'\n\nTcafe.loc[f1:f2].to_csv('../data/termopares/Tcafe-12a17h.csv')\nText.loc[f1:f2].to_csv('../data/termopares/Text-12a17h.csv')\n\n\nf = '../data/termopares/Tcafe-12a17h.csv'\ncafe = pd.read_csv(f,index_col=0,parse_dates=True)\ncafe.plot()\n\n\n\n\n\n\n\n\n\nf = '../data/termopares/Text-12a17h.csv'\next = pd.read_csv(f,index_col=0,parse_dates=True)\next.plot()",
    "crumbs": [
      "Semana Cuatro",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Ejercicio Final - Parte 2: Limpieza de datos</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaCuatro/EF_Analisis.html",
    "href": "notebooks/semanaCuatro/EF_Analisis.html",
    "title": "51  Ejercicio Final - Parte 3: Preparación y visualización de datos",
    "section": "",
    "text": "Bienvenidos a este video dedicado a simplificar el proceso de visualización de datos. En esta sesión, nos centraremos únicamente en cargar los datos, prepararlos para la graficación y finalmente, graficarlos. Este enfoque directo nos permitirá obtener resultados rápidamente y sin complicaciones. Sin más preámbulos, ¡empecemos con el proceso de carga y graficación de datos!\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom dateutil.parser import parse\n\n\nf = '../data/termopares/Tcafe-12a17h.csv'\ncafe = pd.read_csv(f,index_col=0,parse_dates=True)\nf = '../data/termopares/Text-12a17h.csv'\next = pd.read_csv(f,index_col=0,parse_dates=True)\n\n\nTi = pd.concat([cafe,ext],axis=1,keys=['cafe','ext'])\nTi\n\n\n\n\n\n\n\n\n\ncafe\n...\next\n\n\n\nT1\nT10\nT11\nT12\nT2\nT3\nT4\nT5\nT6\nT7\n...\nT10\nT11\nT12\nT2\nT3\nT4\nT6\nT7\nT8\nT9\n\n\nts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2023-04-03 12:00:00\n29.6670\n30.0330\n29.7210\n29.3180\n29.5245\n29.3590\n29.3670\n29.1675\n29.1310\n-8.96\n...\n30.0330\n29.7210\n29.3180\n29.5245\n29.3590\n29.3670\n29.1310\nNaN\n29.2860\n30.5740\n\n\n2023-04-03 12:10:00\n29.6360\n29.9245\n29.6590\n29.3025\n29.4470\n29.3435\n29.3360\n29.0125\n28.9915\n-8.96\n...\n29.9245\n29.6590\n29.3025\n29.4470\n29.3435\n29.3360\n28.9915\nNaN\n29.1000\n30.5120\n\n\n2023-04-03 12:20:00\n30.5040\n30.9165\n30.6820\n30.2175\n30.3770\n30.1885\n30.2350\n29.9965\n29.9625\n-8.96\n...\n30.9165\n30.6820\n30.2175\n30.3770\n30.1885\n30.2350\n29.9625\nNaN\n30.1230\n31.4815\n\n\n2023-04-03 12:30:00\n30.5970\n30.9320\n30.6820\n30.2325\n30.5010\n30.2990\n30.2970\n30.0750\n30.0710\n-8.96\n...\n30.9320\n30.6820\n30.2325\n30.5010\n30.2990\n30.2970\n30.0710\nNaN\n30.1850\n31.5605\n\n\n2023-04-03 12:40:00\n31.3605\n31.6795\n31.4620\n30.9710\n31.1250\n30.9655\n30.9635\n30.7895\n30.8025\n-8.96\n...\n31.6795\n31.4620\n30.9710\n31.1250\n30.9655\n30.9635\n30.8025\nNaN\n30.9755\n32.2890\n\n\n2023-04-03 12:50:00\n30.9240\n31.2890\n31.0870\n30.6105\n30.8280\n30.6400\n30.6690\n30.3090\n30.3655\n-8.96\n...\n31.2890\n31.0870\n30.6105\n30.8280\n30.6400\n30.6690\n30.3655\nNaN\n30.5105\n31.8705\n\n\n2023-04-03 13:00:00\n30.8145\n31.1495\n30.9155\n30.5160\n30.6720\n30.4850\n30.5450\n30.2935\n30.3345\n-8.96\n...\n31.1495\n30.9155\n30.5160\n30.6720\n30.4850\n30.5450\n30.3345\nNaN\n30.4640\n31.7930\n\n\n2023-04-03 13:10:00\n32.0325\n32.5535\n32.3195\n31.8590\n31.9060\n31.7250\n31.7860\n31.5510\n31.5210\n-8.96\n...\n32.5535\n32.3195\n31.8590\n31.9060\n31.7250\n31.7860\n31.5210\nNaN\n31.7195\n33.0795\n\n\n2023-04-03 13:20:00\n32.2035\n32.6310\n32.3350\n31.9210\n32.0765\n31.9110\n31.8345\n31.7565\n31.7065\n-8.96\n...\n32.6310\n32.3350\n31.9210\n32.0765\n31.9110\n31.8345\n31.7065\nNaN\n31.7970\n33.2035\n\n\n2023-04-03 13:30:00\n32.2810\n32.7400\n32.4280\n32.0295\n32.1385\n31.9420\n31.9890\n31.7085\n31.7705\n-8.96\n...\n32.7400\n32.4280\n32.0295\n32.1385\n31.9420\n31.9890\n31.7705\nNaN\n31.9365\n33.2965\n\n\n2023-04-03 13:40:00\n32.0795\n32.5230\n32.2885\n31.9660\n32.0455\n31.8335\n31.8160\n31.5040\n31.5070\n-8.96\n...\n32.5230\n32.2885\n31.9660\n32.0455\n31.8335\n31.8160\n31.5070\nNaN\n31.7040\n33.0950\n\n\n2023-04-03 13:50:00\n32.8235\n33.3135\n33.0170\n32.5770\n32.7585\n32.5775\n32.5850\n32.3030\n32.2820\n-8.96\n...\n33.3135\n33.0170\n32.5770\n32.7585\n32.5775\n32.5850\n32.2820\nNaN\n32.5100\n33.8700\n\n\n2023-04-03 14:00:00\n33.2590\n33.6855\n33.5595\n33.0745\n33.1460\n32.9665\n33.0350\n32.6750\n32.6890\n-8.96\n...\n33.6855\n33.5595\n33.0745\n33.1460\n32.9665\n33.0350\n32.6890\nNaN\n32.8200\n34.3395\n\n\n2023-04-03 14:10:00\n33.7600\n34.1970\n34.0865\n33.5270\n33.6780\n33.4525\n33.5000\n33.1090\n33.1905\n-8.96\n...\n34.1970\n34.0865\n33.5270\n33.6780\n33.4525\n33.5000\n33.1905\nNaN\n33.3315\n34.8250\n\n\n2023-04-03 14:20:00\n33.5070\n33.8405\n33.6215\n33.2450\n33.3480\n33.1995\n33.2365\n32.8145\n32.8950\n-8.96\n...\n33.8405\n33.6215\n33.2450\n33.3480\n33.1995\n33.2365\n32.8950\nNaN\n32.9905\n34.4980\n\n\n2023-04-03 14:30:00\n34.4920\n34.9255\n34.7065\n34.1220\n34.4270\n34.1840\n34.1510\n33.9350\n33.9520\n-8.96\n...\n34.9255\n34.7065\n34.1220\n34.4270\n34.1840\n34.1510\n33.9520\nNaN\n34.1065\n35.4610\n\n\n2023-04-03 14:40:00\n34.4145\n34.7860\n34.5825\n34.1530\n34.2565\n34.0290\n34.1045\n33.7455\n33.8265\n-8.96\n...\n34.7860\n34.5825\n34.1530\n34.2565\n34.0290\n34.1045\n33.8265\nNaN\n33.9360\n35.4300\n\n\n2023-04-03 14:50:00\n34.4920\n35.0650\n34.9090\n34.4010\n34.4580\n34.2615\n34.2905\n33.9040\n34.0435\n-8.96\n...\n35.0650\n34.9090\n34.4010\n34.4580\n34.2615\n34.2905\n34.0435\nNaN\n34.0910\n35.6625\n\n\n2023-04-03 15:00:00\n35.0345\n35.5610\n35.4265\n34.9660\n34.9075\n34.7575\n34.7865\n34.3435\n34.4540\n-8.96\n...\n35.5610\n35.4265\n34.9660\n34.9075\n34.7575\n34.7865\n34.4540\nNaN\n34.6180\n36.1430\n\n\n2023-04-03 15:10:00\n35.1430\n35.5300\n35.2735\n34.9360\n35.0470\n34.8040\n34.8950\n34.6070\n34.6735\n-8.96\n...\n35.5300\n35.2735\n34.9360\n35.0470\n34.8040\n34.8950\n34.6735\nNaN\n34.7575\n36.2360\n\n\n2023-04-03 15:20:00\n34.9415\n35.2975\n35.1140\n34.6805\n34.8455\n34.6955\n34.6470\n34.4055\n34.5340\n-8.96\n...\n35.2975\n35.1140\n34.6805\n34.8455\n34.6955\n34.6470\n34.5340\nNaN\n34.5560\n35.9570\n\n\n2023-04-03 15:30:00\n35.4375\n35.7160\n35.5380\n35.0920\n35.3105\n35.1295\n35.1740\n34.8550\n34.9215\n-8.96\n...\n35.7160\n35.5380\n35.0920\n35.3105\n35.1295\n35.1740\n34.9215\nNaN\n35.0520\n36.4065\n\n\n2023-04-03 15:40:00\n35.5775\n36.2120\n36.0185\n35.6355\n35.5895\n35.3775\n35.4840\n34.9325\n34.9990\n-8.96\n...\n36.2120\n36.0185\n35.6355\n35.5895\n35.3775\n35.4840\n34.9990\nNaN\n35.2535\n36.8095\n\n\n2023-04-03 15:50:00\n35.9095\n36.3515\n36.0960\n35.7905\n35.8375\n35.6410\n35.6415\n35.2580\n35.3555\n-8.96\n...\n36.3515\n36.0960\n35.7905\n35.8375\n35.6410\n35.6415\n35.3555\nNaN\n35.5015\n36.9180\n\n\n2023-04-03 16:00:00\n35.9715\n36.2895\n36.0805\n35.7595\n35.8220\n35.6410\n35.6730\n35.3365\n35.4655\n-8.96\n...\n36.2895\n36.0805\n35.7595\n35.8220\n35.6410\n35.6730\n35.4655\nNaN\n35.5945\n36.9180\n\n\n2023-04-03 16:10:00\n36.4240\n36.8320\n36.6230\n36.3375\n36.3200\n36.0905\n36.1745\n35.6815\n35.8425\n-8.96\n...\n36.8320\n36.6230\n36.3375\n36.3200\n36.0905\n36.1745\n35.8425\nNaN\n35.9665\n37.3990\n\n\n2023-04-03 16:20:00\n36.3775\n36.8165\n36.7005\n36.3375\n36.3665\n36.1370\n36.2065\n35.6320\n35.8260\n-8.96\n...\n36.8165\n36.7005\n36.3375\n36.3665\n36.1370\n36.2065\n35.8260\nNaN\n35.9820\n37.3995\n\n\n2023-04-03 16:30:00\n36.5480\n36.9405\n36.9330\n36.5570\n36.4600\n36.2765\n36.3930\n35.7110\n35.9515\n-8.96\n...\n36.9405\n36.9330\n36.5570\n36.4600\n36.2765\n36.3930\n35.9515\nNaN\n36.0120\n37.6500\n\n\n2023-04-03 16:40:00\n36.0210\n36.1810\n36.1115\n35.8370\n35.8840\n35.6410\n35.7180\n35.2270\n35.4795\n-8.96\n...\n36.1810\n36.1115\n35.8370\n35.8840\n35.6410\n35.7180\n35.4795\nNaN\n35.6255\n36.9180\n\n\n2023-04-03 16:50:00\n37.1835\n37.6845\n38.0830\n38.3500\n37.1945\n36.9330\n37.0900\n36.4765\n36.7915\n-8.96\n...\n37.6845\n38.0830\n38.3500\n37.1945\n36.9330\n37.0900\n36.7915\nNaN\n36.8110\n38.2425\n\n\n2023-04-03 17:00:00\n37.6175\n38.4130\n38.5170\n38.5530\n37.5835\n37.3865\n37.5400\n36.6940\n36.9470\n-8.96\n...\n38.4130\n38.5170\n38.5530\n37.5835\n37.3865\n37.5400\n36.9470\nNaN\n37.1190\n38.6640\n\n\n\n\n31 rows × 23 columns\n\n\n\n\n\nTi['cafe'].mean()\n\nT1     33.775290\nT10    34.193855\nT11    34.018613\nT12    33.641129\nT2     33.673581\nT3     33.479774\nT4     33.521403\nT5     33.155145\nT6     33.234935\nT7     -8.960000\nT8     33.368887\nT9     34.790387\ndtype: float64\n\n\n\nTi['cafe'].mean(axis=1)\n\nts\n2023-04-03 12:00:00    26.349000\n2023-04-03 12:10:00    26.275375\n2023-04-03 12:20:00    27.143667\n2023-04-03 12:30:00    27.206000\n2023-04-03 12:40:00    27.868625\n2023-04-03 12:50:00    27.511917\n2023-04-03 13:00:00    27.418542\n2023-04-03 13:10:00    28.591042\n2023-04-03 13:20:00    28.701333\n2023-04-03 13:30:00    28.775000\n2023-04-03 13:40:00    28.616833\n2023-04-03 13:50:00    29.304750\n2023-04-03 14:00:00    29.690792\n2023-04-03 14:10:00    30.141417\n2023-04-03 14:20:00    29.853000\n2023-04-03 14:30:00    30.791875\n2023-04-03 14:40:00    30.692000\n2023-04-03 14:50:00    30.884833\n2023-04-03 15:00:00    31.336500\n2023-04-03 15:10:00    31.411875\n2023-04-03 15:20:00    31.226167\n2023-04-03 15:30:00    31.639375\n2023-04-03 15:40:00    31.910750\n2023-04-03 15:50:00    32.111708\n2023-04-03 16:00:00    32.132625\n2023-04-03 16:10:00    32.560917\n2023-04-03 16:20:00    32.568458\n2023-04-03 16:30:00    32.706042\n2023-04-03 16:40:00    32.140292\n2023-04-03 16:50:00    33.490000\n2023-04-03 17:00:00    33.839542\ndtype: float64\n\n\n\nfig, ax = plt.subplots(figsize=(12,4))\n\nax.plot(Ti['cafe'].mean(axis=1),'r.',label='cafe')\nax.plot( Ti['ext'].mean(axis=1),'k.',label='ext')\n\nax.set_ylim(20,40)\nax.set_xlabel('Fecha')\nax.set_ylabel('Temperatura [oC]')\nax.legend()",
    "crumbs": [
      "Semana Cuatro",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Ejercicio Final - Parte 3: Preparación y visualización de datos</span>"
    ]
  },
  {
    "objectID": "notebooks/semanaCuatro/Paquetes.html",
    "href": "notebooks/semanaCuatro/Paquetes.html",
    "title": "52  Recomendaciones de paquetes a explorar",
    "section": "",
    "text": "Scipy\nBokeh\nScikit-learn\nTensorFlow\nPyTorch\nNbdev\nCalplot\nWindRose\nVisual Studio Code\nJupyterLab\nColab",
    "crumbs": [
      "Semana Cuatro",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Recomendaciones de paquetes a explorar</span>"
    ]
  },
  {
    "objectID": "creditos.html",
    "href": "creditos.html",
    "title": "Créditos",
    "section": "",
    "text": "Experto\nDr. Guillermo Barrios del Valle\n\n\nRealización y postproducción\nMtro. Vicente Hinojosa Alarcón\nDr. Adrián Sarmiento\nL. DG. Alejandra Ramos\n\n\nDiseño gráfico, ilustración y animación\nL. DG. Alejandra Ramos\n\n\nAsesoría Pedagógica\nDra. Guadalupe Vadillo Bueno\nDra. Jackeline Bucio García\n\n\nDiseño Curricular\nDr. Guillermo Barrios del Valle\nLic. Celeste Morales Santiago\nMtro. Aarón Isaí Pérez Díaz\nLic. Grecia Alejandra Suárez Moreno\n\n\nEdición de ejercicios y libretas\nEst. Ing. Nazli Michelle Alcántara Zárate\nIng. Sebastian Alberto Reyes Romero\n\n\nRevisión de proyectos\nM. en I. Diego Arturo Canul Reyes",
    "crumbs": [
      "Créditos"
    ]
  }
]